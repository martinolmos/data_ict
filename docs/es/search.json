[
  {
    "objectID": "posts/you-only-look-once/index.html",
    "href": "posts/you-only-look-once/index.html",
    "title": "You Only Look Once",
    "section": "",
    "text": "You Only Look Once (YOLO) es una serie de modelos de detección de objetos en tiempo real y de código abierto que pueden identificar y clasificar múltiples objetos dentro de una imagen o fotograma de video. A diferencia de los métodos tradicionales de detección de objetos que se basan en redes de propuestas de regiones, YOLO trata la detección de objetos como un único problema de regresión, prediciendo directamente los cuadros delimitadores y las probabilidades de clase a partir de toda la imagen en una sola evaluación.\nLa serie Ultralytics YOLOv8 admite varias tareas, incluida la detección de objetos, la estimación de poses, la segmentación y la clasificación. Es conocida por su velocidad y precisión, lo que la hace adecuada para aplicaciones en tiempo real como la vigilancia, la conducción autónoma y la robótica.\nAquí está el código para ejecutar un modelo YOLOv8 utilizando la biblioteca Ultralytics en Python para la detección de objetos y la estimación de poses:\n\n\nCódigo\nfrom ultralytics import YOLO\nimport cv2\nimport math \nimport torch\n\n\nCAM_INDEX = 0  # change if you have multiple cameras\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# model\nmodel = YOLO(\"yolo-Weights/yolov8n.pt\")\n\n# Optional: move model to GPU (if available)\ntry:\n    model.to(device)\nexcept Exception:\n    pass  # older ultralytics handles device per-predict call\n\n\n# start webcam\ncap = cv2.VideoCapture(CAM_INDEX)\ncap.set(3, 640)\ncap.set(4, 480)\n\n# object classes\nclassNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n              \"teddy bear\", \"hair drier\", \"toothbrush\"\n              ]\n\n# Video output settings\noutput_path = \"output_detection.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = 30\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile True:\n    success, img = cap.read()\n    if not success:\n        break\n    results = model(img, stream=True, device=\"cuda\")\n\n    # coordinates\n    for r in results:\n        boxes = r.boxes\n\n        for box in boxes:\n            # bounding box\n            x1, y1, x2, y2 = box.xyxy[0]\n            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n\n            # put box in cam\n            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n\n            # confidence\n            confidence = math.ceil((box.conf[0]*100))/100\n            print(\"Confidence ---&gt;\",confidence)\n\n            # class name\n            cls = int(box.cls[0])\n            print(\"Class name --&gt;\", classNames[cls])\n\n            # object details\n            org = [x1, y1]\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            fontScale = 1\n            color = (255, 0, 0)\n            thickness = 2\n\n            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n\n    # Write frame to video file\n    out.write(img)\n    \n    cv2.imshow('Webcam', img)\n    if cv2.waitKey(1) == ord('q'):\n        break\n\ncap.release()\nout.release()  # Release the video writer\ncv2.destroyAllWindows()\nprint(f\"Video saved to {output_path}\")\n\n\nVideo\n\n\nCódigo\n# Realtime pose estimation with YOLOv8 (OpenCV window)\nimport cv2, torch, time\nfrom ultralytics import YOLO\n\nCAM_INDEX = 0  # change if you have multiple cameras\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = YOLO('yolov8n-pose.pt')  # or 'yolov8s-pose.pt'\n# Optional: move model to GPU (if available)\ntry:\n    model.to(device)\nexcept Exception:\n    pass  # older ultralytics handles device per-predict call\n\ncap = cv2.VideoCapture(CAM_INDEX)\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n\n# Video output settings\noutput_path = \"output_pose.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = 30\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nprev_t = time.time()\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    results = model.predict(\n        frame,\n        device=device,\n        imgsz=640,\n        conf=0.5,\n        half=(device == 'cuda'),\n        verbose=False\n    )\n    annotated = results[0].plot()\n\n    # FPS overlay\n    now = time.time()\n    fps_val = 1 / (now - prev_t)\n    prev_t = now\n    cv2.putText(annotated, f'FPS: {fps_val:.1f} ({device})', (10, 30),\n                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n\n    # Write frame to video file\n    out.write(annotated)\n\n    cv2.imshow('YOLOv8 Pose', annotated)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\nout.release()  # Release the video writer\ncv2.destroyAllWindows()\nprint(f\"Video saved to {output_path}\")\n\n\nVideo"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html",
    "href": "posts/transcribe-messi-using-whisper/index.html",
    "title": "Using Whisper to Transcribe Messi",
    "section": "",
    "text": "Whisper es un modelo de código abierto para reconocimiento del habla desarrollado por OpenAI.\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\nAquí la entrevista original:"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#descargo-el-audio-y-el-video-de-youtube",
    "href": "posts/transcribe-messi-using-whisper/index.html#descargo-el-audio-y-el-video-de-youtube",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Descargo el audio y el video de Youtube",
    "text": "Descargo el audio y el video de Youtube\n\n\nCódigo\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\n:::"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#genero-la-transcripción",
    "href": "posts/transcribe-messi-using-whisper/index.html#genero-la-transcripción",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Genero la transcripción",
    "text": "Genero la transcripción\n\n\nCódigo\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#incrusto-la-transcripción-en-el-video-como-subtítulos",
    "href": "posts/transcribe-messi-using-whisper/index.html#incrusto-la-transcripción-en-el-video-como-subtítulos",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Incrusto la transcripción en el video como subtítulos",
    "text": "Incrusto la transcripción en el video como subtítulos\n\n\nCódigo\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n\nAquí el producto final, el video con los subtítulos:"
  },
  {
    "objectID": "posts/stem-book-recommendations/index.html",
    "href": "posts/stem-book-recommendations/index.html",
    "title": "STEM Book Recommendations",
    "section": "",
    "text": "Recomendaciones de libros STEM que me gustaron (sin ningún orden en particular)\n\n“The Innovators” - Walter Isaacson\n\nEste libro explora las vidas y contribuciones de los pioneros detrás de las grandes innovaciones tecnológicas del último siglo. Desde Ada Lovelace hasta los creadores de la web, Isaacson traza una línea clara entre la colaboración humana y los avances tecnológicos. Es una lectura imprescindible para quienes buscan entender cómo la interacción entre ciencia y creatividad ha dado forma a la era digital actual. Recomendado para quienes deseen una inmersión en la historia de la tecnología.\n“A Brief History of Artificial Intelligence” - Michael Wooldridge\n\nWooldridge ofrece una visión accesible y bien fundamentada sobre la evolución de la IA, desde sus inicios en la década de 1950 hasta los desarrollos más recientes. Es una excelente introducción para quienes buscan un enfoque académico pero accesible sobre la historia y las implicancias éticas de la inteligencia artificial. Recomendado para cualquier interesado en cómo la IA ha llegado a donde está hoy.\n“A Brief History of Time” - Stephen W. Hawking\n\nUn clásico de la divulgación científica, este libro de Hawking plantea algunas de las preguntas más fundamentales sobre el universo: desde la naturaleza del tiempo hasta la posibilidad de universos paralelos. Aunque es conocido por su complejidad, Hawking logra presentar conceptos difíciles de una forma comprensible para el lector promedio. Altamente recomendado para quienes buscan expandir su comprensión del cosmos.\n“Weapons of Math Destruction” - Cathy O’Neil\n\nEn este libro, O’Neal analiza el lado oscuro de los algoritmos y cómo, lejos de ser neutrales, pueden exacerbar las desigualdades sociales y económicas. Su crítica apunta a sistemas que impactan negativamente en sectores como la educación, las finanzas y la justicia penal. Recomendado para quienes están interesados en la ética de los algoritmos y el impacto social de la tecnología.\n“Permanent Record” - Edward Snowden\n\nUn relato fascinante desde la perspectiva de Snowden, el famoso denunciante que expuso el programa de vigilancia masiva del gobierno de EE.UU. El libro explora cuestiones clave sobre la privacidad, la seguridad digital y el poder gubernamental. Recomendado para quienes desean una visión crítica y personal de los temas contemporáneos de ciberseguridad y privacidad.\n“The Idea Factory” - Jon Gertner\n\nGertner detalla la historia del laboratorio Bell Labs, el lugar donde se inventaron algunas de las tecnologías más revolucionarias del siglo XX, como el transistor y la fibra óptica. El libro destaca cómo el entorno de colaboración fue clave para estos avances. Recomendado para quienes estén interesados en la historia de la innovación tecnológica.\n“A Mind at Play” - Jimmy Soni\n\nEsta biografía de Claude Shannon, el padre de la teoría de la información, ofrece un relato fascinante sobre uno de los intelectuales más influyentes del siglo XX. Shannon no solo cambió la forma en que entendemos la información, sino que sentó las bases para la revolución digital. Recomendado para aquellos interesados en los orígenes de la teoría de la información y su impacto actual.\n“Everybody Lies” - Seth Stephens-Davidowitz\n\nStephens-Davidowitz utiliza los datos masivos (big data) para revelar cómo las búsquedas en Google y otras fuentes online pueden mostrar lo que realmente piensan y sienten las personas. Es una lectura provocadora que desafía nuestras nociones sobre la privacidad, los prejuicios y el comportamiento humano. Recomendado para quienes buscan una mirada innovadora al uso de datos en la sociedad actual.\n“Fermat’s Last Theorem” - Simon Singh\n\nUn clásico de la divulgación matemática, este libro narra la resolución del problema que mantuvo en vilo a los matemáticos durante siglos. Singh convierte esta historia en un apasionante thriller académico que combina historia, matemáticas y un desafío intelectual. Recomendado para aficionados a las matemáticas y a quienes disfrutan de las historias de superación intelectual."
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n\n\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:25: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:28: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib import cm\nimport matplotlib as mpl\n\n# cmap = cm.coolwarm\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\n\n\n\n\nestab_agro_refefo_gpd.head()\n\n\n\n\n\n\n\n\ncuit\nsucursal\nanio\nlat\nlon\nclae6\nin_departamentos\nprovincia_id\nquintil\nempleo\n...\nCUICOM\nNivAcc\nLocalidad\nDepartamen\nProvincia\nOPERAT\nOBSERV\nLongitud\nLatitud\ndistance\n\n\n\n\n2\n41X8684801PW69\n1\n2021\n-31.831\n-68.538\n13019\n70070\n70\n0\na. 1-9\n...\n116000998\n\nTupeli\n25 de Mayo\nSan Juan\nConectado\nReFeFO\n-68.355148\n-31.835497\n20363.518228\n\n\n6\n8ZXA578022006P\n1\n2021\n-35.707\n-61.852\n14113\n6609\n6\n0\na. 1-9\n...\n116000747\n\nPehuajo\nPehuajo\nBuenos Aires\nConectado\nReFeFO\n-61.886181\n-35.808664\n14455.869113\n\n\n7\n55X57A24220Z03\n1\n2021\n-27.467\n-58.801\n14113\n18021\n18\n0\na. 1-9\n...\n116000280\n\nCorrientes\nCapital\nCorrientes\nConectado\nReFeFO\n-58.853519\n-27.473892\n5910.026706\n\n\n8\n62XA5Z5532016P\n1\n2021\n-36.805\n-63.338\n14113\n6007\n6\n0\na. 1-9\n...\n116000851\n\nSalliquelo\nSalliqueló\nBuenos Aires\nConectado\nReFeFO\n-62.960400\n-36.751767\n42680.380667\n\n\n11\n02X7181Z420J70\n1\n2021\n-33.812\n-59.501\n14610\n6070\n6\n0\na. 1-9\n...\n116000103\n\nBaradero\nBaradero\nBuenos Aires\nConectado\nReFeFO\n-59.509570\n-33.810287\n981.225711\n\n\n\n\n5 rows × 25 columns\n\n\n\n\nestab_agro_refefo_gpd['distance'].describe()\n\ncount    139032.000000\nmean      25544.488222\nstd       43024.509877\nmin          10.732621\n25%        2012.328661\n50%        8579.902917\n75%       35895.504459\nmax      607665.364021\nName: distance, dtype: float64"
  },
  {
    "objectID": "posts/on-regulatory-simplification/index.html",
    "href": "posts/on-regulatory-simplification/index.html",
    "title": "On Regulatory Simplification",
    "section": "",
    "text": "En el último Internet Day, organizado por la Cámara Argentina de Internet (CABASE) los pasados 17 y 18 de mayo, uno de los temas que se discutió fue sobre simplificación regulatoria. Cómo podemos acercarnos a esta cuestión desde el análisis de datos? Una forma es a través del análisis de grafos.\nDe acuerdo al Ente Nacional de Comunicaciones (ENACOM), existen 357 normas fundamentales que regulan al sector de las TIC en Argentina. Por otro lado, Infoleg, el sistema de información normativa y documental de la República Argentina, publica en formato abierto datos sobre la totalidad de las normas vigentes en el país en tres conjuntos de datos: una base de normas, una base de normas modificadas y una base de normas modificatorias (aquí normas modificatorias y modificadas son consideradas en sentido amplio, es decir, incluyen normas complementarias, reglamentarias, etc.).\nPero qué tiene que ver esto con la teoría de grafos? Un grafo es una estructura de datos consistente en un conjunto de nodos y un conjunto de aristas que los conectan. Estas aristas pueden ser dirigidas (aquellas donde la relación va en un sentido pero no en el otro) o no dirigidas (aquellas donde la relación va en ambos sentidos). En el caso de las normas, podemos pensar en un grafo donde los nodos son las normas y las aristas son las relaciones entre ellas.\nEn primer lugar, voy a leer los datos y cargarlos en una base de datos Neo4j, que es una base de datos de grafos.\n\n\nCódigo\nimport pandas as pd\nfrom neo4j import GraphDatabase\nimport os\n\nnormas_fundamentales_tic = pd.read_csv(\"normas_fundamentales_tic.csv\")\nnormas_modificatorias_tic = pd.read_csv(\"normas_modificatorias_tic.csv\")\n\n# Configurar la conexión a Neo4j\nuri = \"bolt://localhost:7687\"  # Ajusta según la configuración de tu Neo4j\nusername = os.getenv(\"NEO4J_USER\")\npassword = os.getenv(\"NEO4J_PASS\")\n\ndriver = GraphDatabase.driver(uri, auth=(username, password))\n\ndef create_nodes_and_relationships(tx, normas_fundamentales_tic, normas_modificatorias_tic):\n    # Crear nodos para normas fundamentales\n    for index, row in normas_fundamentales_tic.iterrows():\n        tx.run(\"MERGE (n:Norma {id: $id, titulo: $titulo, grupo: $grupo, link: $link, notas: $notas, tipo: 'fundamental', boletin_oficial: $boletin_oficial})\",\n               id=row['id_norma'], titulo=row['norma'], grupo=row['grupo'], link=row['link'], notas=row['notas'], boletin_oficial=row['boletin_oficial'])\n    \n    # Crear relaciones \"modifica a\" o \"es modificada por\"\n    for index, row in normas_modificatorias_tic.iterrows():\n        tx.run(\"\"\"\n        MATCH (a:Norma {id: $id_modificatoria}), (b:Norma {id: $id_modificada})\n        MERGE (a)-[:MODIFICA_A]-&gt;(b)\n        \"\"\", id_modificatoria=row['id_norma_modificatoria'], id_modificada=row['id_norma_modificada'])\n\n# Ejecutar la función en una sesión\nwith driver.session() as session:\n    session.execute_write(create_nodes_and_relationships, normas_fundamentales_tic, normas_modificatorias_tic)\n\ndriver.close()\n\n\nVeamos ahora cómo se ve el grafo.\nLa Figura 1 muestra el grafo de las normas fundamentales y modificatorias del sector TIC en Argentina. La Figura 2 es un zoom de una parte del grafo para poder visualizar mejor las relaciones entre las normas.\nPero qué podemos hacer con este grafo? Qué preguntas interesantes podemos responder?\n\n\n\n\n\n\nFigura 1: Grafo de normas fundamentales y modificatorias\n\n\n\n\n\n\n\n\n\nFigura 2: Zoom al grafo de normas fundamentales y modificatorias\n\n\n\nUna pregunta interesante podría ser: cuáles son las 10 normas fundamentales que más fueron modificadas o complementadas por otras normas?\n\n\n\n\n\n\nNota\n\n\n\nNeo4j utiliza un lenguaje de consultas que se llama Cypher. La pregunta anterior se puede responder con la consulta de Cypher que se muestra a continuación.\n\n\nMATCH (n:Norma)-[:MODIFICA_A]-&gt;(m)\nRETURN m.titulo, COUNT(n) AS num_modificaciones\nORDER BY num_modificaciones DESC\nLIMIT 10\n\n\n\n\n\n\nFigura 3: Tabla de normas fundamentales que más fueron modificadas o complementadas\n\n\n\nAquí el ranking lo encabezan el Decreto 764/2000, la Ley Argentina Digital, el Decreto 267/2015 que, entre otras cosas, creó el ENACOM, y la Ley de Servicios de Comunicación Audiovisual."
  },
  {
    "objectID": "posts/internet-submarine-cables/index.html",
    "href": "posts/internet-submarine-cables/index.html",
    "title": "Internet Submarine Cables",
    "section": "",
    "text": "Hace un tiempo Tyler Morgan-Wall hizo una visualizacón de los todos los cables submarinos de internet con los datos de Telegeography.\nTyler publicó el código en este gist. Yo decidí reproducir la visualización con una pequeña modificación para agregarle un título y hacer girar a la tierra para el otro lado.\nAcá va la modificación al último for loop para agregar el título:\n\nfor(i in seq(1,720,by=1)) {\n  tmp &lt;- group_objects(fullcablescene,scale=c(1,1,1)*1.02) %&gt;% \n    add_object(sphere(radius=0.99,material=diffuse(image_texture = \"2k_earth_daymap.jpg\"),angle=c(0,-90,0))) %&gt;% \n    group_objects(angle=c(0,-i/2,0)) %&gt;% \n    add_object(sphere(y=5,z=5,x=5,material=light(intensity = 80,color=\"lightblue\"))) %&gt;% \n    add_object(sphere(y=5,z=5,x=-5,material=light(intensity = 10,color=\"orange\"))) %&gt;% \n    add_object(sphere(y=-10,material=light(intensity = 3,color=\"white\"))) %&gt;%\n    render_scene(samples=64,width=1200,height=1200,fov=0,aperture=0, ortho_dimensions = c(2.3,2.3),\n                 sample_method = \"sobol_blue\",parallel = TRUE,return_raw_array = TRUE)\n  rayimage::add_title(image = tmp,\n                      title_text = \"https://martinolmos.github.io/datos_tic/\",\n                      title_color = \"orange\",\n                      title_position = \"north\",\n                      filename = sprintf(\"imgs/smallcables%d.png\",i))\n}\n\nY la línea para generar la imagen animada girando para el otro lado:\n\nav::av_encode_video(sprintf(\"imgs/smallcables%d.png\", seq(720,1,by=-1)), \n                    framerate = 30, \n                    output = \"cables.mp4\")\n\nY finalmente la visualización con mis pequeñas modificaciones al código:\n\nVideo"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html",
    "href": "posts/ict-infra-subsidies-analysis/index.html",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "",
    "text": "En Argentina, como en muchos otros países, existe un fondo constituido con aportes de las empresas del sector TIC con el objetivo de llevar los servicios a poblaciones que no pueden acceder a ellos por distintos motivos. En este post, participé de un panel donde hablé sobre la historia de este fondo en Argentina, denominado Fondo Fiduciario de Servicio Universal (FFSU), su marco normativo y los distintos programas que tiene en la actualidad.\nEn este post, voy a hacer un pequeño análisis exploratorio de los algunos datos de los dos programas más importantes del FFSU: el Programa Conectividad y el Programa Barrios Populares. El análisis abarco los años entre 2020 y 2023, para los cuales se cuenta con datos. Los datos fueron extraídos de las Actas de Directorio del Ente Nacional de Comunicaciones (ENACOM), que se publican en PDF en la página web del organismo."
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#programa-conectividad",
    "href": "posts/ict-infra-subsidies-analysis/index.html#programa-conectividad",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Programa Conectividad",
    "text": "Programa Conectividad\n\n\nCódigo\n# Me conecto a la base de datos y leo la tabla del Programa Conectividad\n# Connect to the database and read the Conectividad Program table\n\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine\nimport os\nimport pandas as pd\n\nload_dotenv()\n\nhost = os.getenv(\"HOST\")\nport = os.getenv(\"PORT\")\ndatabase = os.getenv(\"DBNAME\")\nuser = os.getenv(\"USER\")\npassword = os.getenv(\"PASSWD\")\n\nengine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n\nanr_prog_con = pd.read_sql_table(table_name=\"conectividad_aprob_georef\", con=engine)\n\n\nLa Figura 1 muestra la cantidad de localidades beneficiarias de ANRs del Programa Conectividad aprobados por provincia, entre 2020 y 2023.\n\n\nCódigo\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_con.groupby(\"provincia_indec\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigura 1: Localidades beneficiarias de ANRs del Prog. Conectividad por provincia\n\n\n\nLa Figura 2 muestra la cantidad de localidades beneficiarias de ANRs del Programa Conectividad por año.\n\n\nCódigo\nanr_prog_con['anio'] = anr_prog_con['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_con.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigura 2: Localidades beneficiarias de ANRs del Prog. Conectividad por año\n\n\n\nLa Figura 3 muestra la cantidad de localidades beneficiarias de ANRs del Programa Conectividad por año y provincia.\n\n\nCódigo\nimport textwrap\n\nanr_prog_con_prov_anio = anr_prog_con.groupby(['anio', 'provincia_indec']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(4,1)\n\nfor i, anio in enumerate(anr_prog_con_prov_anio.index):\n    anr_prog_con_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigura 3: Localidades beneficiarias de ANRs del Prog. Conectividad por año y provincia"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#programa-barrios-populares",
    "href": "posts/ict-infra-subsidies-analysis/index.html#programa-barrios-populares",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Programa Barrios Populares",
    "text": "Programa Barrios Populares\n\n\nCódigo\n# Me conecto a la base de datos y leo la tabla del Programa Barrios Populares\n# Connect to the database and read the Barrios Populares Program table\n\nimport geopandas as gpd\n\nanr_prog_renabap = gpd.read_postgis(\"SELECT * FROM renabap_aprob\", con=engine, geom_col=\"geometry\")\n\n\nLa Figura 4 muestra la cantidad de barrios beneficiados por ANRs del Programa Barrios Populares por provincia, entre 2021, año en que comienza la ejecución del programa, y 2023.\n\n\nCódigo\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_renabap.groupby(\"provincia\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigura 4: Barrios beneficiados con ANRs del Prog. Barrios Populares por provincia\n\n\n\nLa Figura 5 muestra la cantidad de barrios beneficiados con ANRs del Programa Barrios Populares por año.\n\n\nCódigo\nanr_prog_renabap['anio'] = anr_prog_renabap['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_renabap.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigura 5: Barrios beneficiados con ANRs del Prog. Barrios Populares aprobados por año\n\n\n\nLa Figura 6 muestra la cantidad de barrios beneficiados por ANRs del Programa Barrios Populares por año y provincia.\n\n\nCódigo\nimport textwrap\n\nanr_prog_renabap_prov_anio = anr_prog_renabap.groupby(['anio', 'provincia']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(3,1)\n\nfor i, anio in enumerate(anr_prog_renabap_prov_anio.index):\n    anr_prog_renabap_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigura 6: Barrios beneficiados por ANRs del Prog. Barrios Populares aprobados por año y provincia\n\n\n\nMas allá de estos gráficos sobre la cantidad de localidades y barrios vulnerables beneficiados sería interesante hacer un análisis sobre el impacto de estos programas en la conectividad de las poblaciones beneficiarias. Intentaremos aproximarnos a esta cuestión en un próximo post."
  },
  {
    "objectID": "posts/ict-companies-social-network-analysis/index.html",
    "href": "posts/ict-companies-social-network-analysis/index.html",
    "title": "ICT Companies Social Network Analysis",
    "section": "",
    "text": "El Procesamiento de Lenguaje Natural o PLN es el campo de estudio sobre el análisis computacional del lenguaje humano. Esta área de conomiento incluye una variedad muy amplia de técnicas y aplicaciones. Una de ellas, dentro del ámbito del análisis y comprensión del lenguaje, es el Análisis de Sentimientos, una aplicación que permite clasificar un texto de acuerdo a su carga o polaridad positiva, negativa o neutra.\nAquí veremos como con unas pocas líneas de código python uno puede:\n\nConectarse a la API de Twitter\nDescargar los últimos twitts en los que se menciona a determinadas empresas TIC\nUtilizar un modelo de machine learning pre-entrenado para realizar el análisis de sentimientos de los twitts\nVisualizar el análisis\n\nEl modelo pre-entrenado que vamos a utilizar es RoBERTuito, un modelo entrenado con 500 millones de tweets en Español. Los autores del paper/modelo lo disponibilizaron en forma gratuita a través de la plataforma HuggingFace y librería pysentimiento para facilitar la investigación y las aplicaciones de PLN en Español.\nAclaración 1: es natural y esperable que las menciones a las empresas en redes tengan un sesgo negativo, ya que es uno de los canales para hacer llegar reclamos y por tratarse de un servicio pago no es habitual que la conformidad con el servicio redunde en menciones positivas.\nAclaración 2: para acceder a los tweets con las menciones es necesario primero tramitar credenciales de autenticación en Twitter for Developers. Las mismas estarán guardadas en un archivo llamado search_tweets_creds.yml con la siguiente forma:\nsearch_tweets_api:\n    bearer_token: MY_BEARER_TOKEN\n    endpoint: https://api.twitter.com/2/tweets/search/recent\nPara adquirir los tweets utilizaré la librería searchtweets-v2, un Cliente de Python para la Versión 2 de la API de Twitter.\nCon el siguiente código me autentico y requiero los últimos 100 tweets que mencionan a cada una de las empresas que nos interesan:\n\nfrom searchtweets import load_credentials, ResultStream, gen_request_parameters, collect_results\n\nsearch_args = load_credentials(filename=\"search_tweets_creds.yml\", \n                               yaml_key=\"search_tweets_api\",\n                               env_overwrite=False)\n\nempresas = [\"Telecentro\", \"MovistarArg\", \"ClaroArgentina\", \"PersonalAr\"]\nempresas_tweets = dict()\n\nfor empresa in empresas:\n    query = gen_request_parameters(empresa, results_per_call=100, granularity=None)\n    tweets = collect_results(query,\n                             max_tweets=100,\n                             result_stream_args=search_args)\n    empresas_tweets[empresa] = tweets[0]['data']\n\nPreproceso los tweets, aplico el análisis de sentimientos y extraigo la categoría para cada uno de los tweets y empresas:\n\nfrom pysentimiento import create_analyzer\n\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\", model_name=\"pysentimiento/robertuito-sentiment-analysis\")\n\nempresas_tweets_sent = dict()\nempresas_tweets_sent_out = dict()\n\nfor empresa in empresas:\n    empresas_tweets_sent[empresa] = [analyzer.predict(tuit) for tuit in empresas_tweets_proc[empresa]]\n    empresas_tweets_sent_out[empresa] = [tuit.output for tuit in empresas_tweets_sent[empresa]]\n\nVisualizo los resultados:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nempresas_tweets_sent_count = dict()\nfig, axes = plt.subplots(2, 2, figsize=(8, 6),dpi=144)\n\nplt.suptitle(\"Análisis de Sentimientos de Empresas TIC\")\n\narray_index = [(0,0), (0,1), (1,0), (1,1)]\naxes_title_font_size = 10\n\nfor empresa, index in zip(empresas, array_index):\n    empresas_tweets_sent_count[empresa] = np.unique(empresas_tweets_sent_out[empresa], return_counts=True)\n    axes[index].pie(empresas_tweets_sent_count[empresa][1], labels=empresas_tweets_sent_count[empresa][0], wedgeprops=dict(width=.5), autopct='%1.f%%')\n    axes[index].set_title(empresa, fontsize=axes_title_font_size)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html",
    "href": "posts/cumbre-ia/index.html",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "",
    "text": "El pasado 3 y 4 de octubre en Montevideo, Uruguay, se llevó a cabo la 2da Cumbre Ministerial y de Altas Autoridades sobre la Ética en la Inteligencia Artificial en América Latina y el Caribe. En la misma se discutieron los desafíos y oportunidades que presenta la IA en la región, así como los principios éticos que deberían guiar su desarrollo y aplicación.\nAquí se puede acceder el programa completo de la cumbre y a la transmisión en vivo de las exposiciones. En este marco, se aprobó la Declaración de Montevideo y la Hoja de Ruta 2024-2025\nPara los que no pudieron seguir el evento en vivo y no tienen tiempo para ver el video completo, aquí vamos a mostrar cómo se puede transcribir y resumir automáticamente el contenido de un video utilizando servicios de IA, en este caso las APIs de AWS Transcribe y OpenAI."
  },
  {
    "objectID": "posts/cumbre-ia/index.html#descarga-y-segmentación-del-video-y-audio-de-youtube",
    "href": "posts/cumbre-ia/index.html#descarga-y-segmentación-del-video-y-audio-de-youtube",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Descarga y segmentación del video y audio de youtube",
    "text": "Descarga y segmentación del video y audio de youtube\nPrimero es necesario descargar el video y el audio de la transmisión completa.\n\n\nCódigo\nimport yt_dlp as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=mSnMpzkR2R0'\n\nydl_audio_opts = {\n    'outtmpl': 'data/cumbre_ia_montevideo.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'data/cumbre_ia_montevideo.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\nLuego es necesario segmentar el audio y el video en cada una de los paneles y charlas de la cumbre. A modo de muestra, vamos a extraer el panel de apertura, que va desde el comienzo al minuto 43:15.\n\n\nCódigo\nimport pydub\nfrom moviepy.video.io.VideoFileClip import VideoFileClip\n\nduration = 43.15 * 60.00\n\naudio_segmentado = pydub.AudioSegment.from_file('../data/cumbre_ia_montevideo.mp3', duration=duration)\n\nvideo = VideoFileClip('../data/cumbre_ia_montevideo.webm')\nvideo_segmentado = video.subclip(0, duration)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#transcripción-con-aws-transcribe",
    "href": "posts/cumbre-ia/index.html#transcripción-con-aws-transcribe",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Transcripción con AWS Transcribe",
    "text": "Transcripción con AWS Transcribe\nLa API de AWS Transcribe permite utilizar un vocabulario personalizado para mejorar la precisión de la transcripción de palabras técnicas o específicas de un dominio o nombres propios. Además, permite obtener la transcripción tanto en formato de subtítulos como en texto plano.\n\n\nCódigo\nfrom __future__ import print_function\nimport time\nimport boto3\n\ntranscribe = boto3.client('transcribe', 'us-east-1')\n\njob_name = \"cumbre-ia-montevideo-apertura\"\njob_uri = \"s3://cumbre-ia-montevideo/input-audios/cumbre_ia_montevideo_apertura.mp3\"\n\ntranscribe.start_transcription_job(\n    TranscriptionJobName = job_name,\n    Media = {\n        'MediaFileUri': job_uri\n    },\n    OutputBucketName = 'cumbre-ia-montevideo',\n    OutputKey = 'output-transcriptions/', \n    LanguageCode = 'es-US', \n    Subtitles = {\n        'Formats': [\n            'vtt','srt'\n        ],\n        'OutputStartIndex': 1 \n   },\n    Settings = {\n        'ShowSpeakerLabels': True,\n        'MaxSpeakerLabels': 5,\n        'VocabularyName': 'cumbre-ia-montevideo-apertura-vocabulario'\n    }    \n)\n\nwhile True:\n    status = transcribe.get_transcription_job(TranscriptionJobName = job_name)\n    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n        break\n    print(\"Not ready yet...\")\n    time.sleep(5)\nprint(status)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#incrustar-los-subtítulos-en-el-video",
    "href": "posts/cumbre-ia/index.html#incrustar-los-subtítulos-en-el-video",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Incrustar los subtítulos en el video",
    "text": "Incrustar los subtítulos en el video\nLuego incrustamos los subtítulos en el video.\n\n\nCódigo\nfrom moviepy.editor import CompositeVideoClip\nfrom moviepy.video.tools.subtitles import SubtitlesClip\nfrom moviepy.video.fx.resize import resize\nimport moviepy.editor as mp\n\n# Load subtitles from an SRT file\n# You can adjust the font size, font type, etc.\ngenerator = lambda txt: mp.TextClip(txt, font='Arial', fontsize=48, color='white')\n\n# Create the SubtitlesClip\nsubtitles = SubtitlesClip(\"../data/cumbre-ia-montevideo-apertura.srt\", generator)\n\n# Overlay the subtitles on the video\nvideo_with_subtitles = CompositeVideoClip([video_segmentado, subtitles.set_position(('center', 'bottom'))])\n\n# Write the final video file with subtitles embedded\nvideo_with_subtitles.write_videofile(\"../data/cumbre_ia_montevideo_apertura_with_subtitles.mp4\", fps=video.fps)\n\n\nAquí el video de la apertura con los subtítulos incrustados:"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#resumen-automático-con-openai",
    "href": "posts/cumbre-ia/index.html#resumen-automático-con-openai",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Resumen automático con OpenAI",
    "text": "Resumen automático con OpenAI\nAhora vamos a utilizar la API de OpenAI para resumir automáticamente la transcripción de las exposiciones durante la apertura de la cumbre.\nPrimero, es necesario hacer algo de preprocesamiento de las transcripciones.\n\n\nCódigo\nimport boto3\nimport json\n\ns3_client = boto3.client('s3')\n\ntranscripcion = s3_client.get_object(Bucket='cumbre-ia-montevideo', Key='output-transcriptions/cumbre-ia-montevideo-aperura.json')['Body'].read().decode('utf-8')\n\ndata = json.loads(transcripcion)\n\n# Extraer las etiquetas de orador y las palabras\nitems = data['results']['items']\nspeaker_labels = data['results']['speaker_labels']['segments']\n\ntranscripcion_por_orador = []\n\n# Crear una estructura para mantener las intervenciones agrupadas\ncurrent_speaker = None\ncurrent_segment = []\n\nfor segment in speaker_labels:\n    speaker = segment['speaker_label']\n    start_time = float(segment['start_time'])\n    end_time = float(segment['end_time'])\n    \n    if current_speaker is None or current_speaker != speaker:\n        # Guardar la intervención anterior antes de cambiar de orador\n        if current_segment:\n            transcripcion_por_orador.append({\n                \"orador\": current_speaker,\n                \"texto\": \" \".join(current_segment)\n            })\n        # Empezar un nuevo segmento\n        current_speaker = speaker\n        current_segment = []\n\n    # Extraer las palabras dentro del rango de tiempo del segmento actual\n    for item in items:\n        if 'start_time' in item:\n            word_time = float(item['start_time'])\n            if start_time &lt;= word_time &lt; end_time:\n                current_segment.append(item['alternatives'][0]['content'])\n\n# Añadir la última intervención\nif current_segment:\n    transcripcion_por_orador.append({\n        \"orador\": current_speaker,\n        \"texto\": \" \".join(current_segment)\n    })\n\n\ntranscripcion_por_orador_sin_presentador = [intervencion for intervencion in transcripcion_por_orador if intervencion['orador'] != 'spk_0']\n\n\nLuego, enviamos el texto de las intervenciones a OpenAI para obtener un resumen de cada exposición.\n\n\nCódigo\nfrom dotenv import load_dotenv\nimport openai\n\nload_dotenv()\n\nsintesis_transcripciones = []\n\nfor i in range(len(transcripcion_por_orador_sin_presentador)):\n    prompt = f\"\"\"\n    Estoy realizando una síntesis de las exposiciones en la 2da Cumbre Ministerial y de Altas Autoridades sobre la Ética en la Inteligencia Artificial. \\\n    La misma se realizó el pasado 3 y 4 de octubre en Montevideo, Uruguay. \\\n    En este caso, toca resumir la transcripción del panel {panel}, integrado por {''.join(oradores)}. \\\n    Procura corregir los errores de transcripción, sobre todo en los nombres propios. \\\n    Devuelve sólo el resumen de la transcripción, sin comentarios adicionales. \\\n    A continuación, la transcripción completa de la exposición de {oradores[i]}: \\\n    {transcripcion_por_orador_sin_presentador[i]['texto']}\n    \"\"\"\n    response = openai.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1000\n    )\n    assistant_response = response.choices[0].message.content\n    sintesis_transcripciones.append({'orador': oradores[i], 'sintesis_exposicion': assistant_response})\n\n\nFinalmente, mostramos los resúmenes de las exposiciones.\n\n\nCódigo\nfrom IPython.display import display, Markdown\n\nfor sintesis in sintesis_transcripciones:\n    display(Markdown(f\"### {sintesis['orador']}:\\n\\n{sintesis['sintesis_exposicion']}\"))\n\n\n\nBeatriz Argimón, Vicepresidenta de la República Oriental del Uruguay:\nBeatriz Argimón, Vicepresidenta de la República Oriental del Uruguay, expresó su entusiasmo por participar en la apertura de la 2da Cumbre Ministerial sobre la Ética en la Inteligencia Artificial. Destacó la importancia de los debates éticos y el protagonismo que deben asumir aquellos con responsabilidades, sobre todo en un país con alta adhesión democrática como Uruguay. Señaló la relevancia de proteger los derechos humanos y las democracias frente a los cambios vertiginosos de la inteligencia artificial.\nArgimón enfatizó la necesidad de un enfoque regional unido en América Latina y el Caribe para avanzar en el ámbito global y subrayó la importancia de enfrentar los desafíos con responsabilidad ética. Expresó su orgullo por las políticas de Estado de Uruguay, independientes del partido político gobernante, y elogió el papel de AGESIC y Hebert Paguas en la creación de una conciencia estratégica en el ámbito público.\nFinalmente, habló sobre la responsabilidad democrática de informar y educar a la ciudadanía sobre estos nuevos tiempos y agradeció a los organizadores de la cumbre por promover el entendimiento de que estos tiempos, aunque desafiantes, también son esperanzadores.\n\n\nChristian Asinelli, Vicepresidente Corporativo de Programación Estratégica, CAF -banco de desarrollo de América Latina y el Caribe-:\nEn la 2da Cumbre Ministerial y de Altas Autoridades sobre la Ética en la Inteligencia Artificial, celebrada en Montevideo, Uruguay, el discurso de apertura de Christian Asinelli, Vicepresidente Corporativo de Programación Estratégica de CAF -banco de desarrollo de América Latina y el Caribe-, abordó varios puntos clave:\nChristian Asinelli resaltó la importancia de abordar los problemas globales con soluciones regionales, especialmente en el ámbito de la inteligencia artificial (IA) y otras áreas como la energía y la alimentación. Destacó el esfuerzo conjunto con la UNESCO para implementar políticas públicas de IA y mencionó la anterior Cumbre de Ética de la Inteligencia Artificial en Chile, donde se lanzó la Declaración de Santiago. Asinelli expresó la expectativa de que la Declaración de Montevideo continúe avanzando en capacidades regionales.\nAdemás, Asinelli enfatizó la necesidad de una transición justa e inclusiva en América Latina y el Caribe, considerando las capacidades fiscales y la pobreza en la región, y subrayó los riesgos de la IA, incluyendo derechos humanos, transparencia y democracia. Destacó la colaboración con diferentes organizaciones y la intención de crear una hoja de ruta con un enfoque holístico que sitúe al ser humano en el centro de las políticas públicas de IA. También mencionó la importancia de los espacios de diálogo y reflexión durante la cumbre para promover una IA al servicio de la comunidad.\nEn conclusión, Asinelli agradeció los esfuerzos conjuntos del gobierno de Uruguay, la UNESCO y todos los involucrados en la organización de esta cumbre, proyectando que será un evento significativo en el desarrollo de la IA ética en la región.\n\n\nGabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas, UNESCO:\nEn su intervención, Gabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas de la UNESCO, agradeció al Gobierno de Uruguay y a los participantes de la cumbre por la oportunidad de discutir temas relevantes sobre la ética en la inteligencia artificial. Resaltó la importancia de América Latina en definir su propio destino tecnológico y enfatizó que el proceso involucra no solo aspectos tecnológicos, sino sociales, económicos y de visión para el desarrollo sostenible.\nMencionó que el proceso iniciado con el Consenso de Santiago ha sido destacado a nivel internacional y subrayó la necesidad de seguir avanzando con nuevas etapas, como las planificadas para la República Dominicana. Ramos destacó los retos y logros de los países en sus hojas de ruta (RAM), señalando el éxito de Uruguay en diversas áreas como la protección de datos y la energía renovable.\nRamos enfatizó el crecimiento significativo de la inversión global en inteligencia artificial y la necesidad de que las tecnologías sirvan para resolver problemas humanos. Asimismo, instó a los países de América Latina a incrementar sus inversiones en investigación y desarrollo, sugiriendo que un aumento del PIB dedicado a este sector podría impulsar el crecimiento económico y social.\nFinalmente, subrayó la importancia de la ética en el desarrollo tecnológico y el papel de las competencias humanas, proponiendo una educación que fomente el pensamiento crítico y la inclusión de humanidades en programas tecnológicos. Concluyó reiterando el compromiso de la UNESCO de trabajar conjuntamente con las naciones de la región para aprovechar la inteligencia artificial de manera inclusiva y beneficiosa.\n\n\nHebert Paguas, Director Ejecutivo de AGESIC:\nHebert Paguas, Director Ejecutivo de AGESIC, comenzó su intervención en la Cumbre reflexionando sobre el reto de abordar el ritmo acelerado de los cambios tecnológicos, especialmente en comparación con la lentitud de los procesos legislativos tradicionales. Subrayó que aunque la inteligencia artificial (IA) se definió por primera vez en 1956, el debate significativo sobre su influencia apenas tomó auge en 2022 con la aparición de la inteligencia artificial generativa, que simula una conversación humana. Paguas expresó su deseo de que la tecnología no llegue a suplantar la esencia humana, diferenciando a los humanos como “Homo Viator”, seres en constante viaje y búsqueda de madurez.\nAdemás, destacó la importancia de la colaboración regional e internacional para enfrentar los desafíos que surgen en el entorno digital, donde los límites territoriales de la legislación se vuelven obsoletos. Citó la necesidad de coordinación internacional similar a la que ocurre en el mundo físico con convenios como los de extradición, ahora trasladados al ámbito digital.\nPaguas también mencionó el Pacto Global Digital y enfatizó tanto en los beneficios potenciales de la tecnología como en los riesgos aún desconocidos que conlleva. Agradeció a organizaciones como la UNESCO y la CAF por su apoyo logístico y esfuerzo colaborativo en el evento, y concluyó destacando la importancia de que Uruguay se posicione como un polo de innovación, resaltando el rol necesario del sector privado y la preparación del sector público para enfrentar los retos presentes y futuros."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "",
    "text": "Nota: para aquellos interesados en el código utilizado para generar cada visualización, pueden verlo haciendo clic en el botón “Mostrar/Ocultar Todo el Código” en la parte superior derecha de la página o en el botón “Código” que se encuentra arriba y a la derecha de cada visualización."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#día-3---polígonos",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#día-3---polígonos",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Día 3 - Polígonos",
    "text": "Día 3 - Polígonos\nLas celdas de red móvil pueden ser modeladas utilizando Diagramas de Voronoi. Típicamente, esto se hace para análisis de movilidad con datos de señalización celular, como se muestra en este paper.\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#día-4---hexágonos",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#día-4---hexágonos",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Día 4 - Hexágonos",
    "text": "Día 4 - Hexágonos\nLos hexágonos se pueden utilizar también para graficar las radiobases 4G, utilizando la intensidad del color para mostrar su densidad.\n\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "title": "Datos y TICs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "href": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "You Only Look Once\n\n\nYou Only Look Once\n\n\n\ncomputer-vision\n\n\ndeep-learning\n\n\npython\n\n\nyolo\n\n\nultralytics\n\n\n\n\n\n\n\n\n\n11 ene 2026\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models in Spanish\n\n\nModelos de Lenguaje en Español\n\n\n\nAI\n\n\nLLM\n\n\nHugging Face\n\n\n\n\n\n\n\n\n\n18 dic 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nMinisterial Summit on the Ethics of AI in LAC\n\n\nCumbre Ministerial sobre la Ética de la IA en LAC\n\n\n\nAI\n\n\nAWS\n\n\nOpenAI\n\n\n\n\n\n\n\n\n\n17 nov 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nSTEM Movie Recommendations\n\n\nRecomendaciones de películas STEM\n\n\n\nPelículas\n\n\nMovies\n\n\nSeries\n\n\nSTEM\n\n\n\n\n\n\n\n\n\n30 sept 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nSTEM Book Recommendations\n\n\nRecomendaciones de libros STEM\n\n\n\nLibros\n\n\nBooks\n\n\nSTEM\n\n\n\n\n\n\n\n\n\n22 sept 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nOn Regulatory Simplification\n\n\nSobre Simplificación Regulatoria\n\n\n\nAnálisis de Grafos\n\n\nGraph Analysis\n\n\n\n\n\n\n\n\n\n24 jul 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Infrastructure Subsidies Analysis\n\n\nAnálisis de Subsidios para Infraestructura TIC\n\n\n\nANR\n\n\n\n\n\n\n\n\n\n26 abr 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nREFEFO Potential to Enhance Productive Connectivity\n\n\nEl Potencial de la REFEFO para Mejorar la Conectividad Productiva\n\n\n\nREFEFO\n\n\nProductive Connectivity\n\n\n\n\n\n\n\n\n\n26 abr 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Whisper to Transcribe Messi\n\n\nTranscribir a Messi con Whisper\n\n\n\nNLP\n\n\nIA\n\n\nML\n\n\nPython\n\n\nMessi\n\n\n\n\n\n\n\n\n\n3 feb 2023\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nBeckham vs. Papu Gomez\n\n\nBeckham vs. Papu Gomez\n\n\n\n\n\n\n\n\n\n\n\n8 ene 2023\n\n\n\n\n\n\n\n\n\n\n\n\nForum on Equality and the Digital Divide\n\n\nForo Brechas y Equidad Digital\n\n\n\n\n\n\n\n\n\n\n\n17 jun 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Companies Social Network Analysis\n\n\nAnálisis de Empresas TIC en Redes Sociales\n\n\n\nNLP\n\n\nsocial networks\n\n\n\n\n\n\n\n\n\n20 abr 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Fix Access Dashboard for Argentina\n\n\nTablero de Accesos Fijos a Internet en Argentina\n\n\n\n\n\n\n\n\n\n\n\n12 abr 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Satellite Images\n\n\nUsando Imágenes Satelitales\n\n\n\n\n\n\n\n\n\n\n\n19 mar 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Prices Evolution\n\n\nEvolución de los precios\n\n\n\n\n\n\n\n\n\n\n\n7 feb 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Submarine Cables\n\n\nCables Submarinos de Internet\n\n\n\n\n\n\n\n\n\n\n\n6 feb 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Day Map Challenge Day 3 and 4\n\n\nDía 3 y 4 del Desafío de Mapas de 30 Días\n\n\n\n\n\n\n\n\n\n\n\n9 nov 2021\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Days Map Challenge Day 1 and 2\n\n\n30 Days Map Challenge Día 1 y 2\n\n\n\n\n\n\n\n\n6 nov 2021\n\n\nMartin Olmos\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Código\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\nfrom datetime import date\n\ntoday = date.today().strftime(\"%d/%m/%Y\")\n\n# Activity data\nfechas = [\n    (\"01/09/2024\", today, \"CAF: Ejecutivo Principal de la Dirección de Transformación Digital\", \"Experiencia profesional\"),\n    (\"01/09/2023\", \"01/05/2024\", \"BID: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/03/2023\", \"31/12/2023\", \"BNMC: Consultor asociado\", \"Experiencia profesional\"),\n    (\"01/02/2023\", \"01/03/2024\", \"CAF: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/07/2022\", \"01/12/2023\", \"UNSAM: Docente en Gobierno Abierto y Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/06/2021\", \"31/12/2023\", \"PELI: Docente en Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/04/2023\", \"31/12/2023\", \"ITBA: Maestría en Ciencia de Datos\", \"Formación académica\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Subsecretario de TICs\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Especialización en Ciencia de Datos\", \"Formación académica\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Director Ejecutivo\", \"Experiencia profesional\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Formación académica\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Jefe Regional de Ciudad de Buenos Aires\", \"Experiencia profesional\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Experiencia profesional\": \"lightskyblue\",\n    \"Actividad docente\": \"palegreen\",\n    \"Formación académica\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Año')\nplt.title('Línea de Tiempo CV Martin Olmos')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nSoy licenciado en Ciencias Políticas (UCA), Magister en Políticas Públicas (George Washington University), Especialista y Maestrando en Ciencia de Datos (ITBA).\n\nFORMACIÓN ACADÉMICA\n2023 MAESTRÍA EN CIENCIA DE DATOS\n(Tesis en elaboración)\nInstituto Tecnológico de Buenos Aires (ITBA)\n2018 ESPECIALIZACIÓN EN CIENCIA DE DATOS\nInstituto Tecnológico de Buenos Aires (ITBA)\n2016 MASTER IN PUBLIC POLICY\nTrachtenberg School of Public Policy and Public Administration\nGeorge Washington University\n2003 LICENCIATURA EN CIENCIAS POLÍTICAS, CON ORIENTACIÓN EN PROCESOS POLÍTICOS\nFacultad de Ciencias Políticas y Relaciones Internacionales. Pontificia Universidad Católica Argentina. Buenos Aires, Argentina.\n\n\nANTECEDENTES PROFESIONALES Y DOCENTES\n9/2023- 4/2024 BANCO INTERAMERICANO DE DESARROLLO Responsabilidad: Consultor en Ciencia de Datos y TICs\n3/2023- 12/2023 BLUENOTE MANAGEMENT CONSULTING Responsabilidad: Consultor asociado\n2/2023- 2/2024 CAF BANCO DE DESARROLLO DE AMÉRICA LATINA Y EL CARIBE Responsabilidad: Consultor en Ciencia de Datos y TICs\n7/2022- 12/2023 DIPLOMATURA EN GESTIÓN DE CIUDADES - ESCUELA DE ECONOMÍA Y NEGOCIOS – UNIVERSIDAD NACIONAL DE SAN MARTÍN\nResponsabilidad: Docente en Gobierno Abierto y Nuevas Tecnologías\n12/2019-03/2022 SUBSECRETARIO DE TECNOLOGÍAS DE LA INFORMACIÓN Y LAS COMUNICACIONES DE LA JEFATURA DE MINISTROS DE LA NACIÓN\n6/2021-9/2021 PROGRAMA EJECUTIVO EN LIDERAZGO INNOVADOR – OEI, ILES, SECRETARÍA DE ASUNTOS ESTRATÉGICOS DE LA REPÚBLICA ARGENTINA\nResponsabilidad: Docente en Nuevas Tecnologías\n4/2017-11/2019 INSTITUTO CIUDAD – POLÍTICAS PÚBLICAS PARA BUENOS AIRES\nResponsabilidad: Director Ejecutivo\n8/2019-12/2019 SEMINARIO DE INTRODUCCIÓN A LA CIENCIA DE DATOS PARA LAS CIENCIAS SOCIALES – FACULTAD DE CIENCIAS SOCIALES (UBA)\nResponsabilidad: Docente\n2/2019-actualidad THE CARPENTRIES – DATA CARPENTRY\nResponsabilidad: Instructor\n7/2018-11/2019 DIRECCIÓN DE IMPLEMENTACIÓN Y SEGUIMIENTO SUBE – MINISTERIO DE TRANSPORTE DE LA NACIÓN\nResponsabilidad: Consultor en Ciencia de Datos\n8/2018-6/2019 SECRETARÍA DE ASUNTOS PÚBLICOS – MUNICIPALIDAD DE SAN MIGUEL\nResponsabilidad: Consultor en Ciencia de Datos\n2/2018-8/2018 ORGANISMO PROVINCIAL PARA EL DESARROLLO SOSTENIBLE\nResponsabilidad: Consultor en Ciencia de Datos\n1/2017-6/2018 CONVENIO MINISTERIO DE TRANSPORTE-UNSAM\nResponsabilidad: Consultor en Ciencia de Datos\n5/2015-12/2016 BANCO DE DESARROLLO DE AMÉRICA LATINA (CAF)\nResponsabilidad: Consultor en Ciencia de Datos\n11/2009-12/2014 ADMINISTRACIÓN NACIONAL DE LA SEGURIDAD SOCIAL\nResponsabilidad: Jefe Regional de Ciudad de Buenos Aires.\n\n\nBECAS Y DISTINCIONES\n2016 BECA ORGANIZACIÓN DE ESTADOS AMERICANOS (OEA) PARA ESTUDIOS DE POSGRADO.\n2015 GLOBAL LEADERS FELLOWSHIP 2015-2016 , GEORGE WASHINGTON UNIVERSITY.\n2015 BECA FULBRIGHT DE MAESTRÍA 2015-2016 , COMISIÓN FULBRIGHT ARGENTINA.\n2013 IV FORO “EL FUTURO DE AMÉRICA LATINA: LA VISIÓN DE LOS JÓVENES LÍDERES” , CAF – BANCO DE DESARROLLO DE AMÉRICA LATINA A PARTICIPAR, CIUDAD DE MÉXICO, 22 Y 23 DE AGOSTO DE 2013.\n2013 PROGRAMA DE GOBIERNO PARA EL DESARROLLO DE LÍDERES DE COMUNIDADES LOCALES. CENTRO DE ESTUDIOS EN GOBIERNO, EMPRESA, SOCIEDAD Y ECONOMÍA, IAE BUSINESS SCHOOL, UNIVERSIDAD AUSTRAL, PILAR, PROVINCIA DE BUENOS AIRES, MAYO Y JUNIO DE 2013. BECA OTORGADA POR LA FUNDACIÓN RAP (RED DE ACCIÓN POLÍTICA).\n2005 PROGRAMA FURP- USA, AUSTIN Y WASHINGTON DC, ESTADOS UNIDOS DE AMÉRICA. FEBRERO DE 2005.\n\n\nPARTICIPACIÓN EN ACTIVIDADES Y CONFERENCIAS INTERNACIONALES\n\nJunio 2022\n\nOrganizadores | Cámara Chilena de Infraestructura Digital y Asociación Chilena de Municipalidades\nEvento | Foro Brechas y Equidad Digital\nPanel | Los fondos de acceso universal en la Región\n\nMarzo 2022\n\nOrganizador | GSMA\nEvento | Ministerial Programme - Mobile World Congress (MWC)\n\nFebrero 2022\n\nOrganizador | Unión Internacional Telecomunicaciones (ITU)\nEvento | 4th Global Standards Symposium\nTema | Normas Internacionales para Potenciar la Transformación Digital\n\nNoviembre 2021\n\nOrganizador | Forum Europe (Forum Global)\nEvento | Latin America Spectrum Management Conference\nTema | The Emerging Shape of the 6GHz Band\n\nJunio 2021\n\nOrganizador | GSMA\nEvento | Spectrum Roundtable at the Ministerial Programme - Mobile World Congress (MWC)\nTema | The Future of Spectrum Access\n\nNoviembre 2020\n\nOrganizador | Forum Europe (Forum Global)\nEvento | Latam Spectrum Conference\nTema | Bridging the Digital Divide – How Has Covid Shone a Light on Digital Inequalities and How Can the Region Move Forward in Tackling This Issue?\n\nOctubre 2020\n\nOrganizador | International Institute of Communications\nTema | Digital Transformation Post COVID-19: LatAm Responses to the Digital Divide.\n\nJulio 2020\n\nOrganizador | ITU, GeSI & the United Nations Office for South South Cooperation.\nTema | Accelerating Action and Transformative Pathways for Delivering on the Sustainable Development Goals and Recovery from COVID-19 Pandemic.\n\n\nPARTICIPACIÓN EN ACTIVIDADES Y CONFERENCIAS NACIONALES\n\nMayo 2021\n\nOrganizador | CABASE\nEvento | Internet Day\nTema | Iniciativas de desarrollo de la infraestructura de internet para la universalización de la conectividad\nOrganizador | ISOC Capítulo Argentina y Facultad de Ingeniería de Universidad de Palermo\nEvento | 5tas Jornadas sobre Perspectivas de las Telecomunicaciones y TICs 2021\nTema | Desafíos Actuales de las Telecomunicaciones\n\nAbril 2021\n\nOrganizador | Grupo Convergencia\nEvento | NPlay Cono Sur\nTema | Los Planes para Reducir la Brecha Digital y Compartición de Infraestructura\n\nDiciembre 2020\n\nOrganizador | Grupo Convergencia\nTema | Infraestructura y despliegue de red para crecer en la nueva normalidad.\nOrganizador | Internet Governance Forum (IGF)\nTema | Gobernanza de Algoritmos e Inteligencia Artificial\n\nAgosto 2020 – Marzo 2022\n\nOrganizador | BID - INTAL\nPrograma | Proyecto Regional Programa de Integración de la Economía Digital para Latinoamérica y el Caribe\nPosición | Miembro del Consejo Directivo"
  },
  {
    "objectID": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "",
    "text": "Nota: para aquellos interesados en el código con el que se generó cada visualización pueden verlo presionando el botón “Show/Hide All Code” arriba a la derecha de la página o el botón “Code” arriba y a la derecha de cada visualización.\nEl #30daymapchallenge es un desafío de mapeo/cartografía/visualización de datos impulsado por la comunidad de ciencia de datos. La idea es publicar mapas basados en un desafío diario durante 30 días usando el hashtag #30daymapchallenge.\nAquí están los temas diarios para los desafíos de este año:\nEn particular, voy a enfocarme (cuando pueda) en datos relacionados con las TIC.\nEmpecemos con los desafíos de los días 1 (puntos) y 2 (líneas)."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#día-1---puntos",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#día-1---puntos",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Día 1 - Puntos",
    "text": "Día 1 - Puntos\nNodos de conexión a la Red Federal de Fibra Óptica (REFEFO) de ARSAT. /\nLa REFEFO es una red troncal de fibra óptica. En los puntos o nodos de conexión los proveedores de internet o ISPs se conectan para llevar internet a los hogares.\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(sf)\nsf_use_s2(FALSE)\nlibrary(httr)\n\nprovincias_ign &lt;- read_sf(\"https://wms.ign.gob.ar/geoserver/ows?service=wfs&version=1.1.0&request=GetFeature&typeNames=ign:provincia&outputFormat=application/json\")\n\nif(sum(!st_is_valid(provincias_ign)) &gt; 0) {\n  provincias_ign &lt;- st_make_valid(provincias_ign)\n}\n\nprovincias_ign &lt;- st_crop(x = provincias_ign,\n                          y = st_bbox(obj = c(xmin=-76.36532,\n                                              ymin=-56.75009,\n                                              xmax=-51.20850,\n                                              ymax=-20.91625)))\n\nnodos_refefo &lt;- read.csv2(\"https://datos.arsat.com.ar/dataset/8f0b4da0-a40d-4b2b-8fe0-dac06d64152a/resource/15713af0-f384-44c5-8397-c8050162312d/download/puntos-conexion-red-federal-de-fibra-optica-2021-12-01_v1.csv\", fileEncoding = \"LATIN1\")\n\nnodos_refefo &lt;- nodos_refefo %&gt;%\n  na.omit() %&gt;%\n  st_as_sf(crs = 4326, coords=c(\"Longitud\", \"Latitud\"), remove=FALSE)\n\nnodos_refefo &lt;- st_crop(x = nodos_refefo,\n                        y = st_bbox(obj = c(xmin=-76.36532,\n                                            ymin=-56.75009,\n                                            xmax=-51.20850,\n                                            ymax=-20.91625)))\n\nprovincias_ign %&gt;% \n  ggplot() + \n  geom_sf() +\n  geom_sf(data = nodos_refefo, color = \"#2ca25f\", size = 0.5) +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.datos.gob.ar / Source: www.datos.gob.ar\")"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#día-2---líneas",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#día-2---líneas",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Día 2 - Líneas",
    "text": "Día 2 - Líneas\nTraza de la REFEFO. La fibra óptica de la REFEFO en general va enterrada al lado de rutas nacionales y provinciales, conectando distintas localidades pequeñas y medianas, donde no llegan otros proveedores o hay uno sólo y por lo tanto no se dan condiciones de competencia.\n\n\nCódigo\nidecom_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\nrefefo_query &lt;- list(service=\"wfs\",\n                     version=\"1.3.0\",\n                     request=\"GetFeature\",\n                     typeNames=\"publico:FO118-TZFO-REDFIBRAOPTICA-5-2\",\n                     CQL_FILTER=\"OBSERV='ARSAT - ReFeFO'\",\n                     outputFormat=\"application/json\")\n\nidecom_url &lt;- modify_url(url = idecom_base_url, \n                         query = refefo_query)\n\ntraza_refefo_idecom &lt;- read_sf(idecom_url)\n\nprovincias_ign %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_sf(data = traza_refefo_idecom, colour=\"#2b8cbe\") +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.idecom.gob.ar / Source: www.idecom.gob.ar\")"
  },
  {
    "objectID": "posts/beckham-vs-papu-gomez/index.html",
    "href": "posts/beckham-vs-papu-gomez/index.html",
    "title": "Beckham vs. Papu Gomez",
    "section": "",
    "text": "Este post no es sobre TICs. Es sobre el uso de IA para clasificaar imágenes. En este caso tomamos una controversia que se planteó durante del mundial en un stream del Kun Aguero, donde Lio Messi y el Papu Gomez le piden al Kun que adivine a quién se parece el Papu, luego de su nuevo corte de pelo.\n\n\n\n\nA partir de ahí quedó la controversia. Se parece el Papu Gomez a David Beckham? Es por eso que decidí entrenar un modelo de IA para clasificar imágenes de ambos jugadores. Tengo que decir que a partir de esto llegué a la conclusión que algún parecido tienen, ya que tuve que ir pasando de modelos más simples a más complejos para que aprenda a distinguir bien entre los dos.\nPueden probar la aplicación a continuación o en el siguiente link"
  },
  {
    "objectID": "posts/forum-equality-digital-divide/index.html",
    "href": "posts/forum-equality-digital-divide/index.html",
    "title": "Forum on Equality and the Digital Divide",
    "section": "",
    "text": "El pasado 9 y 10 de junio se realizó el Foro Brechas y Equidad Digital. En ese marco me invitaron a exponer en el panel “Los Fondos de Acceso Universal en la Región: el caso de Argentina.\nAquí dejo el video completo de mi participación:\n\n\n\nvideo\n\n\nY mi presentación:"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/etl.html",
    "href": "posts/ict-infra-subsidies-analysis/etl.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "from dotenv import load_dotenv\n\nload_dotenv('../../.env', override=True)\n\nTrue\n\n\n\nfrom sqlalchemy import create_engine\nimport os\n\nhost = os.getenv(\"HOST\")\nport = os.getenv(\"PORT\")\n# database = os.getenv(\"DBNAME\")\ndatabase = \"anr\"\nuser = os.getenv(\"USER\")\npassword = os.getenv(\"PASSWD\")\n\n\n\nengine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n\n\nimport pandas as pd\n\nanr_prog_con = pd.read_sql_table(table_name=\"conectividad_aprob_georef\", con=engine)\n\n\nanr_prog_con.drop_duplicates(inplace=True, ignore_index=True)\n\n\nanr_prog_con.columns\n\nIndex(['acta', 'tipo', 'exp', 'razon_social', 'cuit', 'programa', 'monto',\n       'lugar', 'file', 'acta_nro', 'prog_original', 'acta_file', 'fecha',\n       'provincia', 'localidad', 'departamento', 'id', 'localidad_indec',\n       'departamento_indec', 'provincia_indec', 'lat', 'lon'],\n      dtype='object')\n\n\n\nanr_prog_con.head()\n\n\n\n\n\n\n\n\nacta\ntipo\nexp\nrazon_social\ncuit\nprograma\nmonto\nlugar\nfile\nacta_nro\n...\nfecha\nprovincia\nlocalidad\ndepartamento\nid\nlocalidad_indec\ndepartamento_indec\nprovincia_indec\nlat\nlon\n\n\n\n\n0\nEX-2019-45180205-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-45180205-APN-DNFYD#ENACOM\nSEBE CABLE SOCIEDAD DE RESPONSABILIDAD LIMITADA\n3.064501e+10\nPROGRAMA CONECTIVIDAD\n2261577.0\nLocalidad de Juan A. Pradere, departamento de ...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nBuenos Aires\nJuan A Pradere\nPatagones\n06602050000\nJUAN A. PRADERE\nPatagones\nBuenos Aires\n-39.599380\n-62.651047\n\n\n1\nEX-2019-57002814-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-57002814-APN-DNFYD#ENACOM\nVIDEO CABLE TOTAL S.A.\n3.070783e+10\nPROGRAMA CONECTIVIDAD\n9874019.0\nLocalidad de Teodelina, departamento de Genera...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nSanta Fe\nTeodelina\nGeneral Lopez\n82042280000\nTEODELINA\nGeneral López\nSanta Fe\n-34.191613\n-61.527226\n\n\n2\nEX-2019-88343739-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-88343739-APN-DNFYD#ENACOM\nCOOPERATIVA DE SERVICIOS PÚBLICOS DEL CAMPILLO...\n3.054579e+10\nPROGRAMA CONECTIVIDAD\n8848620.0\nLocalidad de Del Campillo, del departamento de...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nCórdoba\nDel Campillo\nGral Roca\n14035010000\nDEL CAMPILLO\nGeneral Roca\nCórdoba\n-34.376085\n-64.494540\n\n\n3\nEX-2019-81016814-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-81016814-APN-DNFYD#ENACOM\nCOOPERATIVA DE OBRAS Y SERVICIOS PÚBLICOS MONJ...\n3.056536e+10\nPROGRAMA CONECTIVIDAD\n2661583.0\nLocalidad de Monje, departamento de San Jeróni...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nSanta Fe\nMonje\nSan Jerónimo\n82105200000\nMONJE\nSan Jerónimo\nSanta Fe\n-32.358736\n-60.942904\n\n\n4\nEX-2019-77479546-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-77479546-APN-DNFYD#ENACOM\nTELE IMAGEN PRIVADA S.A.\n3.070886e+10\nPROGRAMA CONECTIVIDAD\n5218974.0\nLocalidad de Villa Ascasubi, departamento de T...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nCórdoba\nVilla Ascasubi\nTercero Arriba\n14161170000\nVILLA ASCASUBI\nTercero Arriba\nCórdoba\n-32.164358\n-63.892559\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nanr_prog_con_simple = anr_prog_con[['fecha', 'id']]\n\n\nanr_prog_con_simple.loc[anr_prog_con_simple['fecha']=='junio', 'fecha'] = 'junio 2022' \n\n\nmeses = {'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04', 'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08', 'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'}\n\nanr_prog_con_simple['mes'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[0])\nanr_prog_con_simple['mes'] = anr_prog_con_simple['mes'].map(meses)\nanr_prog_con_simple['anio'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[1])\nanr_prog_con_simple['fecha_alt'] = anr_prog_con_simple['anio'] + '-' + anr_prog_con_simple['mes'] + '-01'\nanr_prog_con_simple['fecha_alt'] = pd.to_datetime(anr_prog_con_simple['fecha_alt'])\n\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['mes'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[0])\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['mes'] = anr_prog_con_simple['mes'].map(meses)\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['anio'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[1])\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['fecha_alt'] = anr_prog_con_simple['anio'] + '-' + anr_prog_con_simple['mes'] + '-01'\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['fecha_alt'] = pd.to_datetime(anr_prog_con_simple['fecha_alt'])\n\n\n\nanr_prog_con_simple['fecha'].unique()\n\narray(['enero 2020', 'julio 2020', 'febrero 2020', 'abril 2020',\n       'mayo 2020', 'agosto 2020', 'octubre 2020', 'noviembre 2020',\n       'febrero 2021', 'abril 2021', 'junio 2021', 'agosto 2021',\n       'octubre 2021', 'noviembre 2021', 'diciembre 2021', 'febrero 2022',\n       'mayo 2022', 'junio', 'agosto 2022', 'septiembre 2022',\n       'noviembre 2022', 'diciembre 2022', 'marzo 2023', 'abril 2022',\n       'mayo 2023', 'junio 2023', 'agosto 2023', 'octubre 2023',\n       'noviembre 2023'], dtype=object)\n\n\n\nanr_prog_con.loc[anr_prog_con['fecha']=='junio', 'acta_file']\n\n100    Acta 79 - junio.pdf\n101    Acta 79 - junio.pdf\n102    Acta 79 - junio.pdf\n103    Acta 79 - junio.pdf\n104    Acta 79 - junio.pdf\nName: acta_file, dtype: object\n\n\n\nanr_prog_con_simple['link'] = anr_prog_con_simple['id'].apply(lambda x: x[:-3] if x is not None else None)\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2617043581.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['link'] = anr_prog_con_simple['id'].apply(lambda x: x[:-3] if x is not None else None)\n\n\n\nanr_prog_con_simple.head()\n\n\n\n\n\n\n\n\nfecha\nid\nmes\nanio\nfecha_alt\nlink\n\n\n\n\n0\nenero 2020\n06602050000\n01\n2020\n2020-01-01\n06602050\n\n\n1\nenero 2020\n82042280000\n01\n2020\n2020-01-01\n82042280\n\n\n2\nenero 2020\n14035010000\n01\n2020\n2020-01-01\n14035010\n\n\n3\nenero 2020\n82105200000\n01\n2020\n2020-01-01\n82105200\n\n\n4\nenero 2020\n14161170000\n01\n2020\n2020-01-01\n14161170\n\n\n\n\n\n\n\n\nanr_prog_con_simple_lag = anr_prog_con_simple.loc[anr_prog_con_simple['fecha_alt'] &lt; '2023-01-01']\n\n\nanr_prog_con_simple.shape, anr_prog_con_simple_lag.shape\n\n((594, 6), (515, 6))\n\n\n\ndatabase2 = \"conectividad_localidad\"\nengine2 = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database2}\")\n\ncon_loc = pd.read_sql_table(table_name=\"con_loc\", con=engine2)\n\n/Users/martinolmos/Documents/py_projects/data_tic/lib/python3.11/site-packages/pandas/io/sql.py:1725: SAWarning: Did not recognize type 'geometry' of column 'geometry'\n  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n\n\n\ncon_loc.columns\n\nIndex(['link', 'codpcia', 'coddpto', 'codloc', 'codpciadpto', 'provincia',\n       'departamento', 'localidad', 'personas', 'hogares', 'geometry',\n       'cambio', 'personas2022', 'hogares_act', 'accesos', 'otros', 'vmd',\n       'ADSL', 'CABLEMODEM', 'DIAL UP', 'FIBRA OPTICA', 'OTROS', 'SATELITAL',\n       'WIMAX', 'WIRELESS', '3G', '4G', 'pen_pob', 'pen_hog'],\n      dtype='object')\n\n\n\ncon_loc_simple = con_loc[['link', 'personas', 'pen_pob', 'vmd']]\n\n\ncon_loc_simple_anr = con_loc_simple.loc[con_loc_simple['link'].isin(anr_prog_con_simple_lag['link'])]\n\n\ncon_loc_simple_elegible = con_loc_simple.loc[con_loc_simple['personas'] &lt; 30000]\n\n\ncon_loc_simple_elegible_sin_anr = con_loc_simple_elegible.loc[~con_loc_simple_elegible['link'].isin(anr_prog_con_simple['link'])]\n\n\ncon_loc_simple.shape, con_loc_simple_elegible.shape, con_loc_simple_elegible_sin_anr.shape, con_loc_simple_anr.shape\n\n((3527, 4), (3355, 4), (2854, 4), (465, 4))\n\n\n\ncon_loc_simple_elegible_sin_anr['pen_pob'].mean(), con_loc_simple_anr['pen_pob'].mean()\n\n(27.391489894477758, 18.36155918758159)\n\n\n\ncon_loc_simple_elegible_sin_anr['pen_pob'].median(), con_loc_simple_anr['pen_pob'].median()\n\n(5.510015155247972, 8.818575156059055)\n\n\n\ncon_loc_simple_elegible_sin_anr['personas'].mean(), con_loc_simple_anr['personas'].mean()\n\n(2497.656271899089, 3126.0717131474103)\n\n\n\ncon_loc_simple_elegible_sin_anr['personas'].median(), con_loc_simple_anr['personas'].median()\n\n(553.5, 1251.0)\n\n\n\n# Calculate the 5th and 95th percentiles\nq_low = con_loc_simple_elegible_sin_anr['pen_pob'].quantile(0.05)\nq_high = con_loc_simple_elegible_sin_anr['pen_pob'].quantile(0.95)\n\n# Filter out the outliers\n# filtered_data = con_loc_simple_elegible_sin_anr[(con_loc_simple_elegible_sin_anr['pen_pob'] &gt; q_low) & (con_loc_simple_elegible_sin_anr['pen_pob'] &lt; q_high)]\nfiltered_data = con_loc_simple_elegible_sin_anr[con_loc_simple_elegible_sin_anr['pen_pob'] &lt; q_high]\n\n# Plot the histogram of the filtered data\nfiltered_data['pen_pob'].hist()\n\n\n\n\n\n\n\n\n\nq_high = con_loc_simple_anr['pen_pob'].quantile(0.95)\n\nfiltered_data_anr = con_loc_simple_anr[con_loc_simple_anr['pen_pob'] &lt; q_high]\n\nfiltered_data_anr['pen_pob'].hist()"
  },
  {
    "objectID": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "href": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "title": "Internet Fix Access Dashboard for Argentina",
    "section": "",
    "text": "Es posible hacer un tablero con datos básicos de accesos fijos en Argentina en forma rápida (unos 30 minutos), con datos abiertos de ENACOM, herramientas open source (en este caso R, Plotly y Flexdashboards pero existen muchas otras) y desplegarlo online en forma gratuita con Github Pages.\nAcá se puede ver el tablero online: https://martinolmos.github.io/tablero_accesos_fijos/\nY a continuación el código para adquirir los datos y generar las visualizaciones.\n\nAccesos Fijos cada 100 Hogares por Provincia\n\n# Penetracion por provincia: accesos cada 100 hogares\npen_prov_hog &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275028/data.csv\", \n                         n_max = 24, \n                         locale = locale(decimal_mark = \",\"))\n\npen_prov_hog_plot &lt;- pen_prov_hog %&gt;% \n  ggplot(aes(x = reorder(Provincia, `Accesos por cada 100 hogares`),\n             y = `Accesos por cada 100 hogares`,\n             text = Provincia)) +\n  geom_col(data=pen_prov_hog, aes(x=reorder(Provincia, `Accesos por cada 100 hogares`)), fill = \"red\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.text.y = element_text(size = 6), axis.title = element_blank())\n\nggplotly(pen_prov_hog_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de Accesos cada 100 habitantes\n\n# Penetración: accesos cada 100 habitantes. Serie histórica\npen_nac_hab_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/281491/data.csv\",\n                              locale = locale(decimal_mark = \",\"))\n\npen_nac_hab_serie_plot &lt;- pen_nac_hab_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Accesos por cada 100 hab`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title = element_blank())\n\nggplotly(pen_nac_hab_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de la Velocidad Media de Descarga\n\n# Velocidad Media de Descarga (Mbps) - Nacional\nvmd_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275016/data.csv\", col_names = c(\"Año\", \"Trimestre\", \"Velocidad Media de Descarga\", \"Periodo\"), skip = 1,\n                          locale = locale(decimal_mark = \",\"))\n\nvmd_nac_serie_plot &lt;- vmd_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Velocidad Media de Descarga`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  labs(y = \"VMD en Mbps\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title.x = element_blank())\n\nggplotly(vmd_nac_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de Accesos Fijos por Tecnología\n\ntec_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275029/data.csv\",\n                          locale = locale(decimal_mark = \",\"))\n\ntec_nac_serie &lt;- tec_nac_serie %&gt;% \n  select(-Total) %&gt;% \n  gather(Tecnología, Accesos, ADSL:Otros)\n\ntec_nac_serie_plot &lt;- tec_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = Accesos,\n             group = Tecnología,\n             color = Tecnología,\n             text = Periodo)) +\n  geom_line() +\n  scale_y_continuous(labels = c(\"0\", \"2M\", \"4M\", \"6M\")) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), \n        axis.title = element_blank(), \n        legend.title = element_blank())\n\nggplotly(tec_nac_serie_plot, tooltip = c(\"text\", \"color\", \"y\")) %&gt;% \n  layout(legend = list(title = \"\", \n                       orientation = \"h\",\n                       y = 1.3))"
  },
  {
    "objectID": "posts/language-models-in-spanish/index.html",
    "href": "posts/language-models-in-spanish/index.html",
    "title": "Language Models in Spanish",
    "section": "",
    "text": "Uno de los temas discutido durante la 2da Reunión Ministerial sobre Ética en la IA en LAC fue la necesidad en que la región avance en el desarrollo de modelos de lenguaje en idiomas iberoamericanos, en particular en español.\nUno de los principales Hubs de modelos de IA generativa es Hugging Face, que ofrece una API para acceder y hostear modelos pre-entrenados, datasets y “Spaces” (espacios donde se hostean aplicaciones web basadas en los modelos existentes en el Hub).DS_Store\nPodemos aprovechar la API de Hugging Face para analizar la cantidad, calidad y uso de modelos, datasets y Spaces en español y comprarlos con otros idiomas como el inglés.\n\n\nCódigo\nfrom huggingface_hub import HfApi\n\napi = HfApi()\nmodels = api.list_models()\nmodels_es = api.list_models(filter=\"es\")\n\n\nVeamos en primer lugar cuántos modelos hay en Huggingface Hub y cuántos de ellos son en español.\n\n\nCódigo\nmodels_list = list(models)\nlen(models_list)\n\n\n1191400\n\n\nCódigo\nmodels_es_list = list(models_es)\nlen(models_es_list)\n\n\n6444\nVemos que actualmente existen 1191400 modelos en el Hub, de los cuales 6444 son en español.\nTomemos ahora uno de los modelos para ver qué metadatos hay disponibles.\n\n\nCódigo\nm = models_list[500]\nm.__dict__\n\n\n{'id': 'mistralai/Mistral-Large-Instruct-2411',\n 'author': None,\n 'sha': None,\n 'last_modified': None,\n 'created_at': datetime.datetime(2024, 11, 14, 20, 3, 52, tzinfo=datetime.timezone.utc),\n 'private': False,\n 'gated': None,\n 'disabled': None,\n 'downloads': 488732,\n 'downloads_all_time': None,\n 'likes': 165,\n 'library_name': 'vllm',\n 'gguf': None,\n 'inference': None,\n 'tags': ['vllm',\n  'safetensors',\n  'mistral',\n  'en',\n  'fr',\n  'de',\n  'es',\n  'it',\n  'pt',\n  'zh',\n  'ja',\n  'ru',\n  'ko',\n  'license:other',\n  'region:us'],\n 'pipeline_tag': None,\n 'mask_token': None,\n 'trending_score': 5,\n 'card_data': None,\n 'widget_data': None,\n 'model_index': None,\n 'config': None,\n 'transformers_info': None,\n 'siblings': None,\n 'spaces': None,\n 'safetensors': None,\n 'security_repo_status': None,\n 'lastModified': None,\n 'cardData': None,\n 'transformersInfo': None,\n '_id': '673657a8517b82b436cb7e4c',\n 'modelId': 'mistralai/Mistral-Large-Instruct-2411'}\nVemos que dentro del campo tags hay etiquetas que indican el lenguaje en código ISO 639-1. Podemos usar estas etiquetas para analizar los datos por lenguaje.\nPrimero entonces voy a bajar un dataset de los códigos ISO 639-1.\n\n\nCódigo\nimport pandas as pd\n\niso_639_url = \"https://raw.githubusercontent.com/datasets/language-codes/refs/heads/main/data/language-codes.csv\"\niso_639 = pd.read_csv(iso_639_url)\nprint(iso_639.head())\n\n\n  alpha2    English\n0     aa       Afar\n1     ab  Abkhazian\n2     ae    Avestan\n3     af  Afrikaans\n4     ak       Akan\nAhora para cada modelo de mi lista de modelos y de modelos en español, voy a crear un atributo languages y asignarle los códigos ISO 639-1 que encuentre en el campo tags.\n\n\nCódigo\nfor m in models_list:\n    m.languages = [l for l in m.tags if l in iso_639[\"alpha2\"].values]\n\nfor m in models_es_list:\n    m.languages = [l for l in m.tags if l in iso_639[\"alpha2\"].values]\n\n\nVeamos cuántos modelos tienen al menos una etiqueta de lenguaje.\n\n\nCódigo\nlanguages = [m.languages for m in models_list if len(m.languages) &gt; 0]\nlanguages_es = [m.languages for m in models_es_list]\n\nlen(languages), len(languages_es)\n\n\n(143924, 6444)\nDel total de modelos, sólo 143924 tienen al menos una etiqueta de lenguaje. De estos, 6444 son en español.\n\n\nCódigo\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import ScalarFormatter\n\n# Make a bar plot of len(models_list), len(languages) and len(languages_es)\nplt.bar([\"Total de modelos\", \"Modelos con etiqueta de lenguaje\", \"Modelos en español\"], [len(models_list), len(languages), len(languages_es)])\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\n# Add a title\nplt.title(\"Cantidad de modelos en Hugging Face Hub por lenguaje\")\n\n# Disable scientific notation\nplt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\nplt.gca().ticklabel_format(style='plain', axis='y')\n\n# Show the plot\nplt.show()\n\n\n\nOtra pregunta interesante es cuántos modelos son en español “puro”, es decir, que no tienen etiquetas de otros idiomas.\n\n\nCódigo\nmodels_es_only_list = [m for m in models_es_list if len(m.languages) == 1]\nlen(models_es_only_list)\n\n\n1568\nLos modelos sólo en español son 1568.\nVeamos ahora métricas de calidad, como la cantidad de likes y descargas de los modelos en español, comparados con los de otros idiomas.\n\n\nCódigo\nlikes = [m.likes for m in models_list]\nlikes_es = [m.likes for m in models_es_only_list]\ndownloads = [m.downloads for m in models_list]\ndownloads_es = [m.downloads for m in models_es_only_list]\n\n\n\n\nCódigo\nlen(likes), likes.count(0), likes.count(1)\n\n\n(1191400, 1092628, 49002)\nDel total de 1191400 modelos, 1092628 tienen 0 likes y 49002 tienen un like.\n\n\nCódigo\nlikes_dist = {\"Min\": np.min(likes), \"25%\": np.quantile(likes, 0.25), \"Median\": np.median(likes), \"Mean\": np.mean(likes), \"75%\": np.quantile(likes, 0.75), \"90%\": np.quantile(likes, 0.9), \"95%\": np.quantile(likes, .95), \"99%\": np.quantile(likes, .99)}\n\n\n\n\nCódigo\nplt.bar(likes_dist.keys(), likes_dist.values())\n\nplt.title(\"Distribución de likes en modelos de Hugging Face Hub\")\n\nplt.show()\n\n\n\nComo se aprecia en el gráfico, el 90% de los modelos tienen 0 likes, el 95% tienen 0 o 1 like y el 99% 11 likes o menos.\nDetengámonos sobre los que tienen mayor cantidad de likes.\n\n\nCódigo\nplt.bar([\"Modelos con más de 100 likes\", \"Modelos con más de 500 likes\", \"Modelos con más de 1000 likes\", \"Modelos con más de 3000\", \"Modelos con más de 5000 likes\"], [len([l for l in likes if l &gt; 100]), len([l for l in likes if l &gt; 500]), len([l for l in likes if l &gt; 1000]), len([l for l in likes if l &gt; 3000]), len([l for l in likes if l &gt; 5000])])\n\nplt.title(\"Cantidad de modelos con más de X likes en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\nVeamos ahora qué ocurre con los modelos que son sólo en español.\n\n\nCódigo\nlen(likes_es), likes_es.count(0), likes_es.count(1)\n\n\n(1568, 1138, 166)\nDel total de 1568 modelos que son sólo en español, 1138 tienen 0 likes y 430 tienen un like.\n\n\nCódigo\nlikes_es_dist = {\"Min\": np.min(likes_es), \"25%\": np.quantile(likes_es, 0.25), \"Median\": np.median(likes_es), \"Mean\": np.mean(likes_es), \"75%\": np.quantile(likes_es, 0.75), \"90%\": np.quantile(likes_es, 0.9), \"95%\": np.quantile(likes_es, .95), \"99%\": np.quantile(likes_es, .99)}\n\n\n\n\nCódigo\nplt.bar(likes_es_dist.keys(), likes_es_dist.values())\n\nplt.title(\"Distribución de likes en modelos sólo en español de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(likes_es_dist)\n\n\n{'Min': np.int64(0), '25%': np.float64(0.0), 'Median': np.float64(0.0), 'Mean': np.float64(1.5012755102040816), '75%': np.float64(1.0), '90%': np.float64(3.0), '95%': np.float64(7.0), '99%': np.float64(27.0)}\nLa media de likes de los modelos sólo en español es de 1.5, el 75% de los modelos tienen 1 like o menos, el 90% tienen 3 likes o menos, el 95% tienen 7 likes o menos y el 99% tienen 27 likes o menos.\nVeamos ahora los modelos sólo en español con mayor cantidad de likes.\n\n\nCódigo\nplt.bar([\"Modelos con más de 150 likes\", \"Modelos con más de 100 likes\", \"Modelos con más de 50 likes\", \"Modelos con más de 20\"], [len([l for l in likes_es if l &gt; 150]), len([l for l in likes_es if l &gt; 100]), len([l for l in likes_es if l &gt; 50]), len([l for l in likes_es if l &gt; 20])])\n\nplt.title(\"Cantidad de modelos sólo en español con más de X likes en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(len([l for l in likes_es if l &gt; 150]), len([l for l in likes_es if l &gt; 100]), len([l for l in likes_es if l &gt; 50]), len([l for l in likes_es if l &gt; 20]))\n\n\n0 1 4 23\nSólo hay un modelo sólo en español con 100 likes o más, mientras que 4 modelos con 50 likes o más y 23 modelos con 20 likes o más.\nVeamos ahora las descargas.\n\n\nCódigo\nlen(downloads), downloads.count(0), downloads.count(1)\n\n\n(1191400, 588526, 26337)\nDel total de 1191400 modelos, 588526 (aproximadamente la mitad) tienen 0 descargas.\n\n\nCódigo\ndl_dist = {\"Min\": np.min(downloads), \"25%\": np.quantile(downloads, 0.25), \"Median\": np.median(downloads), \"Mean\": np.mean(downloads), \"75%\": np.quantile(downloads, 0.75), \"90%\": np.quantile(downloads, 0.9), \"95%\": np.quantile(downloads, .95), \"99%\": np.quantile(downloads, .99)}\n\n\n\n\nCódigo\nplt.bar(dl_dist.keys(), dl_dist.values())\n\nplt.title(\"Distribución de descargas en modelos de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(dl_dist, np.max(downloads))\n\n\n{'Min': np.int64(0), '25%': np.float64(0.0), 'Median': np.float64(1.0), 'Mean': np.float64(1823.2946558670471), '75%': np.float64(11.0), '90%': np.float64(23.0), '95%': np.float64(76.0), '99%': np.float64(1398.0)} 181462888\nLa media de descargas de los modelos es 1823, mientras que la mediana es apenas 1. Esta diferencia tan grande señala que hay unos pocos modelos con una gran cantidad de descargas que hacen que la media sea tan alta.\nEl modelo con mayor cantidad de descargas tiene 181.462.888 descargas. Veamos de cuál es este modelo.\n\n\nCódigo\nplt.bar([\"Modelos con más de 100 mil descargas\", \"Modelos con más de 500 mil descargas\", \"Modelos con más de 1 millón de  descargas\", \"Modelos con más de 10 millones de descargas\", \"Modelos con más de 100 millones de descargas\"], [len([l for l in downloads if l &gt; 100000]), len([l for l in downloads if l &gt; 500000]), len([l for l in downloads if l &gt; 1000000]), len([l for l in downloads if l &gt; 10000000]), len([l for l in downloads if l &gt; 100000000])])\n\nplt.title(\"Cantidad de modelos con más de X descargas en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(len([l for l in downloads if l &gt; 100000]), len([l for l in downloads if l &gt; 500000]), len([l for l in downloads if l &gt; 1000000]), len([l for l in downloads if l &gt; 10000000]), len([l for l in downloads if l &gt; 100000000]))\n\n\n1134 443 273 34 3\nHay 1134 modelos con más de 100 mil descargas, 443 con más de 500 mil descargas, 273 con más de un millón de descargas, 34 con más de 10 millones de descargas y 3 con más de 100 millones de descargas.\nVeamos cuáles son los modelos con más de 10 millones de descargas.\n\n\nCódigo\n[print(f\"Modelo: {m.id}, descargas: {m.downloads}\") for m in models_millon_downloads if m.downloads &gt; 10000000]\n\n\nModelo: nesaorg/benchmark_v0, descargas: 172569176\nModelo: sentence-transformers/all-MiniLM-L6-v2, descargas: 102361718\nModelo: Qwen/Qwen2.5-1.5B-Instruct, descargas: 29787495\nModelo: openai-community/gpt2, descargas: 13635588\nModelo: google-bert/bert-base-uncased, descargas: 69032646\nModelo: openai/clip-vit-large-patch14, descargas: 30593669\nModelo: openai/clip-vit-base-patch32, descargas: 21394717\nModelo: sentence-transformers/all-mpnet-base-v2, descargas: 181462888\nModelo: pyannote/speaker-diarization-3.1, descargas: 11145540\nModelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2, descargas: 10717417\nModelo: pyannote/segmentation-3.0, descargas: 14657651\nModelo: bartowski/Meta-Llama-3.1-8B-Instruct-GGUF, descargas: 10642781\nModelo: FacebookAI/roberta-base, descargas: 16983687\nModelo: sentence-transformers/all-MiniLM-L12-v2, descargas: 10686154\nModelo: openai/clip-vit-large-patch14-336, descargas: 20836111\nModelo: distilbert/distilbert-base-uncased, descargas: 15451802\nModelo: microsoft/resnet-50, descargas: 34636864\nModelo: FacebookAI/xlm-roberta-large, descargas: 71149467\nModelo: google-bert/bert-base-multilingual-uncased, descargas: 12923212\nModelo: FacebookAI/roberta-large, descargas: 14851944\nModelo: FacebookAI/xlm-roberta-base, descargas: 12074140\nModelo: google/electra-base-discriminator, descargas: 10615222\nModelo: google/vit-base-patch16-224-in21k, descargas: 10802933\nModelo: jonatasgrosman/wav2vec2-large-xlsr-53-english, descargas: 20671837\nModelo: openai/clip-vit-base-patch16, descargas: 13014792\nModelo: bigscience/bloomz-560m, descargas: 12417679\nModelo: timm/resnet50.a1_in1k, descargas: 24015981\nModelo: pyannote/wespeaker-voxceleb-resnet34-LM, descargas: 12499697\nModelo: nesaorg/fc_12, descargas: 26749830\nModelo: nesaorg/fc_4, descargas: 19983316\nModelo: nesaorg/fc_6, descargas: 39967060\nModelo: nesaorg/fc_8, descargas: 54180206\nModelo: nesaorg/fc_16, descargas: 12477680\nModelo: distributed/optimized-gpt2-1b, descargas: 25559944\nVeamos ahora las descargas de los modelos sólo en español.\n\n\nCódigo\nprint(len(downloads_es), downloads_es.count(0))\n\n\n1568 248\nDe los 1568 modelos sólo en español, 248 tienen 0 descargas.\n\n\nCódigo\ndl_es_dist = {\"Min\": np.min(downloads_es), \"25%\": np.quantile(downloads_es, 0.25), \"Median\": np.median(downloads_es), \"Mean\": np.mean(downloads_es), \"75%\": np.quantile(downloads_es, 0.75), \"90%\": np.quantile(downloads_es, 0.9), \"95%\": np.quantile(downloads_es, .95), \"99%\": np.quantile(downloads_es, .99)}\n\n\n\n\nCódigo\nplt.bar(dl_es_dist.keys(), dl_es_dist.values())\n\nplt.title(\"Distribución de descargas en modelos sólo en español de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(dl_es_dist)\n\n\n{'Min': np.int64(0), '25%': np.float64(9.0), 'Median': np.float64(15.0), 'Mean': np.float64(2504.596301020408), '75%': np.float64(27.0), '90%': np.float64(99.59999999999991), '95%': np.float64(376.8999999999992), '99%': np.float64(11140.349999999986)}\nLa media de descargas de de los modelos sólo en español es de 2504, mientras que el 95% de los modelos tienen 377 descargas o menos.\n\n\nCódigo\nplt.bar([\"Modelos con más de 1000 descargas\", \"Modelos con más de 5000 descargas\", \"Modelos con más de 10000 descargas\", \"Modelos con más de 100 mil descargas\", \"Modelos con más de 200 mil descargas\", \"Modelos con más de 500 mil descargas\"], [len([l for l in downloads_es if l &gt; 1000]), len([l for l in downloads_es if l &gt; 5000]), len([l for l in downloads_es if l &gt; 10000]), len([l for l in downloads_es if l &gt; 100000]), len([l for l in downloads_es if l &gt; 200000]), len([l for l in downloads_es if l &gt; 500000])])\n\nplt.title(\"Cantidad de modelos sólo en español con más de X descargas en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCódigo\nprint(len([l for l in downloads_es if l &gt; 1000]), len([l for l in downloads_es if l &gt; 5000]), len([l for l in downloads_es if l &gt; 10000]), len([l for l in downloads_es if l &gt; 100000]), len([l for l in downloads_es if l &gt; 200000]), len([l for l in downloads_es if l &gt; 500000]))\n\n\n53 23 17 7 5 2\nVeamos cuáles son los modelos sólo en español con más de 100 mil descargas.\n\n\nCódigo\n[print(f\"Modelo: {m.id}, descargas: {m.downloads}\") for m in models_es_only_list if m.downloads &gt; 100000]\n\n\nModelo: MMG/xlm-roberta-large-ner-spanish, descargas: 657221\nModelo: dccuchile/bert-base-spanish-wwm-uncased, descargas: 458065\nModelo: hiiamsid/sentence_similarity_spanish_es, descargas: 131325\nModelo: pysentimiento/robertuito-emotion-analysis, descargas: 117978\nModelo: pysentimiento/robertuito-sentiment-analysis, descargas: 1111575\nModelo: datificate/gpt2-small-spanish, descargas: 480166\nModelo: finiteautomata/beto-sentiment-analysis, descargas: 461003\n\n\n\n\n\n[None, None, None, None, None, None, None]"
  },
  {
    "objectID": "posts/price-evolution/index.html",
    "href": "posts/price-evolution/index.html",
    "title": "ICT Prices Evolution",
    "section": "",
    "text": "Veamos cuál fue la evolución de los precios de los servicios TIC en Argentina en los últimos años.\nSi tomamos la serie del capítulo de comunicaciones del Índice de Precios al Consumidor del INDEC (IPC-COM) vemos que desde el incio de la serie (Dic-2016=100) las comunicaciones estuvieron por encima del índice general hasta 2020, donde el IPC-COM se ameseta y luego queda por debajo.\n\n\n\nAnalicemos en particular los años 2020 y 2021. Primero 2020: si vemos la variación acumulada anual el IPC-COM se pone por arriba del IPC general con el aumento de marzo que fue parcialmente retrotraído en abril (se retrotrajo el aumento del móvil prepago y de la telefonía fija, no así el móvil pospago y mixto) y luego el IPC se ameseta primero por el acuerdo de precios hasta el 31 de julio y luego por el congelamiento que impuso el DNU 690/2020 hasta el 31 de diciembre.\n\n\n\nVeamos ahora el año 2021:\n\n\n\n\nComo se puede apreciar en los gráficos, tanto 2020 como 2021 fueron años donde los aumentos del sector se ubicaron bien por debajo de los aumentos en el índice general.\nAclaración: de acuerdo al COICOP Argentina, el Capítulo de Comunicaciones del IPC no incluye sólo servicios TIC si no también el precio de los equipos y no incluye precios del servicio de televisión paga, que se encuentran reflejados en el Capítulo de Recreación y Cultura.\nEsto respecto de la evolución. Veamos ahora cómo nos ubicamos respecto de otros países de la región en cuanto a asequibilidad. La Unión Internacional de Telecomunicaciones (UIT) compila estadísticas estandarizadas sobre precios de canastas de precios de servicios fijos y móviles. Algunos ejemplos:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn estas series temporales, Argentina parece estar bien sólo en banda ancha móvil (sólo datos).\nAclaración: estas series temporales sólo incluyen 2018, 2019 y 2020 porque en 2017 hubo un cambio de metodología. Para más información ver aquí."
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "title": "REFEFO Potential to Enhance Productive Connectivity",
    "section": "",
    "text": "La mayoría de los países de la región tienen algún tipo de estrategia más o menos definida y articulada para mejorar la conectvidad digital de las poblaciones vulnerables, aquellas que viven en zonas de baja densidad poblacional donde a veces el sector privado por sí solo no tiene los incentivos para invertir en infraestrutura, o para llevar la conectividad a servicios de educación y salud. Sin embargo, no siempre se ha pensado en la conectividad productiva, es decir, en cómo la conectividad puede mejorar la productividad de las empresas y de los trabajadores.\nUn presupuesto importante para llegar con conectividad a un lugar es que existan redes troncales que permitan luego desarrollar la denominada “última milla” desde estas redes hasta los hogares y empresas. Argentina, por ejemplo, cuenta con la Red Federal de Fibra Óptica (REFEFO) gestionada por ARSAT, que es una red troncal que atraviesa las 23 provincias del país, llegando a unas 1.300 localidades, muchas de las cuales tienen poblaciones de menos de 10.000 habitantes. Por supuesto que existen también redes troncales de fibra óptica de operadores privados, pero el tendido de las mismas y la ubicación de los nodos de conexión no está disponible públicamente.\nPero volviendo al punto anterior, analicemos el potencial de la REFEFO para mejorar la conectividad productiva. Tomemos por ejemplo el sector agropecuario, que es uno de los más importantes de la economía argentina y el mayor generador de divisas.\nPodemos utilizar los datos del ex Ministerio de Desarrollo Productivo para georrefenciar las empresas agropecuarias y calcular la distancia de cada una de ellas al nodo de la REFEFO más cercano y luego analizar la distribución de estas distancias.\nEn primer lugar, obtenemos, filtramos y cruzamos los datos necesarios para el análisis:\n\n\nCódigo\nimport pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n# Cruzo los establecimientos agropecuarios con el nodo de REFEFO más cercano y obtengo la distancia\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\nLuego vamos a plotear en un mapa cada uno de los establecimientos agropecuarios y asignarle un color en función de la distancia con el nodo de la REFEFO más cercano.\n\n\nCódigo\nfrom matplotlib import cm\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\nMapa de Establecimientos Agropecuarios y Distancia a Nodo de REFEFO\n\n\nAdemás, vamos a plotear el histograma de las distancias para poder analizar su distribución.\n\n\nCódigo\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n\n\n\n\nHistograma de Distancias a Nodo de REFEFO\n\n\nComo se puede observar en el mapa y en el histograma, la mayoría de los establecimientos agropecuarios se encuentran a menos de 10 km de un nodo de la REFEFO. Para obtener los números precisos observemos la media y los cuartiles de las distancias.\n\n\nCódigo\nestab_agro_refefo_gpd['distance'].describe()\n\n\nLa media de las distancias de establecimientos agropecuarios al nodo de REFEFO más cercano es de 25.544 metros o 25,5 KMs. Sin embargo, como se observa en el histograma, las distancias no tienen una distribución normal sino que se trata de una distribución asimétrica a la derecha, con la mayor cantidad de distancias con valores bajos y unas pocas distancias con valores muy altos. En estos casos, la mediana es más representativa que la media. Aquí la mediana es de 8.580 metros u 8,6 KMs. Esto quiere decir que el 50% de los establecimientos agropecuarios se encuentran a menos de 8,6 KMs de un nodo de REFEFO. Finalmente, el tercer cuartil es de 35.895 metros o casi 36 KMs, lo que significa que el 75% de los establecimientos agropecuarios se encuentran a menos de 36 KMs de un nodo de REFEFO.\nHay muchas formas de mejorar este análisis preliminar pero esta primera aproximación parece indicar que la distancia a redes troncales no debería ser un impedimento para el desarrollo de la conectividad rural productiva en la Argentina."
  },
  {
    "objectID": "posts/stem-movie-recommendations/index.html",
    "href": "posts/stem-movie-recommendations/index.html",
    "title": "STEM Movie Recommendations",
    "section": "",
    "text": "Breve reseña y recomendación de películas y series STEM, sin orden particular:\n\nEl Código Enigma - The Imitation Game\nEsta película biográfica cuenta la vida de Alan Turing, el matemático británico que descifró el código Enigma durante la Segunda Guerra Mundial. Es un retrato conmovedor de una mente brillante pero incomprendida, destacando la importancia del trabajo de Turing para la informática moderna. Recomendada para aquellos interesados en la historia de la criptografía y los inicios de la inteligencia artificial.\nThe Playlist\nEsta serie sigue la historia de Spotify y cómo revolucionó la industria musical. Muestra el conflicto entre innovación tecnológica y las viejas estructuras de poder en la industria. Recomendada para quienes estén interesados en el impacto de las plataformas tecnológicas en la cultura y los negocios.\nEl Código de la Discordia - The Billion Dollar Code\nEsta miniserie basada en hechos reales cuenta la lucha legal de dos programadores alemanes contra Google por los derechos de patente de lo que se convirtió en Google Earth. Un drama judicial sobre innovación, propiedad intelectual y justicia en la era digital. Recomendada para quienes disfrutan de historias sobre startups y grandes corporaciones tecnológicas.\nBlackberry\nEsta película sigue el ascenso y caída de Blackberry, una de las compañías pioneras en el desarrollo de smartphones. Es una mirada fascinante al vertiginoso mundo de la tecnología y cómo la innovación, y la falta de adaptación, puede hacer o deshacer una empresa. Recomendada para los interesados en la historia de la tecnología móvil y el auge de los dispositivos personales.\nLa Teoría del Todo - The Theory of Everything\nEste biopic sobre Stephen Hawking narra su vida personal y profesional, enfocándose en su lucha contra la enfermedad de Lou Gehrig mientras desarrolla teorías revolucionarias sobre el universo. Una película conmovedora y visualmente impresionante. Altamente recomendada para quienes buscan un relato inspirador sobre la ciencia y la superación personal.\nEl hombre que conocía el infinito - The Man Who Knew Infinity\nLa película retrata la vida de Srinivasa Ramanujan, un prodigio matemático autodidacta que viaja de la India a Cambridge para colaborar con el matemático G.H. Hardy. Es un homenaje a la perseverancia intelectual y al genio que rompe barreras culturales y académicas. Recomendada para quienes disfrutan de las historias biográficas sobre genios matemáticos.\nOppenheimer\nUn retrato épico de la vida de J. Robert Oppenheimer, el físico que lideró el desarrollo de la bomba atómica en el Proyecto Manhattan. La película explora el impacto ético y emocional de crear un arma de destrucción masiva. Altamente recomendada para quienes estén interesados en la historia de la ciencia y los dilemas éticos asociados con la tecnología.\nLa Red Social - The Social Network\nLa película cuenta la creación de Facebook y el ascenso de Mark Zuckerberg. Muestra los conflictos personales y legales que acompañaron el éxito de una de las plataformas más influyentes del siglo XXI. Recomendada para quienes quieran entender los orígenes de las redes sociales y los desafíos éticos del poder digital.\nEl Dilema de las Redes Sociales - The Social Dilemma\nEste documental analiza el impacto negativo de las redes sociales en la sociedad, desde la manipulación psicológica hasta la erosión de la democracia. Con entrevistas a exejecutivos de empresas tecnológicas, es una advertencia clara sobre los peligros de la tecnología descontrolada. Recomendada para quienes estén interesados en los efectos sociales y psicológicos de las redes.\nSteve Jobs\nEste biopic de Danny Boyle ofrece una visión íntima de la vida de Steve Jobs, centrada en tres momentos clave en su carrera. A través de diálogos ágiles y dramáticos, la película presenta al fundador de Apple como un visionario, pero también como una figura compleja. Recomendada para quienes busquen un retrato personal de una de las figuras más influyentes en la tecnología moderna.\nCitizenfour\nEste documental sigue al denunciante Edward Snowden mientras revela el programa de vigilancia masiva del gobierno de EE.UU. Una mirada cruda y urgente sobre la privacidad, la seguridad y el poder gubernamental. Recomendada para aquellos interesados en los derechos digitales y la privacidad.\nThe Internet’s Own Boy: The Story of Aaron Swartz\nEste documental narra la vida de Aaron Swartz, un activista digital y programador que luchó por el acceso libre a la información. Su trágica muerte resalta los conflictos entre la libertad de información y las leyes restrictivas. Recomendada para quienes quieran explorar la intersección entre tecnología, activismo y derechos civiles en la era digital."
  },
  {
    "objectID": "posts/using-satellite-images/index.html",
    "href": "posts/using-satellite-images/index.html",
    "title": "Using Satellite Images",
    "section": "",
    "text": "La teledetección satelital o satellite remote sensing es la actividad de recolectar datos a través del uso de sensores, en este caso satélites, de un lugar al que no se tiene acceso físicamente, es decir en forma remota.\nEstos datos consisten en la medición de energía electromagnética. La radiación electromagnética es una forma de energía emitida por toda materia con temperatura arriba del cero absoluto (0 Kelvin o -272° Celcius). Rayos X, ultravioletas, luz visible, infraroja, calor, microondas y ondas de radio y televisión son todas formas de energía electromagnética con distinta longitud de onda o frecuencia y son parte del espectro electromagnético.\nLos objetos más calientes emiten más energía electromagnética y a ondas más cortas que los más fríos. La fuente de radiación electromagnética más común es el Sol. Los objetos que constituyen la superficie de la Tierra reflejan y emiten radiación electromagnética de distinta manera.\nLa porción del espectro electromagnético donde se ubica el pico de la radiación solar se denomina banda visible, ya que la visión humana es sensible a esas ondas. La teledetección permite extender la capacidad humana de percibir radiación electromagnética más allá de la banda visual, por eso las partes del espectro electromagnético que no podemos ver son muy importantes.\nLos objetos que constituyen la superficie de la Tierra reflejan la radiación electromagnética de distinta manera. El atractivo de la teledetección multiespectral es que objetos indistinguibles a una longitud de onda determinada pueden ser fáciles de distinguir a otra. Las bandas comúnmente usadas para percibir la ocupación y uso del suelo son: visible, infraroja y microondas.\nEntender las diferentes maneras en que longitudes de onda específicas interactúan con distintos objetos permite encontrar “sellos” o “signatures” que permitirán detectar esos objetos automáticamente.\nLas aplicaciones son diversas: monitoreo de deforestación, degradación del suelo, detección y clasificación de objetos tan disímiles como humedales, asentamientos informales y barrios cerrados, monitoreo de la calidad y salinidad del agua, calidad del aire, detección de basurales clandestinos, monitoreo de rellenos sanitarios, monitoreo del impacto ambiental de industrias determinadas, entre otros.\nEn este post no voy a avanzar en detección o clasificación de objetos pero, siguiendo este tutorial voy a utilizar imágenes satelitales junto con datos de elevación SRTM para hacer un mapa en 3D de mi lugar preferido en el mundo: el Dique de Cuesta del Viento en Rodeo, San Juan.\nAcá el código:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nY el resultado:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#breve-intro-conceptual1",
    "href": "posts/using-satellite-images/index.html#breve-intro-conceptual1",
    "title": "Using Satellite Images",
    "section": "",
    "text": "La teledetección satelital o satellite remote sensing es la actividad de recolectar datos a través del uso de sensores, en este caso satélites, de un lugar al que no se tiene acceso físicamente, es decir en forma remota.\nEstos datos consisten en la medición de energía electromagnética. La radiación electromagnética es una forma de energía emitida por toda materia con temperatura arriba del cero absoluto (0 Kelvin o -272° Celcius). Rayos X, ultravioletas, luz visible, infraroja, calor, microondas y ondas de radio y televisión son todas formas de energía electromagnética con distinta longitud de onda o frecuencia y son parte del espectro electromagnético.\nLos objetos más calientes emiten más energía electromagnética y a ondas más cortas que los más fríos. La fuente de radiación electromagnética más común es el Sol. Los objetos que constituyen la superficie de la Tierra reflejan y emiten radiación electromagnética de distinta manera.\nLa porción del espectro electromagnético donde se ubica el pico de la radiación solar se denomina banda visible, ya que la visión humana es sensible a esas ondas. La teledetección permite extender la capacidad humana de percibir radiación electromagnética más allá de la banda visual, por eso las partes del espectro electromagnético que no podemos ver son muy importantes.\nLos objetos que constituyen la superficie de la Tierra reflejan la radiación electromagnética de distinta manera. El atractivo de la teledetección multiespectral es que objetos indistinguibles a una longitud de onda determinada pueden ser fáciles de distinguir a otra. Las bandas comúnmente usadas para percibir la ocupación y uso del suelo son: visible, infraroja y microondas.\nEntender las diferentes maneras en que longitudes de onda específicas interactúan con distintos objetos permite encontrar “sellos” o “signatures” que permitirán detectar esos objetos automáticamente.\nLas aplicaciones son diversas: monitoreo de deforestación, degradación del suelo, detección y clasificación de objetos tan disímiles como humedales, asentamientos informales y barrios cerrados, monitoreo de la calidad y salinidad del agua, calidad del aire, detección de basurales clandestinos, monitoreo de rellenos sanitarios, monitoreo del impacto ambiental de industrias determinadas, entre otros.\nEn este post no voy a avanzar en detección o clasificación de objetos pero, siguiendo este tutorial voy a utilizar imágenes satelitales junto con datos de elevación SRTM para hacer un mapa en 3D de mi lugar preferido en el mundo: el Dique de Cuesta del Viento en Rodeo, San Juan.\nAcá el código:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nY el resultado:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#footnotes",
    "href": "posts/using-satellite-images/index.html#footnotes",
    "title": "Using Satellite Images",
    "section": "Notas",
    "text": "Notas\n\n\nEn base al MOOC “Imagery, Automation, and Applications” de la Universidad de California, Davis y al libro de David DiBiase, The Nature of Geographic Information. Penn State University, College of Earth and Mineral Sciences. Retrieved from https://www.e-education.psu.edu/natureofgeoinfo/↩︎"
  }
]