[
  {
    "objectID": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "title": "Datos y TICs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "href": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Código\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"BID: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Consultor asociado\", \"Experiencia profesional\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Docente en Gobierno Abierto y Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Docente en Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Maestría en Ciencia de Datos\", \"Formación académica\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Subsecretario de TICs\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Especialización en Ciencia de Datos\", \"Formación académica\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Director Ejecutivo\", \"Experiencia profesional\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Formación académica\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Jefe Regional de Ciudad de Buenos Aires\", \"Experiencia profesional\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Experiencia profesional\": \"lightskyblue\",\n    \"Actividad docente\": \"palegreen\",\n    \"Formación académica\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Año')\nplt.title('Línea de Tiempo CV Martin Olmos')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\nSoy licenciado en Ciencias Políticas (UCA), Magister en Políticas Públicas (George Washington University), Especialista y Maestrando en Ciencia de Datos (ITBA).\n\nFORMACIÓN ACADÉMICA\n2022 MAESTRÍA EN CIENCIA DE DATOS\n(Tesis en elaboración)\nInstituto Tecnológico de Buenos Aires (ITBA)\n2018 ESPECIALIZACIÓN EN CIENCIA DE DATOS\nInstituto Tecnológico de Buenos Aires (ITBA)\n2016 MASTER IN PUBLIC POLICY\nTrachtenberg School of Public Policy and Public Administration\nGeorge Washington University\n2003 LICENCIATURA EN CIENCIAS POLÍTICAS, CON ORIENTACIÓN EN PROCESOS POLÍTICOS\nFacultad de Ciencias Políticas y Relaciones Internacionales. Pontificia Universidad Católica Argentina. Buenos Aires, Argentina.\n\n\nANTECEDENTES PROFESIONALES Y DOCENTES\n9/2023- actualidad BANCO INTERAMERICANO DE DESARROLLO Responsabilidad: Consultor en Ciencia de Datos y TICs\n3/2023- actualidad BLUENOTE MANAGEMENT CONSULTING Responsabilidad: Consultor asociado\n2/2023- actualidad CAF BANCO DE DESARROLLO DE AMÉRICA LATINA Y EL CARIBE Responsabilidad: Consultor en Ciencia de Datos y TICs\n7/2022- actualidad DIPLOMATURA EN GESTIÓN DE CIUDADES - ESCUELA DE ECONOMÍA Y NEGOCIOS – UNIVERSIDAD NACIONAL DE SAN MARTÍN\nResponsabilidad: Docente en Gobierno Abierto y Nuevas Tecnologías\n12/2019-03/2022 SUBSECRETARIO DE TECNOLOGÍAS DE LA INFORMACIÓN Y LAS\nCOMUNICACIONES DE LA JEFATURA DE MINISTROS DE LA NACIÓN\n6/2021-9/2021 PROGRAMA EJECUTIVO EN LIDERAZGO INNOVADOR – OEI, ILES, SECRETARÍA DE ASUNTOS ESTRATÉGICOS DE LA REPÚBLICA ARGENTINA\nResponsabilidad: Docente en Nuevas Tecnologías\n4/2017-11/2019 INSTITUTO CIUDAD – POLÍTICAS PÚBLICAS PARA BUENOS AIRES\nResponsabilidad: Director Ejecutivo\n8/2019-12/2019 SEMINARIO DE INTRODUCCIÓN A LA CIENCIA DE DATOS PARA LAS CIENCIAS SOCIALES – FACULTAD DE CIENCIAS SOCIALES (UBA)\nResponsabilidad: Docente\n2/2019-actualidad THE CARPENTRIES – DATA CARPENTRY\nResponsabilidad: Instructor\n7/2018-11/2019 DIRECCIÓN DE IMPLEMENTACIÓN Y SEGUIMIENTO SUBE – MINISTERIO DE TRANSPORTE DE LA NACIÓN\nResponsabilidad: Consultor en Ciencia de Datos\n8/2018-6/2019 SECRETARÍA DE ASUNTOS PÚBLICOS – MUNICIPALIDAD DE SAN MIGUEL\nResponsabilidad: Consultor en Ciencia de Datos\n2/2018-8/2018 ORGANISMO PROVINCIAL PARA EL DESARROLLO SOSTENIBLE\nResponsabilidad: Consultor en Ciencia de Datos\n1/2017-6/2018 CONVENIO MINISTERIO DE TRANSPORTE-UNSAM\nResponsabilidad: Consultor en Ciencia de Datos\n5/2015-12/2016 BANCO DE DESARROLLO DE AMÉRICA LATINA (CAF)\nResponsabilidad: Consultor en Ciencia de Datos\n11/2009-12/2014 ADMINISTRACIÓN NACIONAL DE LA SEGURIDAD SOCIAL\nResponsabilidad: Jefe Regional de Ciudad de Buenos Aires.\n\n\nBECAS Y DISTINCIONES\n2016 BECA ORGANIZACIÓN DE ESTADOS AMERICANOS (OEA) PARA ESTUDIOS DE POSGRADO.\n2015 GLOBAL LEADERS FELLOWSHIP 2015-2016 , GEORGE WASHINGTON UNIVERSITY.\n2015 BECA FULBRIGHT DE MAESTRÍA 2015-2016 , COMISIÓN FULBRIGHT ARGENTINA.\n2013 IV FORO “EL FUTURO DE AMÉRICA LATINA: LA VISIÓN DE LOS JÓVENES LÍDERES” , CAF – BANCO DE DESARROLLO DE AMÉRICA LATINA A PARTICIPAR, CIUDAD DE MÉXICO, 22 Y 23 DE AGOSTO DE 2013.\n2013 PROGRAMA DE GOBIERNO PARA EL DESARROLLO DE LÍDERES DE COMUNIDADES LOCALES. CENTRO DE ESTUDIOS EN GOBIERNO, EMPRESA, SOCIEDAD Y ECONOMÍA, IAE BUSINESS SCHOOL, UNIVERSIDAD AUSTRAL, PILAR, PROVINCIA DE BUENOS AIRES, MAYO Y JUNIO DE 2013. BECA OTORGADA POR LA FUNDACIÓN RAP (RED DE ACCIÓN POLÍTICA).\n2005 PROGRAMA FURP- USA, AUSTIN Y WASHINGTON DC, ESTADOS UNIDOS DE AMÉRICA. FEBRERO DE 2005.\n\n\nPARTICIPACIÓN EN ACTIVIDADES Y CONFERENCIAS INTERNACIONALES\n\nJunio 2022\n\nOrganizadores | Cámara Chilena de Infraestructura Digital y Asociación Chilena de Municipalidades\nEvento | Foro Brechas y Equidad Digital\nPanel | Los fondos de acceso universal en la Región\n\nMarzo 2022\n\nOrganizador | GSMA\nEvento | Ministerial Programme - Mobile World Congress (MWC)\n\nFebrero 2022\n\nOrganizador | Unión Internacional Telecomunicaciones (ITU)\nEvento | 4th Global Standards Symposium\nTema | Normas Internacionales para Potenciar la Transformación Digital\n\nNoviembre 2021\n\nOrganizador | Forum Europe (Forum Global)\nEvento | Latin America Spectrum Management Conference\nTema | The Emerging Shape of the 6GHz Band\n\nJunio 2021\n\nOrganizador | GSMA\nEvento | Spectrum Roundtable at the Ministerial Programme - Mobile World Congress (MWC)\nTema | The Future of Spectrum Access\n\nNoviembre 2020\n\nOrganizador | Forum Europe (Forum Global)\nEvento | Latam Spectrum Conference\nTema | Bridging the Digital Divide – How Has Covid Shone a Light on Digital Inequalities and How Can the Region Move Forward in Tackling This Issue?\n\nOctubre 2020\n\nOrganizador | International Institute of Communications\nTema | Digital Transformation Post COVID-19: LatAm Responses to the Digital Divide.\n\nJulio 2020\n\nOrganizador | ITU, GeSI & the United Nations Office for South South Cooperation.\nTema | Accelerating Action and Transformative Pathways for Delivering on the Sustainable Development Goals and Recovery from COVID-19 Pandemic.\n\n\nPARTICIPACIÓN EN ACTIVIDADES Y CONFERENCIAS NACIONALES\n\nMayo 2021\n\nOrganizador | CABASE\nEvento | Internet Day\nTema | Iniciativas de desarrollo de la infraestructura de internet para la universalización de la conectividad\nOrganizador | ISOC Capítulo Argentina y Facultad de Ingeniería de Universidad de Palermo\nEvento | 5tas Jornadas sobre Perspectivas de las Telecomunicaciones y TICs 2021\nTema | Desafíos Actuales de las Telecomunicaciones\n\nAbril 2021\n\nOrganizador | Grupo Convergencia\nEvento | NPlay Cono Sur\nTema | Los Planes para Reducir la Brecha Digital y Compartición de Infraestructura\n\nDiciembre 2020\n\nOrganizador | Grupo Convergencia\nTema | Infraestructura y despliegue de red para crecer en la nueva normalidad.\nOrganizador | Internet Governance Forum (IGF)\nTema | Gobernanza de Algoritmos e Inteligencia Artificial\n\nAgosto 2020 – Marzo 2022\n\nOrganizador | BID - INTAL\nPrograma | Proyecto Regional Programa de Integración de la Economía Digital para Latinoamérica y el Caribe\nPosición | Miembro del Consejo Directivo"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html",
    "href": "posts/transcribe-messi-using-whisper/index.html",
    "title": "Using Whisper to Transcribe Messi",
    "section": "",
    "text": "Whisper es un modelo de código abierto para reconocimiento del habla desarrollado por OpenAI.\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\nAquí la entrevista original:"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#descargo-el-audio-y-el-video-de-youtube",
    "href": "posts/transcribe-messi-using-whisper/index.html#descargo-el-audio-y-el-video-de-youtube",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Descargo el audio y el video de Youtube",
    "text": "Descargo el audio y el video de Youtube\n\n\nCódigo\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\n:::"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#genero-la-transcripción",
    "href": "posts/transcribe-messi-using-whisper/index.html#genero-la-transcripción",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Genero la transcripción",
    "text": "Genero la transcripción\n\n\nCódigo\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#incrusto-la-transcripción-en-el-video-como-subtítulos",
    "href": "posts/transcribe-messi-using-whisper/index.html#incrusto-la-transcripción-en-el-video-como-subtítulos",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Incrusto la transcripción en el video como subtítulos",
    "text": "Incrusto la transcripción en el video como subtítulos\n\n\nCódigo\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n\nAquí el producto final, el video con los subtítulos:"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "",
    "text": "Nota: para aquellos interesados en el código utilizado para generar cada visualización, pueden verlo haciendo clic en el botón “Mostrar/Ocultar Todo el Código” en la parte superior derecha de la página o en el botón “Código” que se encuentra arriba y a la derecha de cada visualización."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#día-3---polígonos",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#día-3---polígonos",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Día 3 - Polígonos",
    "text": "Día 3 - Polígonos\nLas celdas de red móvil pueden ser modeladas utilizando Diagramas de Voronoi. Típicamente, esto se hace para análisis de movilidad con datos de señalización celular, como se muestra en este paper.\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#día-4---hexágonos",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#día-4---hexágonos",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Día 4 - Hexágonos",
    "text": "Día 4 - Hexágonos\nLos hexágonos se pueden utilizar también para graficar las radiobases 4G, utilizando la intensidad del color para mostrar su densidad.\n\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "posts/beckham-vs-papu-gomez/index.html",
    "href": "posts/beckham-vs-papu-gomez/index.html",
    "title": "Beckham vs. Papu Gomez",
    "section": "",
    "text": "Este post no es sobre TICs. Es sobre el uso de IA para clasificaar imágenes. En este caso tomamos una controversia que se planteó durante del mundial en un stream del Kun Aguero, donde Lio Messi y el Papu Gomez le piden al Kun que adivine a quién se parece el Papu, luego de su nuevo corte de pelo.\n\n\n\n\nA partir de ahí quedó la controversia. Se parece el Papu Gomez a David Beckham? Es por eso que decidí entrenar un modelo de IA para clasificar imágenes de ambos jugadores. Tengo que decir que a partir de esto llegué a la conclusión que algún parecido tienen, ya que tuve que ir pasando de modelos más simples a más complejos para que aprenda a distinguir bien entre los dos.\nPueden probar la aplicación a continuación o en el siguiente link"
  },
  {
    "objectID": "posts/ict-companies-social-network-analysis/index.html",
    "href": "posts/ict-companies-social-network-analysis/index.html",
    "title": "ICT Companies Social Network Analysis",
    "section": "",
    "text": "El Procesamiento de Lenguaje Natural o PLN es el campo de estudio sobre el análisis computacional del lenguaje humano. Esta área de conomiento incluye una variedad muy amplia de técnicas y aplicaciones. Una de ellas, dentro del ámbito del análisis y comprensión del lenguaje, es el Análisis de Sentimientos, una aplicación que permite clasificar un texto de acuerdo a su carga o polaridad positiva, negativa o neutra.\nAquí veremos como con unas pocas líneas de código python uno puede:\n\nConectarse a la API de Twitter\nDescargar los últimos twitts en los que se menciona a determinadas empresas TIC\nUtilizar un modelo de machine learning pre-entrenado para realizar el análisis de sentimientos de los twitts\nVisualizar el análisis\n\nEl modelo pre-entrenado que vamos a utilizar es RoBERTuito, un modelo entrenado con 500 millones de tweets en Español. Los autores del paper/modelo lo disponibilizaron en forma gratuita a través de la plataforma HuggingFace y librería pysentimiento para facilitar la investigación y las aplicaciones de PLN en Español.\nAclaración 1: es natural y esperable que las menciones a las empresas en redes tengan un sesgo negativo, ya que es uno de los canales para hacer llegar reclamos y por tratarse de un servicio pago no es habitual que la conformidad con el servicio redunde en menciones positivas.\nAclaración 2: para acceder a los tweets con las menciones es necesario primero tramitar credenciales de autenticación en Twitter for Developers. Las mismas estarán guardadas en un archivo llamado search_tweets_creds.yml con la siguiente forma:\nsearch_tweets_api:\n    bearer_token: MY_BEARER_TOKEN\n    endpoint: https://api.twitter.com/2/tweets/search/recent\nPara adquirir los tweets utilizaré la librería searchtweets-v2, un Cliente de Python para la Versión 2 de la API de Twitter.\nCon el siguiente código me autentico y requiero los últimos 100 tweets que mencionan a cada una de las empresas que nos interesan:\n\nfrom searchtweets import load_credentials, ResultStream, gen_request_parameters, collect_results\n\nsearch_args = load_credentials(filename=\"search_tweets_creds.yml\", \n                               yaml_key=\"search_tweets_api\",\n                               env_overwrite=False)\n\nempresas = [\"Telecentro\", \"MovistarArg\", \"ClaroArgentina\", \"PersonalAr\"]\nempresas_tweets = dict()\n\nfor empresa in empresas:\n    query = gen_request_parameters(empresa, results_per_call=100, granularity=None)\n    tweets = collect_results(query,\n                             max_tweets=100,\n                             result_stream_args=search_args)\n    empresas_tweets[empresa] = tweets[0]['data']\n\nPreproceso los tweets, aplico el análisis de sentimientos y extraigo la categoría para cada uno de los tweets y empresas:\n\nfrom pysentimiento import create_analyzer\n\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\", model_name=\"pysentimiento/robertuito-sentiment-analysis\")\n\nempresas_tweets_sent = dict()\nempresas_tweets_sent_out = dict()\n\nfor empresa in empresas:\n    empresas_tweets_sent[empresa] = [analyzer.predict(tuit) for tuit in empresas_tweets_proc[empresa]]\n    empresas_tweets_sent_out[empresa] = [tuit.output for tuit in empresas_tweets_sent[empresa]]\n\nVisualizo los resultados:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nempresas_tweets_sent_count = dict()\nfig, axes = plt.subplots(2, 2, figsize=(8, 6),dpi=144)\n\nplt.suptitle(\"Análisis de Sentimientos de Empresas TIC\")\n\narray_index = [(0,0), (0,1), (1,0), (1,1)]\naxes_title_font_size = 10\n\nfor empresa, index in zip(empresas, array_index):\n    empresas_tweets_sent_count[empresa] = np.unique(empresas_tweets_sent_out[empresa], return_counts=True)\n    axes[index].pie(empresas_tweets_sent_count[empresa][1], labels=empresas_tweets_sent_count[empresa][0], wedgeprops=dict(width=.5), autopct='%1.f%%')\n    axes[index].set_title(empresa, fontsize=axes_title_font_size)"
  },
  {
    "objectID": "posts/price-evolution/index.html",
    "href": "posts/price-evolution/index.html",
    "title": "ICT Prices Evolution",
    "section": "",
    "text": "Veamos cuál fue la evolución de los precios de los servicios TIC en Argentina en los últimos años.\nSi tomamos la serie del capítulo de comunicaciones del Índice de Precios al Consumidor del INDEC (IPC-COM) vemos que desde el incio de la serie (Dic-2016=100) las comunicaciones estuvieron por encima del índice general hasta 2020, donde el IPC-COM se ameseta y luego queda por debajo.\n\n\n\nAnalicemos en particular los años 2020 y 2021. Primero 2020: si vemos la variación acumulada anual el IPC-COM se pone por arriba del IPC general con el aumento de marzo que fue parcialmente retrotraído en abril (se retrotrajo el aumento del móvil prepago y de la telefonía fija, no así el móvil pospago y mixto) y luego el IPC se ameseta primero por el acuerdo de precios hasta el 31 de julio y luego por el congelamiento que impuso el DNU 690/2020 hasta el 31 de diciembre.\n\n\n\nVeamos ahora el año 2021:\n\n\n\n\nComo se puede apreciar en los gráficos, tanto 2020 como 2021 fueron años donde los aumentos del sector se ubicaron bien por debajo de los aumentos en el índice general.\nAclaración: de acuerdo al COICOP Argentina, el Capítulo de Comunicaciones del IPC no incluye sólo servicios TIC si no también el precio de los equipos y no incluye precios del servicio de televisión paga, que se encuentran reflejados en el Capítulo de Recreación y Cultura.\nEsto respecto de la evolución. Veamos ahora cómo nos ubicamos respecto de otros países de la región en cuanto a asequibilidad. La Unión Internacional de Telecomunicaciones (UIT) compila estadísticas estandarizadas sobre precios de canastas de precios de servicios fijos y móviles. Algunos ejemplos:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEn estas series temporales, Argentina parece estar bien sólo en banda ancha móvil (sólo datos).\nAclaración: estas series temporales sólo incluyen 2018, 2019 y 2020 porque en 2017 hubo un cambio de metodología. Para más información ver aquí."
  },
  {
    "objectID": "migration.html",
    "href": "migration.html",
    "title": "30 day map challenge day 1 and 2",
    "section": "",
    "text": "import openai\nfrom dotenv import load_dotenv\nimport os\n\n_ = load_dotenv()\n\nopenai.api_key  = os.getenv('OPENAI_KEY')\n# List available models\n\n[print(model.id) for model in openai.models.list()]\n\ngpt-3.5-turbo-0301\ntext-embedding-3-large\ngpt-4-turbo-preview\ndall-e-3\nwhisper-1\ndall-e-2\ntext-embedding-ada-002\ntts-1-hd-1106\ntts-1-hd\ndavinci-002\nbabbage-002\ntext-embedding-3-small\ngpt-4-0125-preview\ngpt-3.5-turbo-0613\ngpt-3.5-turbo\ngpt-4-0613\ngpt-4-vision-preview\ngpt-3.5-turbo-16k-0613\ngpt-4\ngpt-3.5-turbo-1106\ntts-1-1106\ngpt-3.5-turbo-instruct\ntts-1\ngpt-3.5-turbo-instruct-0914\ngpt-4-1106-preview\ngpt-3.5-turbo-16k\n\n\n[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]\nmodel = \"gpt-3.5-turbo-16k\"\n\ndef get_completion(prompt, model=model):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response\nposteo_espanol_ejemplo = \"\"\"\n---\ntitle: Usando Whisper para Transcribir a Messi\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n## Descargo el audio y el video de Youtube\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n## Genero la transcripción\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n## Incrusto la transcripción en el video como subtítulos\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\nAquí el producto final, el video con los subtítulos:\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\"\"\"\nposteo_ingles_ejemplo = \"\"\"\n---\ntitle: Using Whisper to Transcribe Messi\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n## Download audio and video from Youtube\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n## Generate the transcript\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n## Embed the transcript in the video as subtitles\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\nHere the final product, the video with the subtitles:\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\"\"\"\nposteo_fusionado_ejemplo = \"\"\"\n---\ntitle: Using Whisper to Transcribe Messi\nsubtitle: Transcribir a Messi con Whisper\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n::: {.content-visible when-profile=\"english\"}\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n:::\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n::: {.content-visible when-profile=\"english\"}\n## Download audio and video from Youtube\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Descargo el audio y el video de Youtube\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Generate the transcript\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Genero la transcripción\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n::: {.content-visible when-profile=\"english\"}\n## Embed the transcript in the video as subtitles\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Incrusto la transcripción en el video como subtítulos\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\n::: {.content-visible when-profile=\"english\"}\nHere is the final product, the video with the subtitles:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\nAquí el producto final, el video con los subtítulos:\n\n:::\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\n\"\"\"\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_espanol.txt', 'r') as file:\n    posteo_espanol_ejemplo = file.read()\n\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_ingles.txt', 'r') as file:\n    posteo_ingles_ejemplo = file.read()\n\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_fusion.txt', 'r') as file:\n    posteo_fusionado_ejemplo = file.read()\nprint(posteo_fusionado_ejemplo)\n\n---\ntitle: Using Whisper to Transcribe Messi\nsubtitle: Transcribir a Messi con Whisper\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n::: {.content-visible when-profile=\"english\"}\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n:::\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n::: {.content-visible when-profile=\"english\"}\n## Download audio and video from Youtube\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Descargo el audio y el video de Youtube\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Generate the transcript\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Genero la transcripción\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\nwith open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/2021-11-06-30-days-map-challenge-dia-1-y-2/index.es.Rmd', 'r') as f:\n    posteo_espanol = f.readlines()\n\nwith open('/Users/martinolmos/Documents/datos_tic/content/english/post/2021-11-06-30-days-map-challenge-day-1-and-2/index.en.Rmd', 'r') as f:\n    posteo_ingles = f.readlines()\nposteo_espanol = \"\".join(posteo_espanol)\nposteo_ingles = \"\".join(posteo_ingles)\nimport re\n\nposteo_espanol = re.sub(r'\\`\\`\\`\\{r include=FALSE, message=FALSE}\\\\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\\\\n\\`\\`\\`', '', posteo_espanol)\n\nposteo_ingles = re.sub(r'```{r include=FALSE, message=FALSE}\\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\\n```', '', posteo_ingles)\npattern = r\"```{r\\s+include=FALSE,\\s+message=FALSE}\\nknitr::opts_chunk\\$set\\(echo\\s+=\\s+TRUE,\\s+message\\s+=\\s+FALSE,\\s+warning\\s+=\\s+FALSE\\)\\n```\"\n\nposteo_espanol = re.sub(pattern, '', posteo_espanol, flags=re.DOTALL)\nposteo_ingles = re.sub(pattern, '', posteo_ingles, flags=re.DOTALL)"
  },
  {
    "objectID": "migration.html#day-map-challenge-day-3-and-4",
    "href": "migration.html#day-map-challenge-day-3-and-4",
    "title": "30 day map challenge day 1 and 2",
    "section": "30 day map challenge day 3 and 4",
    "text": "30 day map challenge day 3 and 4\n\nwith open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/2021-11-09-30-day-map-challenge-dia-3-y-4/index.es.Rmd', 'r') as f:\n    posteo_espanol = f.read()\n\n# with open('/Users/martinolmos/Documents/datos_tic/content/english/post/2021-11-09-30-day-map-challenge-day-3-and-4/index.en.Rmd', 'r') as f:\n#     posteo_ingles = f.readlines()\n\n\nposteo_espanol_ingles_ejemplo = posteo_fusionado_ejemplo\n\n\ndef fusionar_posteo(posteo_espanol):\n    prompt = f\"\"\"\nTe voy a pasar un posteo de un blog en español y necesito que le agregues la traducción al inglés. \\\nEl posteo contiene texto en español y bloques de código. \nLo que necesito es que el texto en español lo enmarques entre `::: {{.content-visible when-profile=\"spanish\"}}` y ::: \\\ny a continuación agregues el texto traducido al inglés enmarcado entre `::: {{.content-visible when-profile=\"english\"}}` y `:::` .  \\\nLos bloques de código deben aparecer una sóla vez luego del texto en español e inglés. \\\nEl encabezado o YAML está demarcado por `---` al principio y al final. La idea es tener un encabezado con el título en inglés y el subtítulo en español. \\\n\nTe voy a mostrar un ejemplo:\n\nPosteo en español: \\\n{posteo_espanol_ejemplo} \\\n\nResultado esperado en español e inglés: \\\n{posteo_espanol_ingles_ejemplo}\n\nAhora transforma el siguiente posteo: \\\n\nPosteo en español: \\\n{posteo_espanol} \\\n\nResultado esperado en español e inglés: \\\n\n\"\"\"\n    response = get_completion(prompt)\n    return response.choices[0].message.content\n\n\nposteo_espanol_ingles = fusionar_posteo(posteo_espanol)\n\n\nprint(posteo_espanol_ingles)\n\n---\ntitle: 30 Day Map Challenge Day 3 and 4\nsubtitle: Día 3 y 4 del Desafío de Mapas de 30 Días\nauthor: Martin Olmos\ndate: '2021-11-09'\nslug: []\ncategories: []\ntags:\n  - 30daymapchallenge\n---\n\n::: {.content-visible when-profile=\"english\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n*Note: for those interested in the code used to generate each visualization, you can see it by clicking the \"Show/Hide All Code\" button at the top right of the page or the \"Code\" button above and to the right of each visualization.*\n\n## Day 3 - Polygons\n\nMobile network cells can be modeled using [Voronoi Diagrams][3]. Typically, this is done for mobility analysis with cellular signaling data, as shown in [this paper][5].\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Day 4 - Hexagons\n\nHexagons can also be used to plot 4G radio bases, using color intensity to show their density.\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n:::\n\n[3]:https://en.wikipedia.org/wiki/Voronoi_diagram\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n\n\n\nfolder = 'posts/30-day-map-challenge-day-3-and-4/'\n\n# os.mkdir(folder)\n\nwith open(folder + 'index.qmd', 'w') as f:\n    f.write(posteo_espanol_ingles)\n\n\nprint(posteo_fusionado.choices[0].message.content)\n\n---\ntitle: 30 Day Map Challenge Day 3 and 4\nsubtitle: Día 3 y 4 del Desafío de Mapas de 30 Días\nauthor: Martin Olmos\ndate: '2021-11-09'\nslug: []\ncategories: []\ntags:\n  - 30daymapchallenge\n---\n\n::: {.content-visible when-profile=\"english\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n\n*Note: for thoses interested in the code for each visualization you can see it by pressing the \"Show All Code\" button at the top right of the page or by pressing the \"Code\" button above and to the right of each visualization.*\n\n## Day 3 - Polygons\n\nThe cells of mobile networks can be modeled using [Voronoi diagrams][3]. Typically this is done for mobility analysis with cell phone signaling data, as shown in [this paper][5].\n\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n## Day 4 - Hexagons\n\nHexagons can also be used to visualize 4G base stations, using the color intensity to show density.\n\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n[3]:https://es.wikipedia.org/wiki/Pol%C3%ADgonos_de_Thiessen\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n\n*Nota: para aquellos interesados en el código con el que se generó cada visualización pueden verlo presionando el botón \"Show/Hide All Code\" arriba a la derecha de la página o el botón \"Code\" arriba y a la derecha de cada visualización.*\n\n## Día 3 - Polígonos\n\nLas celdas de las redes móviles se pueden modelar mediante [Diagramas de Voronoi][3]. Típicamente esto se hace para análisis de movilidad con datos de señalización de los teléfonos celulares, como se muestra en [este paper][5]. \n\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n## Día 4 - Hexágonos\n\nPara graficar las radiobases 4G también se pueden utilizar hexágonos, utilizando la intesidad del color para mostrar la densidad de las mismas.\n\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n[3]:https://es.wikipedia.org/wiki/Pol%C3%ADgonos_de_Thiessen\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n:::"
  },
  {
    "objectID": "migration.html#cables-submarinos-de-internet",
    "href": "migration.html#cables-submarinos-de-internet",
    "title": "30 day map challenge day 1 and 2",
    "section": "Cables Submarinos De Internet",
    "text": "Cables Submarinos De Internet\n\nposteos_ingles = os.listdir('/Users/martinolmos/Documents/datos_tic/content/english/post/')\n\n\nposteos_ingles = posteos.copy()\n\n\nposteos_ingles\n\n['2022-02-06-internet-submarine-cables',\n '2022-02-07-price-evolution',\n '2022-03-19-using-satellite-images',\n '2022-04-12-internet-fix-access-dashboard-in-argentina',\n '2022-04-20-ict-companies-social-network-analysis',\n '2022-06-17-forum-equality-digital-divide',\n '2023-01-08-beckham-vs-papu-gomez']\n\n\n\nposteos_espanol = os.listdir('/Users/martinolmos/Documents/datos_tic/content/spanish/post/')\n\n\n# remove 0,7,10,11\nposteos_espanol\n\n['2022-02-06-cables-submarinos-de-internet',\n '2022-02-07-evoluci-n-de-los-precios',\n '2022-03-19-usando-im-genes-satelitales',\n '2022-04-12-tablero-de-accesos-fijos-a-internet-en-argentina',\n '2022-04-19-an-lisis-de-empresas-tic-en-redes-sociales',\n '2022-06-17-foro-brechas-y-equidad-digital',\n '2023-01-08-beckham-vs-papu-gomez']\n\n\n\ndef fusionar_posteo(posteo_espanol, posteo_ingles):\n    prompt = f\"\"\"\nTe voy a pasar un posteo de un blog en español y en inglés y necesito que los fusiones de un modo particular. \n\nEl encabezado o YAML está demarcado por `---` al principio y al final. La idea es conservar un sólo encabezado, con el título en inglés y el subtítulo en español. \\\nLos textos entre cada bloque de código deben enmarcarse con `::: {{.content-visible when-profile=\"spanish\"}}` par el texto en español y `:::` y con `::: {{.content-visible when-profile=\"english\"}}` y `:::` para el texto en inglés.  \\ \nCada bloque de código debe aparecer una sóla vez luego del texto en español e inglés. \\\n\nLa estructura esperada es la siguiente: \\\n\n---\ntitle: Title in english\nsubtitle: Título en español\nauthor: Martin Olmos\n...\n\n::: {{.content-visible when-profile=\"english\"}}\n\nFirst text block in english. Should contain all text until the first code block.\n\n:::\n\n::: {{.content-visible when-profile=\"spanish\"}}\n\nPrimer bloque de texto en español. Debería contener todo el texto hasta el primer bloque de código.\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nFirst code block\n\n```\n\n::: {{.content-visible when-profile=\"english\"}}\n\nSecond text block in english. Should contain all text until the second code block.\n\n:::\n\n::: {{.content-visible when-profile=\"spanish\"}}\n\nSegundo bloque de texto en español. Debería contener todo el texto hasta el segundo bloque de código.\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nSecond code block\n\n```\n\nAhora fusiona los siguientes posteos: \\\n\nPosteo en español: \\\n{posteo_espanol} \\\n\nPosteo en inglés: \\\n{posteo_ingles} \\\n\nPosteo fusionado esperado: \\\n\n\"\"\"\n    response = get_completion(prompt)\n    return response.choices[0].message.content\n\n\nfor i in range(len(posteos_ingles)):\n    with open('/Users/martinolmos/Documents/datos_tic/content/english/post/' + posteos_ingles[i] + '/index.en.Rmd', 'r') as fi:\n        posteo_ingles = fi.read()\n    \n    with open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/' + posteos_espanol[i] + '/index.es.Rmd', 'r') as fe:\n        posteo_espanol = fe.read()\n\n    response = fusionar_posteo(posteo_espanol, posteo_ingles)\n\n    folder = re.sub(\"\\d{4}-\\d{2}-\\d{2}-\", \"\", posteos_ingles[i])\n\n    os.mkdir('posts/' + folder)\n\n    with open('posts/' + folder + '/index.qmd', 'w') as fw:\n        fw.write(response)\n\n\nre.sub(\"\\d{4}-\\d{2}-\\d{2}-\", \"\", posteos_ingles[1])\n\n'price-evolution'\n\n\n\nwith open('prueba.qmd', 'w') as fw:\n    fw.write()\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"BID: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Consultor asociado\", \"Experiencia profesional\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Docente en Gobierno Abierto y Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Docente en Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Maestría en Ciencia de Datos\", \"Formación académica\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Subsecretario de TICs\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Especialización en Ciencia de Datos\", \"Formación académica\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Director Ejecutivo\", \"Experiencia profesional\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Formación académica\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Jefe Regional de Ciudad de Buenos Aires\", \"Experiencia profesional\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Experiencia profesional\": \"lightskyblue\",\n    \"Actividad docente\": \"palegreen\",\n    \"Formación académica\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Año')\nplt.title('Línea de Tiempo CV Martin Olmos')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"IDB: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Associate Consultant\", \"Professional Experience\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Instructor in Open Government and New Technologies\", \"Teaching Activity\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Instructor in New Technologies\", \"Teaching Activity\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Master's in Data Science\", \"Academic Training\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Deputy Secretary of ICTs\", \"Professional Experience\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Specialization in Data Science\", \"Academic Training\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Executive Director\", \"Professional Experience\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Data Science Consultant\", \"Professional Experience\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Academic Training\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Regional Head of Buenos Aires City\", \"Professional Experience\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Professional Experience\": \"lightskyblue\",\n    \"Teaching Activity\": \"palegreen\",\n    \"Academic Training\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Year')\nplt.title('Martin Olmos CV Timeline')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()"
  },
  {
    "objectID": "posts/internet-submarine-cables/index.html",
    "href": "posts/internet-submarine-cables/index.html",
    "title": "Internet Submarine Cables",
    "section": "",
    "text": "Hace un tiempo Tyler Morgan-Wall hizo una visualizacón de los todos los cables submarinos de internet con los datos de Telegeography.\nTyler publicó el código en este gist. Yo decidí reproducir la visualización con una pequeña modificación para agregarle un título y hacer girar a la tierra para el otro lado.\nAcá va la modificación al último for loop para agregar el título:\n\nfor(i in seq(1,720,by=1)) {\n  tmp &lt;- group_objects(fullcablescene,scale=c(1,1,1)*1.02) %&gt;% \n    add_object(sphere(radius=0.99,material=diffuse(image_texture = \"2k_earth_daymap.jpg\"),angle=c(0,-90,0))) %&gt;% \n    group_objects(angle=c(0,-i/2,0)) %&gt;% \n    add_object(sphere(y=5,z=5,x=5,material=light(intensity = 80,color=\"lightblue\"))) %&gt;% \n    add_object(sphere(y=5,z=5,x=-5,material=light(intensity = 10,color=\"orange\"))) %&gt;% \n    add_object(sphere(y=-10,material=light(intensity = 3,color=\"white\"))) %&gt;%\n    render_scene(samples=64,width=1200,height=1200,fov=0,aperture=0, ortho_dimensions = c(2.3,2.3),\n                 sample_method = \"sobol_blue\",parallel = TRUE,return_raw_array = TRUE)\n  rayimage::add_title(image = tmp,\n                      title_text = \"https://martinolmos.github.io/datos_tic/\",\n                      title_color = \"orange\",\n                      title_position = \"north\",\n                      filename = sprintf(\"imgs/smallcables%d.png\",i))\n}\n\nY la línea para generar la imagen animada girando para el otro lado:\n\nav::av_encode_video(sprintf(\"imgs/smallcables%d.png\", seq(720,1,by=-1)), \n                    framerate = 30, \n                    output = \"cables.mp4\")\n\nY finalmente la visualización con mis pequeñas modificaciones al código:\n\nVideo"
  },
  {
    "objectID": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "href": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "title": "Internet Fix Access Dashboard for Argentina",
    "section": "",
    "text": "Es posible hacer un tablero con datos básicos de accesos fijos en Argentina en forma rápida (unos 30 minutos), con datos abiertos de ENACOM, herramientas open source (en este caso R, Plotly y Flexdashboards pero existen muchas otras) y desplegarlo online en forma gratuita con Github Pages.\nAcá se puede ver el tablero online: https://martinolmos.github.io/tablero_accesos_fijos/\nY a continuación el código para adquirir los datos y generar las visualizaciones.\n\nAccesos Fijos cada 100 Hogares por Provincia\n\n# Penetracion por provincia: accesos cada 100 hogares\npen_prov_hog &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275028/data.csv\", \n                         n_max = 24, \n                         locale = locale(decimal_mark = \",\"))\n\npen_prov_hog_plot &lt;- pen_prov_hog %&gt;% \n  ggplot(aes(x = reorder(Provincia, `Accesos por cada 100 hogares`),\n             y = `Accesos por cada 100 hogares`,\n             text = Provincia)) +\n  geom_col(data=pen_prov_hog, aes(x=reorder(Provincia, `Accesos por cada 100 hogares`)), fill = \"red\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.text.y = element_text(size = 6), axis.title = element_blank())\n\nggplotly(pen_prov_hog_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de Accesos cada 100 habitantes\n\n# Penetración: accesos cada 100 habitantes. Serie histórica\npen_nac_hab_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/281491/data.csv\",\n                              locale = locale(decimal_mark = \",\"))\n\npen_nac_hab_serie_plot &lt;- pen_nac_hab_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Accesos por cada 100 hab`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title = element_blank())\n\nggplotly(pen_nac_hab_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de la Velocidad Media de Descarga\n\n# Velocidad Media de Descarga (Mbps) - Nacional\nvmd_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275016/data.csv\", col_names = c(\"Año\", \"Trimestre\", \"Velocidad Media de Descarga\", \"Periodo\"), skip = 1,\n                          locale = locale(decimal_mark = \",\"))\n\nvmd_nac_serie_plot &lt;- vmd_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Velocidad Media de Descarga`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  labs(y = \"VMD en Mbps\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title.x = element_blank())\n\nggplotly(vmd_nac_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolución de Accesos Fijos por Tecnología\n\ntec_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275029/data.csv\",\n                          locale = locale(decimal_mark = \",\"))\n\ntec_nac_serie &lt;- tec_nac_serie %&gt;% \n  select(-Total) %&gt;% \n  gather(Tecnología, Accesos, ADSL:Otros)\n\ntec_nac_serie_plot &lt;- tec_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = Accesos,\n             group = Tecnología,\n             color = Tecnología,\n             text = Periodo)) +\n  geom_line() +\n  scale_y_continuous(labels = c(\"0\", \"2M\", \"4M\", \"6M\")) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), \n        axis.title = element_blank(), \n        legend.title = element_blank())\n\nggplotly(tec_nac_serie_plot, tooltip = c(\"text\", \"color\", \"y\")) %&gt;% \n  layout(legend = list(title = \"\", \n                       orientation = \"h\",\n                       y = 1.3))"
  },
  {
    "objectID": "posts/using-satellite-images/index.html",
    "href": "posts/using-satellite-images/index.html",
    "title": "Using Satellite Images",
    "section": "",
    "text": "La teledetección satelital o satellite remote sensing es la actividad de recolectar datos a través del uso de sensores, en este caso satélites, de un lugar al que no se tiene acceso físicamente, es decir en forma remota.\nEstos datos consisten en la medición de energía electromagnética. La radiación electromagnética es una forma de energía emitida por toda materia con temperatura arriba del cero absoluto (0 Kelvin o -272° Celcius). Rayos X, ultravioletas, luz visible, infraroja, calor, microondas y ondas de radio y televisión son todas formas de energía electromagnética con distinta longitud de onda o frecuencia y son parte del espectro electromagnético.\nLos objetos más calientes emiten más energía electromagnética y a ondas más cortas que los más fríos. La fuente de radiación electromagnética más común es el Sol. Los objetos que constituyen la superficie de la Tierra reflejan y emiten radiación electromagnética de distinta manera.\nLa porción del espectro electromagnético donde se ubica el pico de la radiación solar se denomina banda visible, ya que la visión humana es sensible a esas ondas. La teledetección permite extender la capacidad humana de percibir radiación electromagnética más allá de la banda visual, por eso las partes del espectro electromagnético que no podemos ver son muy importantes.\nLos objetos que constituyen la superficie de la Tierra reflejan la radiación electromagnética de distinta manera. El atractivo de la teledetección multiespectral es que objetos indistinguibles a una longitud de onda determinada pueden ser fáciles de distinguir a otra. Las bandas comúnmente usadas para percibir la ocupación y uso del suelo son: visible, infraroja y microondas.\nEntender las diferentes maneras en que longitudes de onda específicas interactúan con distintos objetos permite encontrar “sellos” o “signatures” que permitirán detectar esos objetos automáticamente.\nLas aplicaciones son diversas: monitoreo de deforestación, degradación del suelo, detección y clasificación de objetos tan disímiles como humedales, asentamientos informales y barrios cerrados, monitoreo de la calidad y salinidad del agua, calidad del aire, detección de basurales clandestinos, monitoreo de rellenos sanitarios, monitoreo del impacto ambiental de industrias determinadas, entre otros.\nEn este post no voy a avanzar en detección o clasificación de objetos pero, siguiendo este tutorial voy a utilizar imágenes satelitales junto con datos de elevación SRTM para hacer un mapa en 3D de mi lugar preferido en el mundo: el Dique de Cuesta del Viento en Rodeo, San Juan.\nAcá el código:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nY el resultado:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#breve-intro-conceptual1",
    "href": "posts/using-satellite-images/index.html#breve-intro-conceptual1",
    "title": "Using Satellite Images",
    "section": "",
    "text": "La teledetección satelital o satellite remote sensing es la actividad de recolectar datos a través del uso de sensores, en este caso satélites, de un lugar al que no se tiene acceso físicamente, es decir en forma remota.\nEstos datos consisten en la medición de energía electromagnética. La radiación electromagnética es una forma de energía emitida por toda materia con temperatura arriba del cero absoluto (0 Kelvin o -272° Celcius). Rayos X, ultravioletas, luz visible, infraroja, calor, microondas y ondas de radio y televisión son todas formas de energía electromagnética con distinta longitud de onda o frecuencia y son parte del espectro electromagnético.\nLos objetos más calientes emiten más energía electromagnética y a ondas más cortas que los más fríos. La fuente de radiación electromagnética más común es el Sol. Los objetos que constituyen la superficie de la Tierra reflejan y emiten radiación electromagnética de distinta manera.\nLa porción del espectro electromagnético donde se ubica el pico de la radiación solar se denomina banda visible, ya que la visión humana es sensible a esas ondas. La teledetección permite extender la capacidad humana de percibir radiación electromagnética más allá de la banda visual, por eso las partes del espectro electromagnético que no podemos ver son muy importantes.\nLos objetos que constituyen la superficie de la Tierra reflejan la radiación electromagnética de distinta manera. El atractivo de la teledetección multiespectral es que objetos indistinguibles a una longitud de onda determinada pueden ser fáciles de distinguir a otra. Las bandas comúnmente usadas para percibir la ocupación y uso del suelo son: visible, infraroja y microondas.\nEntender las diferentes maneras en que longitudes de onda específicas interactúan con distintos objetos permite encontrar “sellos” o “signatures” que permitirán detectar esos objetos automáticamente.\nLas aplicaciones son diversas: monitoreo de deforestación, degradación del suelo, detección y clasificación de objetos tan disímiles como humedales, asentamientos informales y barrios cerrados, monitoreo de la calidad y salinidad del agua, calidad del aire, detección de basurales clandestinos, monitoreo de rellenos sanitarios, monitoreo del impacto ambiental de industrias determinadas, entre otros.\nEn este post no voy a avanzar en detección o clasificación de objetos pero, siguiendo este tutorial voy a utilizar imágenes satelitales junto con datos de elevación SRTM para hacer un mapa en 3D de mi lugar preferido en el mundo: el Dique de Cuesta del Viento en Rodeo, San Juan.\nAcá el código:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nY el resultado:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#footnotes",
    "href": "posts/using-satellite-images/index.html#footnotes",
    "title": "Using Satellite Images",
    "section": "Notas",
    "text": "Notas\n\n\nEn base al MOOC “Imagery, Automation, and Applications” de la Universidad de California, Davis y al libro de David DiBiase, The Nature of Geographic Information. Penn State University, College of Earth and Mineral Sciences. Retrieved from https://www.e-education.psu.edu/natureofgeoinfo/↩︎"
  },
  {
    "objectID": "posts/forum-equality-digital-divide/index.html",
    "href": "posts/forum-equality-digital-divide/index.html",
    "title": "Forum on Equality and the Digital Divide",
    "section": "",
    "text": "El pasado 9 y 10 de junio se realizó el Foro Brechas y Equidad Digital. En ese marco me invitaron a exponer en el panel “Los Fondos de Acceso Universal en la Región: el caso de Argentina.\nAquí dejo el video completo de mi participación:\n\n\n\nvideo\n\n\nY mi presentación:"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "",
    "text": "Nota: para aquellos interesados en el código con el que se generó cada visualización pueden verlo presionando el botón “Show/Hide All Code” arriba a la derecha de la página o el botón “Code” arriba y a la derecha de cada visualización.\nEl #30daymapchallenge es un desafío de mapeo/cartografía/visualización de datos impulsado por la comunidad de ciencia de datos. La idea es publicar mapas basados en un desafío diario durante 30 días usando el hashtag #30daymapchallenge.\nAquí están los temas diarios para los desafíos de este año:\nEn particular, voy a enfocarme (cuando pueda) en datos relacionados con las TIC.\nEmpecemos con los desafíos de los días 1 (puntos) y 2 (líneas)."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#día-1---puntos",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#día-1---puntos",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Día 1 - Puntos",
    "text": "Día 1 - Puntos\nNodos de conexión a la Red Federal de Fibra Óptica (REFEFO) de ARSAT. /\nLa REFEFO es una red troncal de fibra óptica. En los puntos o nodos de conexión los proveedores de internet o ISPs se conectan para llevar internet a los hogares.\n\n\nCódigo\nlibrary(tidyverse)\nlibrary(sf)\nsf_use_s2(FALSE)\nlibrary(httr)\n\nprovincias_ign &lt;- read_sf(\"https://wms.ign.gob.ar/geoserver/ows?service=wfs&version=1.1.0&request=GetFeature&typeNames=ign:provincia&outputFormat=application/json\")\n\nif(sum(!st_is_valid(provincias_ign)) &gt; 0) {\n  provincias_ign &lt;- st_make_valid(provincias_ign)\n}\n\nprovincias_ign &lt;- st_crop(x = provincias_ign,\n                          y = st_bbox(obj = c(xmin=-76.36532,\n                                              ymin=-56.75009,\n                                              xmax=-51.20850,\n                                              ymax=-20.91625)))\n\nnodos_refefo &lt;- read.csv2(\"https://datos.arsat.com.ar/dataset/8f0b4da0-a40d-4b2b-8fe0-dac06d64152a/resource/15713af0-f384-44c5-8397-c8050162312d/download/puntos-conexion-red-federal-de-fibra-optica-2021-12-01_v1.csv\", fileEncoding = \"LATIN1\")\n\nnodos_refefo &lt;- nodos_refefo %&gt;%\n  na.omit() %&gt;%\n  st_as_sf(crs = 4326, coords=c(\"Longitud\", \"Latitud\"), remove=FALSE)\n\nnodos_refefo &lt;- st_crop(x = nodos_refefo,\n                        y = st_bbox(obj = c(xmin=-76.36532,\n                                            ymin=-56.75009,\n                                            xmax=-51.20850,\n                                            ymax=-20.91625)))\n\nprovincias_ign %&gt;% \n  ggplot() + \n  geom_sf() +\n  geom_sf(data = nodos_refefo, color = \"#2ca25f\", size = 0.5) +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.datos.gob.ar / Source: www.datos.gob.ar\")"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#día-2---líneas",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#día-2---líneas",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Día 2 - Líneas",
    "text": "Día 2 - Líneas\nTraza de la REFEFO. La fibra óptica de la REFEFO en general va enterrada al lado de rutas nacionales y provinciales, conectando distintas localidades pequeñas y medianas, donde no llegan otros proveedores o hay uno sólo y por lo tanto no se dan condiciones de competencia.\n\n\nCódigo\nidecom_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\nrefefo_query &lt;- list(service=\"wfs\",\n                     version=\"1.3.0\",\n                     request=\"GetFeature\",\n                     typeNames=\"publico:FO118-TZFO-REDFIBRAOPTICA-5-2\",\n                     CQL_FILTER=\"OBSERV='ARSAT - ReFeFO'\",\n                     outputFormat=\"application/json\")\n\nidecom_url &lt;- modify_url(url = idecom_base_url, \n                         query = refefo_query)\n\ntraza_refefo_idecom &lt;- read_sf(idecom_url)\n\nprovincias_ign %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_sf(data = traza_refefo_idecom, colour=\"#2b8cbe\") +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.idecom.gob.ar / Source: www.idecom.gob.ar\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "REFEFO Potential to Enhance Productive Connectivity\n\n\nEl Potencial de la REDFO para Mejorar la Conectividad Productiva\n\n\n\n\nREFEFO\n\n\nProductive Connectivity\n\n\n\n\n\n\n\n\n\n\n\n26 abr 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nUsing Whisper to Transcribe Messi\n\n\nTranscribir a Messi con Whisper\n\n\n\n\nNLP\n\n\nIA\n\n\nML\n\n\nPython\n\n\nMessi\n\n\n\n\n\n\n\n\n\n\n\n3 feb 2023\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nBeckham vs. Papu Gomez\n\n\nBeckham vs. Papu Gomez\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n8 ene 2023\n\n\n\n\n\n\n  \n\n\n\n\nForum on Equality and the Digital Divide\n\n\nForo Brechas y Equidad Digital\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n17 jun 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nICT Companies Social Network Analysis\n\n\nAnálisis de Empresas TIC en Redes Sociales\n\n\n\n\nNLP\n\n\nsocial networks\n\n\n\n\n\n\n\n\n\n\n\n20 abr 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nInternet Fix Access Dashboard for Argentina\n\n\nTablero de Accesos Fijos a Internet en Argentina\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n12 abr 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nUsing Satellite Images\n\n\nUsando Imágenes Satelitales\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n19 mar 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\nICT Prices Evolution\n\n\nEvolución de los precios\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n7 feb 2022\n\n\n\n\n\n\n  \n\n\n\n\nInternet Submarine Cables\n\n\nCables Submarinos de Internet\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 feb 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\n30 Day Map Challenge Day 3 and 4\n\n\nDía 3 y 4 del Desafío de Mapas de 30 Días\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n9 nov 2021\n\n\nMartin Olmos\n\n\n\n\n\n\n  \n\n\n\n\n30 Days Map Challenge Day 1 and 2\n\n\n30 Days Map Challenge Día 1 y 2\n\n\n\n\n\n\n\n\n\n6 nov 2021\n\n\nMartin Olmos\n\n\n\n\n\n\nNo hay resultados"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Datos y TICs",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/refefo-potential-for-productive-conectivity.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/refefo-potential-for-productive-conectivity.html",
    "title": "REFEFO Potential to Enhance Productive Connectivity",
    "section": "",
    "text": "La mayoría de los países de la región tienen algún tipo de estrategia más o menos definida y articulada para mejorar la conectvidad digital de las poblaciones vulnerables, aquellas que viven en zonas de baja densidad poblacional donde a veces el sector privado por sí solo no tiene los incentivos para invertir en infraestrutura, o para llevar la conectividad a servicios de educación y salud. Sin embargo, no siempre se ha pensado en la conectividad productiva, es decir, en cómo la conectividad puede mejorar la productividad de las empresas y de los trabajadores.\nUn presupuesto importante para llegar con conectividad a un lugar es que existan redes troncales que permitan luego desarrollar la denominada “última milla” desde estas redes hasta los hogares y empresas. Argentina, por ejemplo, cuenta con la Red Federal de Fibra Óptica (REFEFO) gestionada por ARSAT, que es una red troncal que atraviesa las 23 provincias del país, llegando a unas 1.300 localidades, muchas de las cuales tienen poblaciones de menos de 10.000 habitantes. Por supuesto que existen también redes troncales de fibra óptica de operadores privados, pero el tendido de las mismas y la ubicación de los nodos de conexión no está disponible públicamente.\nPero volviendo al punto anterior, analicemos el potencial de la REFEFO para mejorar la conectividad productiva. Tomemos por ejemplo el sector agropecuario, que es uno de los más importantes de la economía argentina y el mayor generador de divisas.\nPodemos utilizar los datos del ex Ministerio de Desarrollo Productivo para georrefenciar las empresas agropecuarias y calcular la distancia de cada una de ellas al nodo de la REFEFO más cercano y luego analizar la distribución de estas distancias.\nEn primer lugar, obtenemos, filtramos y cruzamos los datos necesarios para el análisis:\n\n\nCódigo\nimport pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n# Cruzo los establecimientos agropecuarios con el nodo de REFEFO más cercano y obtengo la distancia\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\nLuego vamos a plotear en un mapa cada uno de los establecimientos agropecuarios y asignarle un color en función de la distancia con el nodo de la REFEFO más cercano.\n\n\nCódigo\nfrom matplotlib import cm\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\nMapa de Establecimientos Agropecuarios y Distancia a Nodo de REFEFO\n\n\nAdemás, vamos a plotear el histograma de las distancias para poder analizar su distribución.\n\n\nCódigo\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n\n\n\n\nHistograma de Distancias a Nodo de REFEFO\n\n\nComo se puede observar en el mapa y en el histograma, la mayoría de los establecimientos agropecuarios se encuentran a menos de 10 km de un nodo de la REFEFO. Para obtener los números precisos observemos la media y los cuartiles de las distancias.\n\n\nCódigo\nestab_agro_refefo_gpd['distance'].describe()\n\n\nLa media de las distancias de establecimientos agropecuarios al nodo de REFEFO más cercano es de 25.544 metros o 25,5 KMs. Sin embargo, como se observa en el histograma, las distancias no tienen una distribución normal sino que se trata de una distribución asimétrica a la derecha, con la mayor cantidad de distancias con valores bajos y unas pocas distancias con valores muy altos. En estos casos, la mediana es más representativa que la media. Aquí la mediana es de 8.580 metros u 8,6 KMs. Esto quiere decir que el 50% de los establecimientos agropecuarios se encuentran a menos de 8,6 KMs de un nodo de REFEFO. Finalmente, el tercer cuartil es de 35.895 metros o casi 36 KMs, lo que significa que el 75% de los establecimientos agropecuarios se encuentran a menos de 36 KMs de un nodo de REFEFO.\nHay muchas formas de mejorar este análisis preliminar pero esta primera aproximación parece indicar que la distancia a redes troncales no debería ser un impedimento para el desarrollo de la conectividad rural productiva en la Argentina."
  },
  {
    "objectID": "utils/migration.html",
    "href": "utils/migration.html",
    "title": "30 day map challenge day 1 and 2",
    "section": "",
    "text": "import openai\nfrom dotenv import load_dotenv\nimport os\n\n_ = load_dotenv()\n\nopenai.api_key  = os.getenv('OPENAI_KEY')\n# List available models\n\n[print(model.id) for model in openai.models.list()]\n\ngpt-3.5-turbo-0301\ntext-embedding-3-large\ngpt-4-turbo-preview\ndall-e-3\nwhisper-1\ndall-e-2\ntext-embedding-ada-002\ntts-1-hd-1106\ntts-1-hd\ndavinci-002\nbabbage-002\ntext-embedding-3-small\ngpt-4-0125-preview\ngpt-3.5-turbo-0613\ngpt-3.5-turbo\ngpt-4-0613\ngpt-4-vision-preview\ngpt-3.5-turbo-16k-0613\ngpt-4\ngpt-3.5-turbo-1106\ntts-1-1106\ngpt-3.5-turbo-instruct\ntts-1\ngpt-3.5-turbo-instruct-0914\ngpt-4-1106-preview\ngpt-3.5-turbo-16k\n\n\n[None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None,\n None]\nmodel = \"gpt-3.5-turbo-16k\"\n\ndef get_completion(prompt, model=model):\n    messages = [{\"role\": \"user\", \"content\": prompt}]\n    response = openai.chat.completions.create(\n        model=model,\n        messages=messages,\n        temperature=0, # this is the degree of randomness of the model's output\n    )\n    return response\nposteo_espanol_ejemplo = \"\"\"\n---\ntitle: Usando Whisper para Transcribir a Messi\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n## Descargo el audio y el video de Youtube\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n## Genero la transcripción\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n## Incrusto la transcripción en el video como subtítulos\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\nAquí el producto final, el video con los subtítulos:\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\"\"\"\nposteo_ingles_ejemplo = \"\"\"\n---\ntitle: Using Whisper to Transcribe Messi\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n## Download audio and video from Youtube\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n## Generate the transcript\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n## Embed the transcript in the video as subtitles\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\nHere the final product, the video with the subtitles:\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\"\"\"\nposteo_fusionado_ejemplo = \"\"\"\n---\ntitle: Using Whisper to Transcribe Messi\nsubtitle: Transcribir a Messi con Whisper\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n::: {.content-visible when-profile=\"english\"}\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n:::\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n::: {.content-visible when-profile=\"english\"}\n## Download audio and video from Youtube\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Descargo el audio y el video de Youtube\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Generate the transcript\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Genero la transcripción\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\n\n::: {.content-visible when-profile=\"english\"}\n## Embed the transcript in the video as subtitles\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Incrusto la transcripción en el video como subtítulos\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n```\n\n::: {.content-visible when-profile=\"english\"}\nHere is the final product, the video with the subtitles:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\nAquí el producto final, el video con los subtítulos:\n\n:::\n\n&lt;center&gt;\n&lt;video width=\"640\" height=\"480\" controls&gt;\n  &lt;source src=\"whisper_messi_corto_con_subs.mp4\" type=\"video/mp4\"&gt;\n&lt;/video&gt;\n&lt;/center&gt;\n\n\"\"\"\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_espanol.txt', 'r') as file:\n    posteo_espanol_ejemplo = file.read()\n\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_ingles.txt', 'r') as file:\n    posteo_ingles_ejemplo = file.read()\n\nwith open('posts/30-day-map-challenge-day-1-and-2/ejemplo_fusion.txt', 'r') as file:\n    posteo_fusionado_ejemplo = file.read()\nprint(posteo_fusionado_ejemplo)\n\n---\ntitle: Using Whisper to Transcribe Messi\nsubtitle: Transcribir a Messi con Whisper\nauthor: Martin Olmos\ndate: '2023-02-03'\nslug: []\ncategories:\n  - NLP\n  - IA\n  - ML\ntags:\n  - Whisper\n  - Messi\n---\n\n::: {.content-visible when-profile=\"english\"}\n[Whisper]('https://openai.com/blog/whisper/') is an open source model for speech recognition developed by [OpenAI](https://openai.com).\n\nWe will try to use it to add subtitles to a recent interview.\n\nHere is the original interview:\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n[Whisper]('https://openai.com/blog/whisper/') es un modelo de código abierto para reconocimiento del habla desarrollado por [OpenAI](https://openai.com).\n\nIntentaremos utilizarlo para agregar subtítulos a una entrevista reciente.\n\nAquí la entrevista original:\n\n:::\n\n&lt;center&gt;\n&lt;iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/RYXcR3YejwY\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen&gt;&lt;/iframe&gt;\n&lt;/center&gt;\n\n::: {.content-visible when-profile=\"english\"}\n## Download audio and video from Youtube\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Descargo el audio y el video de Youtube\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n```\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Generate the transcript\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n## Genero la transcripción\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)\n```\nwith open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/2021-11-06-30-days-map-challenge-dia-1-y-2/index.es.Rmd', 'r') as f:\n    posteo_espanol = f.readlines()\n\nwith open('/Users/martinolmos/Documents/datos_tic/content/english/post/2021-11-06-30-days-map-challenge-day-1-and-2/index.en.Rmd', 'r') as f:\n    posteo_ingles = f.readlines()\nposteo_espanol = \"\".join(posteo_espanol)\nposteo_ingles = \"\".join(posteo_ingles)\nimport re\n\nposteo_espanol = re.sub(r'\\`\\`\\`\\{r include=FALSE, message=FALSE}\\\\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\\\\n\\`\\`\\`', '', posteo_espanol)\n\nposteo_ingles = re.sub(r'```{r include=FALSE, message=FALSE}\\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\\n```', '', posteo_ingles)\npattern = r\"```{r\\s+include=FALSE,\\s+message=FALSE}\\nknitr::opts_chunk\\$set\\(echo\\s+=\\s+TRUE,\\s+message\\s+=\\s+FALSE,\\s+warning\\s+=\\s+FALSE\\)\\n```\"\n\nposteo_espanol = re.sub(pattern, '', posteo_espanol, flags=re.DOTALL)\nposteo_ingles = re.sub(pattern, '', posteo_ingles, flags=re.DOTALL)"
  },
  {
    "objectID": "utils/migration.html#day-map-challenge-day-3-and-4",
    "href": "utils/migration.html#day-map-challenge-day-3-and-4",
    "title": "30 day map challenge day 1 and 2",
    "section": "30 day map challenge day 3 and 4",
    "text": "30 day map challenge day 3 and 4\n\nwith open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/2021-11-09-30-day-map-challenge-dia-3-y-4/index.es.Rmd', 'r') as f:\n    posteo_espanol = f.read()\n\n# with open('/Users/martinolmos/Documents/datos_tic/content/english/post/2021-11-09-30-day-map-challenge-day-3-and-4/index.en.Rmd', 'r') as f:\n#     posteo_ingles = f.readlines()\n\n\nposteo_espanol_ingles_ejemplo = posteo_fusionado_ejemplo\n\n\ndef fusionar_posteo(posteo_espanol):\n    prompt = f\"\"\"\nTe voy a pasar un posteo de un blog en español y necesito que le agregues la traducción al inglés. \\\nEl posteo contiene texto en español y bloques de código. \nLo que necesito es que el texto en español lo enmarques entre `::: {{.content-visible when-profile=\"spanish\"}}` y ::: \\\ny a continuación agregues el texto traducido al inglés enmarcado entre `::: {{.content-visible when-profile=\"english\"}}` y `:::` .  \\\nLos bloques de código deben aparecer una sóla vez luego del texto en español e inglés. \\\nEl encabezado o YAML está demarcado por `---` al principio y al final. La idea es tener un encabezado con el título en inglés y el subtítulo en español. \\\n\nTe voy a mostrar un ejemplo:\n\nPosteo en español: \\\n{posteo_espanol_ejemplo} \\\n\nResultado esperado en español e inglés: \\\n{posteo_espanol_ingles_ejemplo}\n\nAhora transforma el siguiente posteo: \\\n\nPosteo en español: \\\n{posteo_espanol} \\\n\nResultado esperado en español e inglés: \\\n\n\"\"\"\n    response = get_completion(prompt)\n    return response.choices[0].message.content\n\n\nposteo_espanol_ingles = fusionar_posteo(posteo_espanol)\n\n\nprint(posteo_espanol_ingles)\n\n---\ntitle: 30 Day Map Challenge Day 3 and 4\nsubtitle: Día 3 y 4 del Desafío de Mapas de 30 Días\nauthor: Martin Olmos\ndate: '2021-11-09'\nslug: []\ncategories: []\ntags:\n  - 30daymapchallenge\n---\n\n::: {.content-visible when-profile=\"english\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n*Note: for those interested in the code used to generate each visualization, you can see it by clicking the \"Show/Hide All Code\" button at the top right of the page or the \"Code\" button above and to the right of each visualization.*\n\n## Day 3 - Polygons\n\nMobile network cells can be modeled using [Voronoi Diagrams][3]. Typically, this is done for mobility analysis with cellular signaling data, as shown in [this paper][5].\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n:::\n\n::: {.content-visible when-profile=\"english\"}\n## Day 4 - Hexagons\n\nHexagons can also be used to plot 4G radio bases, using color intensity to show their density.\n\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n:::\n\n[3]:https://en.wikipedia.org/wiki/Voronoi_diagram\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n\n\n\nfolder = 'posts/30-day-map-challenge-day-3-and-4/'\n\n# os.mkdir(folder)\n\nwith open(folder + 'index.qmd', 'w') as f:\n    f.write(posteo_espanol_ingles)\n\n\nprint(posteo_fusionado.choices[0].message.content)\n\n---\ntitle: 30 Day Map Challenge Day 3 and 4\nsubtitle: Día 3 y 4 del Desafío de Mapas de 30 Días\nauthor: Martin Olmos\ndate: '2021-11-09'\nslug: []\ncategories: []\ntags:\n  - 30daymapchallenge\n---\n\n::: {.content-visible when-profile=\"english\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n\n*Note: for thoses interested in the code for each visualization you can see it by pressing the \"Show All Code\" button at the top right of the page or by pressing the \"Code\" button above and to the right of each visualization.*\n\n## Day 3 - Polygons\n\nThe cells of mobile networks can be modeled using [Voronoi diagrams][3]. Typically this is done for mobility analysis with cell phone signaling data, as shown in [this paper][5].\n\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n## Day 4 - Hexagons\n\nHexagons can also be used to visualize 4G base stations, using the color intensity to show density.\n\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n[3]:https://es.wikipedia.org/wiki/Pol%C3%ADgonos_de_Thiessen\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n:::\n\n::: {.content-visible when-profile=\"spanish\"}\n```{r include=FALSE}\nknitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)\n```\n\n*Nota: para aquellos interesados en el código con el que se generó cada visualización pueden verlo presionando el botón \"Show/Hide All Code\" arriba a la derecha de la página o el botón \"Code\" arriba y a la derecha de cada visualización.*\n\n## Día 3 - Polígonos\n\nLas celdas de las redes móviles se pueden modelar mediante [Diagramas de Voronoi][3]. Típicamente esto se hace para análisis de movilidad con datos de señalización de los teléfonos celulares, como se muestra en [este paper][5]. \n\n```{r, eval=FALSE}\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_comuna1_map.png){width=75%}\n&lt;/center&gt;\n\n## Día 4 - Hexágonos\n\nPara graficar las radiobases 4G también se pueden utilizar hexágonos, utilizando la intesidad del color para mostrar la densidad de las mismas.\n\n```{r, eval=FALSE}\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())\n\n```\n\n&lt;center&gt;\n![](radiobases_4g_caba_map.png)\n&lt;/center&gt;\n\n[3]:https://es.wikipedia.org/wiki/Pol%C3%ADgonos_de_Thiessen\n[5]:https://www.researchgate.net/publication/260297863_Mobile_Phone_Location_Area_Based_Traffic_Flow_Estimation_in_Urban_Road_Traffic\n:::"
  },
  {
    "objectID": "utils/migration.html#cables-submarinos-de-internet",
    "href": "utils/migration.html#cables-submarinos-de-internet",
    "title": "30 day map challenge day 1 and 2",
    "section": "Cables Submarinos De Internet",
    "text": "Cables Submarinos De Internet\n\nposteos_ingles = os.listdir('/Users/martinolmos/Documents/datos_tic/content/english/post/')\n\n\nposteos_ingles = posteos.copy()\n\n\nposteos_ingles\n\n['2022-02-06-internet-submarine-cables',\n '2022-02-07-price-evolution',\n '2022-03-19-using-satellite-images',\n '2022-04-12-internet-fix-access-dashboard-in-argentina',\n '2022-04-20-ict-companies-social-network-analysis',\n '2022-06-17-forum-equality-digital-divide',\n '2023-01-08-beckham-vs-papu-gomez']\n\n\n\nposteos_espanol = os.listdir('/Users/martinolmos/Documents/datos_tic/content/spanish/post/')\n\n\n# remove 0,7,10,11\nposteos_espanol\n\n['2022-02-06-cables-submarinos-de-internet',\n '2022-02-07-evoluci-n-de-los-precios',\n '2022-03-19-usando-im-genes-satelitales',\n '2022-04-12-tablero-de-accesos-fijos-a-internet-en-argentina',\n '2022-04-19-an-lisis-de-empresas-tic-en-redes-sociales',\n '2022-06-17-foro-brechas-y-equidad-digital',\n '2023-01-08-beckham-vs-papu-gomez']\n\n\n\ndef fusionar_posteo(posteo_espanol, posteo_ingles):\n    prompt = f\"\"\"\nTe voy a pasar un posteo de un blog en español y en inglés y necesito que los fusiones de un modo particular. \n\nEl encabezado o YAML está demarcado por `---` al principio y al final. La idea es conservar un sólo encabezado, con el título en inglés y el subtítulo en español. \\\nLos textos entre cada bloque de código deben enmarcarse con `::: {{.content-visible when-profile=\"spanish\"}}` par el texto en español y `:::` y con `::: {{.content-visible when-profile=\"english\"}}` y `:::` para el texto en inglés.  \\ \nCada bloque de código debe aparecer una sóla vez luego del texto en español e inglés. \\\n\nLa estructura esperada es la siguiente: \\\n\n---\ntitle: Title in english\nsubtitle: Título en español\nauthor: Martin Olmos\n...\n\n::: {{.content-visible when-profile=\"english\"}}\n\nFirst text block in english. Should contain all text until the first code block.\n\n:::\n\n::: {{.content-visible when-profile=\"spanish\"}}\n\nPrimer bloque de texto en español. Debería contener todo el texto hasta el primer bloque de código.\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nFirst code block\n\n```\n\n::: {{.content-visible when-profile=\"english\"}}\n\nSecond text block in english. Should contain all text until the second code block.\n\n:::\n\n::: {{.content-visible when-profile=\"spanish\"}}\n\nSegundo bloque de texto en español. Debería contener todo el texto hasta el segundo bloque de código.\n\n:::\n\n```{python, eval=FALSE, echo=TRUE}\n\nSecond code block\n\n```\n\nAhora fusiona los siguientes posteos: \\\n\nPosteo en español: \\\n{posteo_espanol} \\\n\nPosteo en inglés: \\\n{posteo_ingles} \\\n\nPosteo fusionado esperado: \\\n\n\"\"\"\n    response = get_completion(prompt)\n    return response.choices[0].message.content\n\n\nfor i in range(len(posteos_ingles)):\n    with open('/Users/martinolmos/Documents/datos_tic/content/english/post/' + posteos_ingles[i] + '/index.en.Rmd', 'r') as fi:\n        posteo_ingles = fi.read()\n    \n    with open('/Users/martinolmos/Documents/datos_tic/content/spanish/post/' + posteos_espanol[i] + '/index.es.Rmd', 'r') as fe:\n        posteo_espanol = fe.read()\n\n    response = fusionar_posteo(posteo_espanol, posteo_ingles)\n\n    folder = re.sub(\"\\d{4}-\\d{2}-\\d{2}-\", \"\", posteos_ingles[i])\n\n    os.mkdir('posts/' + folder)\n\n    with open('posts/' + folder + '/index.qmd', 'w') as fw:\n        fw.write(response)\n\n\nre.sub(\"\\d{4}-\\d{2}-\\d{2}-\", \"\", posteos_ingles[1])\n\n'price-evolution'\n\n\n\nwith open('prueba.qmd', 'w') as fw:\n    fw.write()\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"BID: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Consultor asociado\", \"Experiencia profesional\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Consultor en Ciencia de Datos y TICs\", \"Experiencia profesional\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Docente en Gobierno Abierto y Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Docente en Nuevas Tecnologías\", \"Actividad docente\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Maestría en Ciencia de Datos\", \"Formación académica\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Subsecretario de TICs\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Especialización en Ciencia de Datos\", \"Formación académica\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Director Ejecutivo\", \"Experiencia profesional\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Consultor en Ciencia de Datos\", \"Experiencia profesional\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Formación académica\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Jefe Regional de Ciudad de Buenos Aires\", \"Experiencia profesional\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Experiencia profesional\": \"lightskyblue\",\n    \"Actividad docente\": \"palegreen\",\n    \"Formación académica\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Año')\nplt.title('Línea de Tiempo CV Martin Olmos')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"IDB: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Associate Consultant\", \"Professional Experience\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Instructor in Open Government and New Technologies\", \"Teaching Activity\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Instructor in New Technologies\", \"Teaching Activity\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Master's in Data Science\", \"Academic Training\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Deputy Secretary of ICTs\", \"Professional Experience\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Specialization in Data Science\", \"Academic Training\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Executive Director\", \"Professional Experience\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Data Science Consultant\", \"Professional Experience\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Academic Training\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Regional Head of Buenos Aires City\", \"Professional Experience\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Professional Experience\": \"lightskyblue\",\n    \"Teaching Activity\": \"palegreen\",\n    \"Academic Training\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Year')\nplt.title('Martin Olmos CV Timeline')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()"
  }
]