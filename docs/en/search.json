[
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\n# Activity data\nfechas = [\n    (\"01/09/2023\", \"31/01/2024\", \"IDB: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/03/2023\", \"31/01/2024\", \"BNMC: Associate Consultant\", \"Professional Experience\"),\n    (\"01/02/2023\", \"31/01/2024\", \"CAF: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/07/2022\", \"31/01/2024\", \"UNSAM: Instructor in Open Government and New Technologies\", \"Teaching Activity\"),\n    (\"01/06/2021\", \"31/01/2024\", \"PELI: Instructor in New Technologies\", \"Teaching Activity\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Master's in Data Science\", \"Academic Training\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Deputy Secretary of ICTs\", \"Professional Experience\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Specialization in Data Science\", \"Academic Training\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Executive Director\", \"Professional Experience\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Data Science Consultant\", \"Professional Experience\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Academic Training\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Regional Head of Buenos Aires City\", \"Professional Experience\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Professional Experience\": \"lightskyblue\",\n    \"Teaching Activity\": \"palegreen\",\n    \"Academic Training\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Year')\nplt.title('Martin Olmos CV Timeline')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nI have a degree in Political Science (Universidad Católica Argentina - UCA), a Masters degree in Public Policy (George Washington University - GWU) and a Specialization in Data Science (Instituto Tecnológico de Buenos Aires - ITBA).\n\nEDUCATION\n2022 MASTER IN DATA SCIENCE\n(Thesis in progress) Instituto Tecnológico de Buenos Aires (ITBA)\n2018 SPECIALIZATION IN DATA SCIENCE\nInstituto Tecnológico de Buenos Aires (ITBA)\n2016 MASTER IN PUBLIC POLICY\nTrachtenberg School of Public Policy and Public Administration\nGeorge Washington University\n2003 DEGREE IN POLITICAL SCIENCE\nFacultad de Ciencias Políticas y Relaciones Internacionales. Pontificia Universidad Católica Argentina. Buenos Aires, Argentina.\n\n\nPROFESIONAL AND TEACHING BACKGROUND\n9/2023- present day INTER-AMERICAN DEVELOPMENT BANK\nResponsibility: Consultant on Data Science and ICTs\n3/2023- present day BLUENOTE MANAGEMENT CONSULTING\nResponsibility: Associate Consultant\n2/2023- present day CAF LATIN AMERICAN DEVELOPMENT BANK\nResponsibility: Consultant on Data Science and ICTs\n7/2022- present day DIPLOMA ON CITY MANAGEMENT - ESCUELA DE ECONOMÍA Y NEGOCIOS – UNIVERSIDAD NACIONAL DE SAN MARTÍN\nResponsibility: Professor on Open Government and New Technologies\n12/2019-03/2022 UNDERSECRETARY OF INFORMATION AND COMMUNICATIONS TECHNOLOGIES OF THE CHIEF OF CABINET OF ARGENTINA\n6/2021-9/2021 EXECUTIVE PROGRAM ON INNOVATIVE LEADERSHIP – OEI, ILES, SECRETARÍA DE ASUNTOS ESTRATÉGICOS DE LA REPÚBLICA ARGENTINA\nResponsibility: Professor on New Technologies\n*4/2017-11/2019 INSTITUTO CIUDAD – POLÍTICAS PÚBLICAS PARA BUENOS AIRES\nResponsibility: Executive Director\n8/2019-present day INTRODUCTORY SEMINAR ON DATA SCIENCE FOR SOCIAL SCIENCES – FACULTAD DE CIENCIAS SOCIALES (UBA)\nResponsibility: Professor\n2/2019-present day THE CARPENTRIES – DATA CARPENTRY\nResponsibility: Instructor\n7/2018-11/2019 DIRECCIÓN DE IMPLEMENTACIÓN Y SEGUIMIENTO SUBE – MINISTERIO DE TRANSPORTE DE LA NACIÓN\nResponsibility: Consultant on data science\n8/2018-6/2019 SECRETARÍA DE ASUNTOS PÚBLICOS – MUNICIPALIDAD DE SAN MIGUEL\nResponsibility: Consultant on data science\n2/2018-8/2018 ORGANISMO PROVINCIAL PARA EL DESARROLLO SOSTENIBLE\nResponsibility: Consultant on data science\n1/2017-6/2018 CONVENIO MINISTERIO DE TRANSPORTE-UNSAM\nResponsibility: Consultant on data science\n5/2015-12/2016 BANCO DE DESARROLLO DE AMÉRICA LATINA (CAF)\nResponsibility: Consultant on data science\n11/2009-12/2014 ADMINISTRACIÓN NACIONAL DE LA SEGURIDAD SOCIAL\nResponsibility: Regional Chief for Buenos Aires City.\n\n\nFELLOWSHIPS\n2016 ORGANIZATION OF AMERICAN STATES (OAS) FELLOWSHIP FOR GRADUATE STUDIES.\n2015 GLOBAL LEADERS FELLOWSHIP 2015-2016 , GEORGE WASHINGTON UNIVERSITY.\n2015 FULBRIGHT FELLOWSHIP FOR MASTER STUDIES 2015-2016 , COMISIÓN FULBRIGHT ARGENTINA.\n2013 IV FORO “EL FUTURO DE AMÉRICA LATINA: LA VISIÓN DE LOS JÓVENES LÍDERES” , CAF – BANCO DE DESARROLLO DE AMÉRICA LATINA A PARTICIPAR, CIUDAD DE MÉXICO, 22 Y 23 DE AGOSTO DE 2013.\n2013 PROGRAMA DE GOBIERNO PARA EL DESARROLLO DE LÍDERES DE COMUNIDADES LOCALES. CENTRO DE ESTUDIOS EN GOBIERNO, EMPRESA, SOCIEDAD Y ECONOMÍA, IAE BUSINESS SCHOOL, UNIVERSIDAD AUSTRAL, PILAR, PROVINCIA DE BUENOS AIRES, MAYO Y JUNIO DE 2013. BECA OTORGADA POR LA FUNDACIÓN RAP (RED DE ACCIÓN POLÍTICA).\n2005 FURP-USA PROGRAM, DEPARTMENT OF STATE OF THE UNITED STATES OF AMERICA. FEBRUARY 2005.\n\n\nINTERNATIONAL CONFERENCES AND ACTIVITIES\n\nJune 2022\n\nOrganized by | Cámara Chilena de Infraestructura Digital y Asociación Chilena de Municipalidades\nEvent | Forum on Equality and Digital Divide\nPanel | The role of universal access funds\n\nMarch 2022\n\nOrganized by | GSMA\nEvent | Ministerial Programme - Mobile World Congress (MWC)\n\nFebruary 2022\n\nOrganized by | Unión Internacional Telecomunicaciones (ITU)\nEvent | 4th Global Standards Symposium\nPanel | International Standards for Digital Transformation\n\nNovember 2021\n\nOrganized by | Forum Europe (Forum Global)\nEvent | Latin America Spectrum Management Conference\nTema | The Emerging Shape of the 6GHz Band\n\nJune 2021\n\nOrganized by | GSMA\nEvent | Spectrum Roundtable at the Ministerial Programme - Mobile World Congress (MWC)\nRoundtable | The Future of Spectrum Access\n\nNovember 2020\n\nOrganized by | Forum Europe (Forum Global)\nEvent | Latam Spectrum Conference\nTema | Bridging the Digital Divide – How Has Covid Shone a Light on Digital Inequalities and How Can the Region Move Forward in Tackling This Issue?\n\nOctober 2020\n\nOrganized by | International Institute of Communications\nTema | Digital Transformation Post COVID-19: LatAm Responses to the Digital Divide.\n\nJuly 2020\n\nOrganized by | ITU, GeSI & the United Nations Office for South South Cooperation.\nPanel | Accelerating Action and Transformative Pathways for Delivering on the Sustainable Development Goals and Recovery from COVID-19 Pandemic.\n\n\nNATIONAL CONFERENCES AND ACTIVITIES\n\nMay 2021\n\nOrganized by | CABASE\nEvent | Internet Day\nPanel | Infrastructure development initiatives for universal connectivity\nOrganized by | ISOC Argentinean Chapter and Facultad de Ingeniería de Universidad de Palermo\nEvent | 5tas Jornadas sobre Perspectivas de las Telecomunicaciones y TICs 2021\nPanel | Desafíos Actuales de las Telecomunicaciones\n\nApril 2021\n\nOrganized by | Grupo Convergencia\nEvent | NPlay Cono Sur\nTema | Programms to Reduce the Digital Divide and Infrastructure Sharing\n\nDecember 2020\n\nOrganized by | Grupo Convergencia\nTema | Infrastructure and Network Deployment for Growth in the New Normal\nOrganized by | Internet Governance Forum (IGF)\nTema | Algorithms and AI Governance\n\nAugust 2020 – March 2022\n\nOrganized by | BID - INTAL\nProgram | Regional Program for Latin America and the Caribbean Integration to the Digital Economy\nPosition | Member of the Board"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html",
    "href": "posts/transcribe-messi-using-whisper/index.html",
    "title": "Using Whisper to Transcribe Messi",
    "section": "",
    "text": "Whisper is an open source model for speech recognition developed by OpenAI.\nWe will try to use it to add subtitles to a recent interview.\nHere is the original interview:"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#download-audio-and-video-from-youtube",
    "href": "posts/transcribe-messi-using-whisper/index.html#download-audio-and-video-from-youtube",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Download audio and video from Youtube",
    "text": "Download audio and video from Youtube\n\n\nCode\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\n:::"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#generate-the-transcript",
    "href": "posts/transcribe-messi-using-whisper/index.html#generate-the-transcript",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Generate the transcript",
    "text": "Generate the transcript\n\n\nCode\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#embed-the-transcript-in-the-video-as-subtitles",
    "href": "posts/transcribe-messi-using-whisper/index.html#embed-the-transcript-in-the-video-as-subtitles",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Embed the transcript in the video as subtitles",
    "text": "Embed the transcript in the video as subtitles\n\n\nCode\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n\nHere is the final product, the video with the subtitles:"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "",
    "text": "Note: for those interested in the code used to generate each visualization, you can see it by clicking the “Show/Hide All Code” button at the top right of the page or the “Code” button above and to the right of each visualization."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#day-3---polygons",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#day-3---polygons",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Day 3 - Polygons",
    "text": "Day 3 - Polygons\nMobile network cells can be modeled using Voronoi Diagrams. Typically, this is done for mobility analysis with cellular signaling data, as shown in this paper.\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#day-4---hexagons",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#day-4---hexagons",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Day 4 - Hexagons",
    "text": "Day 4 - Hexagons\nHexagons can also be used to plot 4G radio bases, using color intensity to show their density.\n\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "posts/beckham-vs-papu-gomez/index.html",
    "href": "posts/beckham-vs-papu-gomez/index.html",
    "title": "Beckham vs. Papu Gomez",
    "section": "",
    "text": "This post is not about ICTs. It’s about using AI to classify images. In this case we take a controversy that came up during the World Cup in a stream of Kun Aguero, where Lio Messi and Papu Gomez asked Kun to guess who Papu looks like, after his new haircut.\n\n\n\n\nAfter that, a controversy was opened. Does Papu Gomez look like David Beckham? That’s why I decided to train an AI model to classify images of both players. I have to say that after this I came to the conclusion that they have some similarity, since I had to go from simpler to more complex models so that it could learn to distinguish between the two.\nYou can try the application below or in the following link"
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "title": "REFEFO Potential to Enhance Productive Connectivity",
    "section": "",
    "text": "Most countries in the region have some sort of strategy to improve digital connectivity for vulnerable populations, for those who live in low density areas where the private sector alone does not have the incentives to invest in infrastructure, or to bring connectivity to education and health services. However, we cannot say the same about productive connectivity, meaning, connectivity infrastructure oriented towards improving the productivity of companies and workers.\nAn important prerequisite for bringing connectivity to a place is the existance of backbone networks that allow the development of the so-called “last mile” to connect homes and businesses. Argentina, for example, has the Federal Fiber Optic Network (REFEFO) managed by ARSAT, which is a backbone network that goes through the 23 provinces of the country, reaching about 1,300 localities, many of which have populations of less than 10,000 people. Of course, there are also other backbone fiber optic networks of private operators, but the layout of these networks and the location of the connection nodes is not publicly available.\nBut going back to the previous point, let’s analyze the potential of REFEFO to improve productive connectivity. Let’s take for example the agricultural sector, which is one of the most important in the Argentine economy and the most important regarding exports.\nWe can use data from the former Ministry of Productive Development to georeference agricultural companies and calculate the distance of each of them to the nearest REFEFO node and then analyze the distribution of these distances.\nFirst, we will obtain, filter and merge the necessary data for the analysis:\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n# Cruzo los establecimientos agropecuarios con el nodo de REFEFO más cercano y obtengo la distancia\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\nThen we will plot on a map each of the agricultural establishments and assign a color based on the distance to the nearest REFEFO node.\n\n\nCode\nfrom matplotlib import cm\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\nMapa de Establecimientos Agropecuarios y Distancia a Nodo de REFEFO\n\n\nAlso, we will plot the histogram of the distances to analyze their distribution.\n\n\nCode\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n\n\n\n\nHistograma de Distancias a Nodo de REFEFO\n\n\nAs you can see in the map and in the histogram, most of the agricultural establishments are located less than 10 km from a REFEFO node. To get the precise numbers let’s take a look at the mean and the quartiles of the distances.\n\n\nCode\nestab_agro_refefo_gpd['distance'].describe()\n\n\nThe mean distance of agricultural establishments to the nearest REFEFO node is 25,544 meters or 25.5 KMs. However, as observed in the histogram, the distances do not have a normal distribution but rather a right-skewed distribution, with most distances having low values and a few distances having very high values. In these cases, the median is more representative than the mean. Here the median is 8,580 meters or 8.6 KMs. This means that 50% of the agricultural establishments are located less than 8.6 KMs from a REFEFO node. Finally, the third quartile is 35,895 meters or almost 36 KMs, which means that 75% of the agricultural establishments are located less than 36 KMs from a REFEFO node.\nThere are many ways in which we can improve this preliminary analysis but this first approach seems to indicate that the distance to backbone networks should not be an obstacle for the development of productive rural connectivity in Argentina."
  },
  {
    "objectID": "posts/using-satellite-images/index.html",
    "href": "posts/using-satellite-images/index.html",
    "title": "Using Satellite Images",
    "section": "",
    "text": "Satellite remote sensing or satellite remote sensing is the activity of collecting data through the use of sensors, in this case satellites, from a place to which there is no physical access, that is, remotely.\nThese data consist of the measurement of electromagnetic energy. Electromagnetic radiation is a form of energy emitted by all matter with a temperature above absolute zero (0 Kelvin or -272° Celcius). X-rays, ultraviolet, visible light, infrared, heat, microwaves, and radio and television waves are all forms of electromagnetic energy with different wavelengths or frequencies and are part of the electromagnetic spectrum.\nHotter objects emit more electromagnetic energy and shorter wavelengths than cooler ones. The most common source of electromagnetic radiation is the Sun. Objects that make up the Earth’s surface reflect and emit electromagnetic radiation in different ways.\nThe portion of the electromagnetic spectrum where the peak of solar radiation is located is called the visible band, since human vision is sensitive to these waves. Remote sensing allows us to extend the human ability to perceive electromagnetic radiation beyond the visual band, so the parts of the electromagnetic spectrum that we cannot see are very important.\nThe objects that make up the Earth’s surface reflect electromagnetic radiation in different ways. The appeal of multispectral remote sensing is that objects indistinguishable at one wavelength may be easy to distinguish at another. The bands commonly used to perceive occupation and land use are: visible, infrared and microwave.\nUnderstanding the different ways in which specific wavelengths interact with different objects allows finding “stamps” or “signatures” that will allow those objects to be detected automatically.\nThe applications are diverse: monitoring of deforestation, soil degradation, detection and classification of objects as dissimilar as wetlands, informal settlements and gated communities, monitoring of water quality and salinity, air quality, detection of clandestine dumps, monitoring of landfills health, monitoring the environmental impact of certain industries, among others.\nIn this post I am not going to advance in detection or classification of objects but, following this tutorial I am going to use satellite images together with SRTM elevation data to make a 3D map of my favorite place in the world: the Cuesta del Viento Dam in Rodeo, San Juan.\nHere is the code:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nAnd the resulting visualization:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#brief-concept-intro1",
    "href": "posts/using-satellite-images/index.html#brief-concept-intro1",
    "title": "Using Satellite Images",
    "section": "",
    "text": "Satellite remote sensing or satellite remote sensing is the activity of collecting data through the use of sensors, in this case satellites, from a place to which there is no physical access, that is, remotely.\nThese data consist of the measurement of electromagnetic energy. Electromagnetic radiation is a form of energy emitted by all matter with a temperature above absolute zero (0 Kelvin or -272° Celcius). X-rays, ultraviolet, visible light, infrared, heat, microwaves, and radio and television waves are all forms of electromagnetic energy with different wavelengths or frequencies and are part of the electromagnetic spectrum.\nHotter objects emit more electromagnetic energy and shorter wavelengths than cooler ones. The most common source of electromagnetic radiation is the Sun. Objects that make up the Earth’s surface reflect and emit electromagnetic radiation in different ways.\nThe portion of the electromagnetic spectrum where the peak of solar radiation is located is called the visible band, since human vision is sensitive to these waves. Remote sensing allows us to extend the human ability to perceive electromagnetic radiation beyond the visual band, so the parts of the electromagnetic spectrum that we cannot see are very important.\nThe objects that make up the Earth’s surface reflect electromagnetic radiation in different ways. The appeal of multispectral remote sensing is that objects indistinguishable at one wavelength may be easy to distinguish at another. The bands commonly used to perceive occupation and land use are: visible, infrared and microwave.\nUnderstanding the different ways in which specific wavelengths interact with different objects allows finding “stamps” or “signatures” that will allow those objects to be detected automatically.\nThe applications are diverse: monitoring of deforestation, soil degradation, detection and classification of objects as dissimilar as wetlands, informal settlements and gated communities, monitoring of water quality and salinity, air quality, detection of clandestine dumps, monitoring of landfills health, monitoring the environmental impact of certain industries, among others.\nIn this post I am not going to advance in detection or classification of objects but, following this tutorial I am going to use satellite images together with SRTM elevation data to make a 3D map of my favorite place in the world: the Cuesta del Viento Dam in Rodeo, San Juan.\nHere is the code:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nAnd the resulting visualization:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#footnotes",
    "href": "posts/using-satellite-images/index.html#footnotes",
    "title": "Using Satellite Images",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn base al MOOC “Imagery, Automation, and Applications” de la Universidad de California, Davis y al libro de David DiBiase, The Nature of Geographic Information. Penn State University, College of Earth and Mineral Sciences. Retrieved from https://www.e-education.psu.edu/natureofgeoinfo/↩︎"
  },
  {
    "objectID": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "href": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "title": "Internet Fix Access Dashboard for Argentina",
    "section": "",
    "text": "It is possible to make a dashboard with basic data on fix access in Argentina very quickly (about 30 minutes), with open data from ENACOM, open source tools (in this case R, Plotly and Flexdashboards but there are many others) and deploy it online for free with Github Pages.\nHere you can see the dashboard online (in Spanish): https://martinolmos.github.io/tablero_accesos_fijos/\nAnd the code to acquire the data and generate the visualizations:\n\nFixed Accesses per 100 Households by Province\n\n# Penetracion por provincia: accesos cada 100 hogares\npen_prov_hog &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275028/data.csv\", \n                         n_max = 24, \n                         locale = locale(decimal_mark = \",\"))\n\npen_prov_hog_plot &lt;- pen_prov_hog %&gt;% \n  ggplot(aes(x = reorder(Provincia, `Accesos por cada 100 hogares`),\n             y = `Accesos por cada 100 hogares`,\n             text = Provincia)) +\n  geom_col(data=pen_prov_hog, aes(x=reorder(Provincia, `Accesos por cada 100 hogares`)), fill = \"red\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.text.y = element_text(size = 6), axis.title = element_blank())\n\nggplotly(pen_prov_hog_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of Accesses per 100 people\n\n# Penetración: accesos cada 100 habitantes. Serie histórica\npen_nac_hab_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/281491/data.csv\",\n                              locale = locale(decimal_mark = \",\"))\n\npen_nac_hab_serie_plot &lt;- pen_nac_hab_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Accesos por cada 100 hab`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title = element_blank())\n\nggplotly(pen_nac_hab_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of the Average Download Speed\n\n# Velocidad Media de Descarga (Mbps) - Nacional\nvmd_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275016/data.csv\", col_names = c(\"Año\", \"Trimestre\", \"Velocidad Media de Descarga\", \"Periodo\"), skip = 1,\n                          locale = locale(decimal_mark = \",\"))\n\nvmd_nac_serie_plot &lt;- vmd_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Velocidad Media de Descarga`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  labs(y = \"VMD en Mbps\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title.x = element_blank())\n\nggplotly(vmd_nac_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of Fix Accesses by Technology\n\ntec_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275029/data.csv\",\n                          locale = locale(decimal_mark = \",\"))\n\ntec_nac_serie &lt;- tec_nac_serie %&gt;% \n  select(-Total) %&gt;% \n  gather(Tecnología, Accesos, ADSL:Otros)\n\ntec_nac_serie_plot &lt;- tec_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = Accesos,\n             group = Tecnología,\n             color = Tecnología,\n             text = Periodo)) +\n  geom_line() +\n  scale_y_continuous(labels = c(\"0\", \"2M\", \"4M\", \"6M\")) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), \n        axis.title = element_blank(), \n        legend.title = element_blank())\n\nggplotly(tec_nac_serie_plot, tooltip = c(\"text\", \"color\", \"y\")) %&gt;% \n  layout(legend = list(title = \"\", \n                       orientation = \"h\",\n                       y = 1.3))"
  },
  {
    "objectID": "posts/internet-submarine-cables/index.html",
    "href": "posts/internet-submarine-cables/index.html",
    "title": "Internet Submarine Cables",
    "section": "",
    "text": "Some time ago Tyler Morgan-Wall made a visualization of all the submarine internet cables with Telegeography data.\nTyler posted the code in this gist. I decided to reproduce the visualization with a little modification to add a title and change earth´s rotation direction.\nHere is the modification to the last for loop to add the title:\n\nfor(i in seq(1,720,by=1)) {\n  tmp &lt;- group_objects(fullcablescene,scale=c(1,1,1)*1.02) %&gt;% \n    add_object(sphere(radius=0.99,material=diffuse(image_texture = \"2k_earth_daymap.jpg\"),angle=c(0,-90,0))) %&gt;% \n    group_objects(angle=c(0,-i/2,0)) %&gt;% \n    add_object(sphere(y=5,z=5,x=5,material=light(intensity = 80,color=\"lightblue\"))) %&gt;% \n    add_object(sphere(y=5,z=5,x=-5,material=light(intensity = 10,color=\"orange\"))) %&gt;% \n    add_object(sphere(y=-10,material=light(intensity = 3,color=\"white\"))) %&gt;%\n    render_scene(samples=64,width=1200,height=1200,fov=0,aperture=0, ortho_dimensions = c(2.3,2.3),\n                 sample_method = \"sobol_blue\",parallel = TRUE,return_raw_array = TRUE)\n  rayimage::add_title(image = tmp,\n                      title_text = \"https://martinolmos.github.io/datos_tic/\",\n                      title_color = \"orange\",\n                      title_position = \"north\",\n                      filename = sprintf(\"imgs/smallcables%d.png\",i))\n}\n\nAnd here is the code to change the direction of earth´s rotation:\n\nav::av_encode_video(sprintf(\"imgs/smallcables%d.png\", seq(720,1,by=-1)), \n                    framerate = 30, \n                    output = \"cables.mp4\")\n\nAnd finally the new visualization:\n\nVideo"
  },
  {
    "objectID": "posts/price-evolution/index.html",
    "href": "posts/price-evolution/index.html",
    "title": "ICT Prices Evolution",
    "section": "",
    "text": "Let’s see what was the evolution of prices of ICT services in Argentina in recent years.\nIf we take the time-series of the communications chapter of the INDEC Consumer Price Index (IPC-COM) we see that since the beginning of the series (Dec-2016=100) prices of communication services were above the general index until 2020, where the IPC-COM flattens and then goes below the general index.\n\n\n\nLet’s analyze in particular the years 2020 and 2021. First, 2020: if we look at the cumulative annual variation, the IPC-COM rises above the general IPC with the increase in March, which was partially reversed in April (the increase in prepaid mobile and fixed telephony, but not postpaid and mixed mobile) and then the IPC plateaus first due to the price agreement until July 31 and then due to the freeze imposed by DNU 690/2020 until December 31.\n\n\n\nNow let’s look at the year 2021:\n\n\n\n\nAs we can see, both 2020 and 2021 were years where price increases in ICTs were well below the increases in the general index.\nNote: according to COICOP Argentina, the Communications Chapter of the IPC does not include only ICT services but also the price of equipment and does not include prices of pay television services, which are reflected in the Chapter of Recreation and Culture.\nNow let’s see how we rank against other countries in the region in terms of affordability. The International Telecommunication Union (ITU) compiles standardized price statistics of price baskets for fixed and mobile services. Some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn these time-series, Argentina only seems to be doing well in mobile broadband (only data).\nNote: these time-series only includes 2018, 2019 and 2020 because in 2017 there was a change in methodology. For more information see here."
  },
  {
    "objectID": "posts/ict-companies-social-network-analysis/index.html",
    "href": "posts/ict-companies-social-network-analysis/index.html",
    "title": "ICT Companies Social Network Analysis",
    "section": "",
    "text": "Natural Language Processing or NLP is the field of study on computational analysis of human language. This area of knowledge includes a very wide variety of techniques and applications. One of them, within the field of language analysis and comprehension, is Sentiment Analysis, an application that allows a text to be classified according to its positive, negative or neutral charge or polarity.\nIn this post, with a few lines of python code we’ll do the following tasks:\n\nConnect to the Twitter API\nDownload the latest tweets that mention certain ICT companies\nUse a pre-trained machine learning model to perform sentiment analysis of these tweets\nVisualize the results\n\nThe pre-trained model that we are going to use is RoBERTuito, a model trained with 500 million tweets in Spanish. The authors of the paper/model made it available through the platform HuggingFace and the library pysentimento to facilitate NLP research and applications in Spanish.\nClarification 1: It is natural and expected that mentions of ICT companies in social media have a negative sentiment, since it is one of the channels for submitting complaints and, as it is a paid service, it is unusual to post a positive comment in case there are no problems with the service.\nClarification 2: to access the tweets, it is necessary to first apply for authentication credentials at Twitter for Developers. Once you have the credentials you should save them in a file called search_tweets_creds.yml with the following structure:\nsearch_tweets_api:\n    bearer_token: MY_BEARER_TOKEN\n    endpoint: https://api.twitter.com/2/tweets/search/recent\nTo obtain the tweets I will use the searchtweets-v2 library, a Python Client for the Twitter API Version 2.\nUse the following code for authentication and to obtain the last 100 tweets that mention each of the companies of interest:\n\nfrom searchtweets import load_credentials, ResultStream, gen_request_parameters, collect_results\n\nsearch_args = load_credentials(filename=\"search_tweets_creds.yml\", \n                               yaml_key=\"search_tweets_api\",\n                               env_overwrite=False)\n\nempresas = [\"Telecentro\", \"MovistarArg\", \"ClaroArgentina\", \"PersonalAr\"]\nempresas_tweets = dict()\n\nfor empresa in empresas:\n    query = gen_request_parameters(empresa, results_per_call=100, granularity=None)\n    tweets = collect_results(query,\n                             max_tweets=100,\n                             result_stream_args=search_args)\n    empresas_tweets[empresa] = tweets[0]['data']\n\nPre-process tweets, apply sentiment analysis and extract the category for each of the tweets and companies:\n\nfrom pysentimiento import create_analyzer\n\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\", model_name=\"pysentimiento/robertuito-sentiment-analysis\")\n\nempresas_tweets_sent = dict()\nempresas_tweets_sent_out = dict()\n\nfor empresa in empresas:\n    empresas_tweets_sent[empresa] = [analyzer.predict(tuit) for tuit in empresas_tweets_proc[empresa]]\n    empresas_tweets_sent_out[empresa] = [tuit.output for tuit in empresas_tweets_sent[empresa]]\n\nVisualize the results:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nempresas_tweets_sent_count = dict()\nfig, axes = plt.subplots(2, 2, figsize=(8, 6),dpi=144)\n\nplt.suptitle(\"Análisis de Sentimientos de Empresas TIC\")\n\narray_index = [(0,0), (0,1), (1,0), (1,1)]\naxes_title_font_size = 10\n\nfor empresa, index in zip(empresas, array_index):\n    empresas_tweets_sent_count[empresa] = np.unique(empresas_tweets_sent_out[empresa], return_counts=True)\n    axes[index].pie(empresas_tweets_sent_count[empresa][1], labels=empresas_tweets_sent_count[empresa][0], wedgeprops=dict(width=.5), autopct='%1.f%%')\n    axes[index].set_title(empresa, fontsize=axes_title_font_size)"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html",
    "href": "posts/ict-infra-subsidies-analysis/index.html",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "",
    "text": "In Argentina, as in many other countries, there is a fund made up of contributions from companies in the ICT sector with the goal of bringing services to populations that have no access to them for various reasons. In this post, I participated in a panel where I talked about the history of this fund in Argentina, called the Universal Service Trust Fund (FFSU), its regulatory framework and the different programs it has today.\nIn this post, I will develop a small exploratory analysis of some of the data regarding the two most important programs of the FFSU: the Connectivity Program and the Vulnerable Neighborhoods Program. The analysis covers the years between 2020 and 2023, for which data is available. The data was extracted from the minutes of the meetings of the Board of Directors of the National Communications Entity (ENACOM), which are published in PDF on the agency’s website."
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#connectivity-program",
    "href": "posts/ict-infra-subsidies-analysis/index.html#connectivity-program",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Connectivity Program",
    "text": "Connectivity Program\n\n\nCode\n# Me conecto a la base de datos y leo la tabla del Programa Conectividad\n# Connect to the database and read the Conectividad Program table\n\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine\nimport os\nimport pandas as pd\n\nload_dotenv()\n\nhost = os.getenv(\"HOST\")\nport = os.getenv(\"PORT\")\ndatabase = os.getenv(\"DBNAME\")\nuser = os.getenv(\"USER\")\npassword = os.getenv(\"PASSWD\")\n\nengine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n\nanr_prog_con = pd.read_sql_table(table_name=\"conectividad_aprob_georef\", con=engine)\n\n\nThe Figure 1 shows the number of localities that were beneficiaries from ANRs from the Connectivity Program approved by province, between 2020 and 2023.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_con.groupby(\"provincia_indec\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 1: Localidades beneficiarias de ANRs del Prog. Conectividad por provincia\n\n\n\nThe Figure 2 shows the number of localities that were beneficiaries of ANRs from the Connectivity Program by year.\n\n\nCode\nanr_prog_con['anio'] = anr_prog_con['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_con.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 2: Localidades beneficiarias de ANRs del Prog. Conectividad por año\n\n\n\nThe Figure 3 shows the number of localities that were beneficiairies from ANRs from the Connectivity Program by year and province.\n\n\nCode\nimport textwrap\n\nanr_prog_con_prov_anio = anr_prog_con.groupby(['anio', 'provincia_indec']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(4,1)\n\nfor i, anio in enumerate(anr_prog_con_prov_anio.index):\n    anr_prog_con_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigure 3: Localidades beneficiarias de ANRs del Prog. Conectividad por año y provincia"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#vulnerable-neighborhoods-program",
    "href": "posts/ict-infra-subsidies-analysis/index.html#vulnerable-neighborhoods-program",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Vulnerable Neighborhoods Program",
    "text": "Vulnerable Neighborhoods Program\n\n\nCode\n# Me conecto a la base de datos y leo la tabla del Programa Barrios Populares\n# Connect to the database and read the Barrios Populares Program table\n\nimport geopandas as gpd\n\nanr_prog_renabap = gpd.read_postgis(\"SELECT * FROM renabap_aprob\", con=engine, geom_col=\"geometry\")\n\n\nThe Figure 4 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by province, between 2021, the year in which the program began, and 2023.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_renabap.groupby(\"provincia\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 4: Barrios beneficiados con ANRs del Prog. Barrios Populares por provincia\n\n\n\nThe Figure 5 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by year.\n\n\nCode\nanr_prog_renabap['anio'] = anr_prog_renabap['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_renabap.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 5: Barrios beneficiados con ANRs del Prog. Barrios Populares aprobados por año\n\n\n\nThe Figure 6 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by year and province.\n\n\nCode\nimport textwrap\n\nanr_prog_renabap_prov_anio = anr_prog_renabap.groupby(['anio', 'provincia']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(3,1)\n\nfor i, anio in enumerate(anr_prog_renabap_prov_anio.index):\n    anr_prog_renabap_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigure 6: Barrios beneficiados por ANRs del Prog. Barrios Populares aprobados por año y provincia\n\n\n\nBeyond these graphs about the number of localities and vulnerable neighborhoods that were beneficiaries, it would be interesting to analyze the impact of these programs on the connectivity of the beneficiary populations. We will try to approach this issue in a future post."
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n\n\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:25: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:28: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib import cm\nimport matplotlib as mpl\n\n# cmap = cm.coolwarm\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\n\n\n\n\nestab_agro_refefo_gpd.head()\n\n\n\n\n\n\n\n\n\ncuit\nsucursal\nanio\nlat\nlon\nclae6\nin_departamentos\nprovincia_id\nquintil\nempleo\n...\nCUICOM\nNivAcc\nLocalidad\nDepartamen\nProvincia\nOPERAT\nOBSERV\nLongitud\nLatitud\ndistance\n\n\n\n\n2\n41X8684801PW69\n1\n2021\n-31.831\n-68.538\n13019\n70070\n70\n0\na. 1-9\n...\n116000998\n\nTupeli\n25 de Mayo\nSan Juan\nConectado\nReFeFO\n-68.355148\n-31.835497\n20363.518228\n\n\n6\n8ZXA578022006P\n1\n2021\n-35.707\n-61.852\n14113\n6609\n6\n0\na. 1-9\n...\n116000747\n\nPehuajo\nPehuajo\nBuenos Aires\nConectado\nReFeFO\n-61.886181\n-35.808664\n14455.869113\n\n\n7\n55X57A24220Z03\n1\n2021\n-27.467\n-58.801\n14113\n18021\n18\n0\na. 1-9\n...\n116000280\n\nCorrientes\nCapital\nCorrientes\nConectado\nReFeFO\n-58.853519\n-27.473892\n5910.026706\n\n\n8\n62XA5Z5532016P\n1\n2021\n-36.805\n-63.338\n14113\n6007\n6\n0\na. 1-9\n...\n116000851\n\nSalliquelo\nSalliqueló\nBuenos Aires\nConectado\nReFeFO\n-62.960400\n-36.751767\n42680.380667\n\n\n11\n02X7181Z420J70\n1\n2021\n-33.812\n-59.501\n14610\n6070\n6\n0\na. 1-9\n...\n116000103\n\nBaradero\nBaradero\nBuenos Aires\nConectado\nReFeFO\n-59.509570\n-33.810287\n981.225711\n\n\n\n\n5 rows × 25 columns\n\n\n\n\n\nestab_agro_refefo_gpd['distance'].describe()\n\ncount    139032.000000\nmean      25544.488222\nstd       43024.509877\nmin          10.732621\n25%        2012.328661\n50%        8579.902917\n75%       35895.504459\nmax      607665.364021\nName: distance, dtype: float64"
  },
  {
    "objectID": "posts/forum-equality-digital-divide/index.html",
    "href": "posts/forum-equality-digital-divide/index.html",
    "title": "Forum on Equality and the Digital Divide",
    "section": "",
    "text": "The Forum on Equality and the Digital Divide was held on June 9 and 10. In this context, I was invited to speak at the panel “Universal Access Funds in the Region: the case of Argentina.”\nHere I leave the full video of my participation (in Spanish):\n\n\n\nvideo\n\n\nAnd my presentation (in Spanish):"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "",
    "text": "Note: for those interested in the code used to generate each visualization, you can see it by pressing the “Show/Hide All Code” button at the top right of the page or the “Code” button at the top right of each visualization.\nThe #30daymapchallenge is a mapping/cartography/data visualization challenge powered by the data science community. The idea is to publish maps based on a daily challenge for 30 days using the hashtag #30daymapchallenge.\nHere are the daily themes for this year’s challenges:\nIn particular, I am going to focus (whenever I can) on data related to ICTs.\nLet’s start with the challenges of days 1 (points) and 2 (lines)."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#day-1---points",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#day-1---points",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Day 1 - Points",
    "text": "Day 1 - Points\nConnection nodes to the Federal Fiber Optic Network (REFEFO) of ARSAT.\nThe REFEFO is a fiber optic trunk network. Internet providers or ISPs connect to the connection points or nodes to bring internet services to final users.\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nsf_use_s2(FALSE)\nlibrary(httr)\n\nprovincias_ign &lt;- read_sf(\"https://wms.ign.gob.ar/geoserver/ows?service=wfs&version=1.1.0&request=GetFeature&typeNames=ign:provincia&outputFormat=application/json\")\n\nif(sum(!st_is_valid(provincias_ign)) &gt; 0) {\n  provincias_ign &lt;- st_make_valid(provincias_ign)\n}\n\nprovincias_ign &lt;- st_crop(x = provincias_ign,\n                          y = st_bbox(obj = c(xmin=-76.36532,\n                                              ymin=-56.75009,\n                                              xmax=-51.20850,\n                                              ymax=-20.91625)))\n\nnodos_refefo &lt;- read.csv2(\"https://datos.arsat.com.ar/dataset/8f0b4da0-a40d-4b2b-8fe0-dac06d64152a/resource/15713af0-f384-44c5-8397-c8050162312d/download/puntos-conexion-red-federal-de-fibra-optica-2021-12-01_v1.csv\", fileEncoding = \"LATIN1\")\n\nnodos_refefo &lt;- nodos_refefo %&gt;%\n  na.omit() %&gt;%\n  st_as_sf(crs = 4326, coords=c(\"Longitud\", \"Latitud\"), remove=FALSE)\n\nnodos_refefo &lt;- st_crop(x = nodos_refefo,\n                        y = st_bbox(obj = c(xmin=-76.36532,\n                                            ymin=-56.75009,\n                                            xmax=-51.20850,\n                                            ymax=-20.91625)))\n\nprovincias_ign %&gt;% \n  ggplot() + \n  geom_sf() +\n  geom_sf(data = nodos_refefo, color = \"#2ca25f\", size = 0.5) +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.datos.gob.ar / Source: www.datos.gob.ar\")"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#day-2---lines",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#day-2---lines",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Day 2 - Lines",
    "text": "Day 2 - Lines\nLay out of the REFEFO. The optical fiber of the REFEFO is generally buried next to national and provincial routes, connecting different small and medium-sized towns, where there are no other providers or there is only one and therefore there is no competition.\n\n\nCode\nidecom_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\nrefefo_query &lt;- list(service=\"wfs\",\n                     version=\"1.3.0\",\n                     request=\"GetFeature\",\n                     typeNames=\"publico:FO118-TZFO-REDFIBRAOPTICA-5-2\",\n                     CQL_FILTER=\"OBSERV='ARSAT - ReFeFO'\",\n                     outputFormat=\"application/json\")\n\nidecom_url &lt;- modify_url(url = idecom_base_url, \n                         query = refefo_query)\n\ntraza_refefo_idecom &lt;- read_sf(idecom_url)\n\nprovincias_ign %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_sf(data = traza_refefo_idecom, colour=\"#2b8cbe\") +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.idecom.gob.ar / Source: www.idecom.gob.ar\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "STEM Movie Recommendations\n\n\nRecomendaciones de películas STEM\n\n\n\nPelículas\n\n\nMovies\n\n\nSeries\n\n\nSTEM\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nSTEM Book Recommendations\n\n\nRecomendaciones de libros STEM\n\n\n\nLibros\n\n\nBooks\n\n\nSTEM\n\n\n\n\n\n\n\n\n\nSep 22, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nOn Regulatory Simplification\n\n\nSobre Simplificación Regulatoria\n\n\n\nAnálisis de Grafos\n\n\nGraph Analysis\n\n\n\n\n\n\n\n\n\nJul 24, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Infrastructure Subsidies Analysis\n\n\nAnálisis de Subsidios para Infraestructura TIC\n\n\n\nANR\n\n\n\n\n\n\n\n\n\nApr 26, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nREFEFO Potential to Enhance Productive Connectivity\n\n\nEl Potencial de la REFEFO para Mejorar la Conectividad Productiva\n\n\n\nREFEFO\n\n\nProductive Connectivity\n\n\n\n\n\n\n\n\n\nApr 26, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Whisper to Transcribe Messi\n\n\nTranscribir a Messi con Whisper\n\n\n\nNLP\n\n\nIA\n\n\nML\n\n\nPython\n\n\nMessi\n\n\n\n\n\n\n\n\n\nFeb 3, 2023\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nBeckham vs. Papu Gomez\n\n\nBeckham vs. Papu Gomez\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nForum on Equality and the Digital Divide\n\n\nForo Brechas y Equidad Digital\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Companies Social Network Analysis\n\n\nAnálisis de Empresas TIC en Redes Sociales\n\n\n\nNLP\n\n\nsocial networks\n\n\n\n\n\n\n\n\n\nApr 20, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Fix Access Dashboard for Argentina\n\n\nTablero de Accesos Fijos a Internet en Argentina\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Satellite Images\n\n\nUsando Imágenes Satelitales\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Prices Evolution\n\n\nEvolución de los precios\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Submarine Cables\n\n\nCables Submarinos de Internet\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Day Map Challenge Day 3 and 4\n\n\nDía 3 y 4 del Desafío de Mapas de 30 Días\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2021\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Days Map Challenge Day 1 and 2\n\n\n30 Days Map Challenge Día 1 y 2\n\n\n\n\n\n\n\n\nNov 6, 2021\n\n\nMartin Olmos\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "href": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "title": "Data & ICTs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "posts/on-regulatory-simplification/index.html",
    "href": "posts/on-regulatory-simplification/index.html",
    "title": "On Regulatory Simplification",
    "section": "",
    "text": "At the last Internet Day, organized by the Argentine Chamber of Internet (CABASE) on May 17 and 18, one of the topics discussed was regulatory simplification. How can we approach this issue from a data analysis perspective? One way is through graph analysis.\nAccording to the National Communications Entity (ENACOM), there are 357 fundamental regulations that regulate the ICT sector in Argentina. On the other hand, Infoleg, the normative and documentary information system of the Argentine Republic, publishes in open format data on all the regulations in force in the country in three data sets: a base of regulations, a base of modified regulations, and a base of modifying regulations (here modifying and modified regulations are considered in a broad sense, that is, they include complementary regulations).\nBut what does this have to do with graph theory? A graph is a data structure consisting of a set of nodes and a set of edges that connect them. These edges can be directed (those where the relationship goes in one direction but not the other) or undirected (those where the relationship goes in both directions). In the case of regulations, we can think of a graph where the nodes are the regulations and the edges are the relationships between them.\nFirst, I will read the data and load it into a Neo4j database, which is a graph database.\n\n\nCode\nimport pandas as pd\nfrom neo4j import GraphDatabase\nimport os\n\nnormas_fundamentales_tic = pd.read_csv(\"normas_fundamentales_tic.csv\")\nnormas_modificatorias_tic = pd.read_csv(\"normas_modificatorias_tic.csv\")\n\n# Configurar la conexión a Neo4j\nuri = \"bolt://localhost:7687\"  # Ajusta según la configuración de tu Neo4j\nusername = os.getenv(\"NEO4J_USER\")\npassword = os.getenv(\"NEO4J_PASS\")\n\ndriver = GraphDatabase.driver(uri, auth=(username, password))\n\ndef create_nodes_and_relationships(tx, normas_fundamentales_tic, normas_modificatorias_tic):\n    # Crear nodos para normas fundamentales\n    for index, row in normas_fundamentales_tic.iterrows():\n        tx.run(\"MERGE (n:Norma {id: $id, titulo: $titulo, grupo: $grupo, link: $link, notas: $notas, tipo: 'fundamental', boletin_oficial: $boletin_oficial})\",\n               id=row['id_norma'], titulo=row['norma'], grupo=row['grupo'], link=row['link'], notas=row['notas'], boletin_oficial=row['boletin_oficial'])\n    \n    # Crear relaciones \"modifica a\" o \"es modificada por\"\n    for index, row in normas_modificatorias_tic.iterrows():\n        tx.run(\"\"\"\n        MATCH (a:Norma {id: $id_modificatoria}), (b:Norma {id: $id_modificada})\n        MERGE (a)-[:MODIFICA_A]-&gt;(b)\n        \"\"\", id_modificatoria=row['id_norma_modificatoria'], id_modificada=row['id_norma_modificada'])\n\n# Ejecutar la función en una sesión\nwith driver.session() as session:\n    session.execute_write(create_nodes_and_relationships, normas_fundamentales_tic, normas_modificatorias_tic)\n\ndriver.close()\n\n\nNow let’s see what the graph looks like.\nThe Figure 1 shows the graph of the fundamental and modifying regulations of the ICT sector in Argentina. The Figure 2 is a zoom of a part of the graph to better visualize the relationships between the regulations.\nBut what can we do with this graph? What interesting questions can we answer?\n\n\n\n\n\n\nFigure 1: Grafo de normas fundamentales y modificatorias\n\n\n\n\n\n\n\n\n\nFigure 2: Zoom al grafo de normas fundamentales y modificatorias\n\n\n\nAn interesting question could be: what are the 10 fundamental regulations that have been modified or complemented the most by other regulations?\n\n\n\n\n\n\nNote\n\n\n\nNeo4j uses a query language called Cypher. The previous question can be answered with the Cypher query shown below.\n\n\nMATCH (n:Norma)-[:MODIFICA_A]-&gt;(m)\nRETURN m.titulo, COUNT(n) AS num_modificaciones\nORDER BY num_modificaciones DESC\nLIMIT 10\n\n\n\n\n\n\nFigure 3: Tabla de normas fundamentales que más fueron modificadas o complementadas\n\n\n\nHere the ranking is led by Decree 764/2000, the Digital Argentina Law, Decree 267/2015 which, among other things, created ENACOM, and the Audiovisual Communication Services Law."
  },
  {
    "objectID": "posts/stem-book-recommendations/index.html",
    "href": "posts/stem-book-recommendations/index.html",
    "title": "STEM Book Recommendations",
    "section": "",
    "text": "STEM book recommendations that I enjoyed (in no particular order)\n\n“The Innovators” - Walter Isaacson\n\nThis book explores the lives and contributions of the pioneers behind the great technological innovations of the last century. From Ada Lovelace to the creators of the web, Isaacson clearly connects human collaboration with technological advancement. It’s a must-read for those looking to understand how the interplay between science and creativity has shaped today’s digital age. Recommended for anyone seeking a deep dive into the history of technology.\n“A Brief History of Artificial Intelligence” - Michael Wooldridge\n\nWooldridge offers an accessible and well-researched overview of the evolution of AI, from its beginnings in the 1950s to the latest developments. It’s an excellent introduction for those looking for an academic yet approachable take on the history and ethical implications of artificial intelligence. Recommended for anyone interested in how AI has reached its current state.\n“A Brief History of Time” - Stephen W. Hawking\n\nA classic in popular science, this book by Hawking poses some of the most fundamental questions about the universe: from the nature of time to the possibility of parallel universes. Though known for its complexity, Hawking manages to present difficult concepts in a way that’s understandable for the average reader. Highly recommended for those looking to expand their understanding of the cosmos.\n“Weapons of Math Destruction” - Cathy O’Neil\n\nIn this book, O’Neal examines the dark side of algorithms and how, far from being neutral, they can exacerbate social and economic inequalities. Her critique targets systems that negatively impact sectors like education, finance, and criminal justice. Recommended for those interested in the ethics of algorithms and the social impact of technology.\n“Permanent Record” - Edward Snowden\n\nA fascinating account from Snowden, the famous whistleblower who exposed the U.S. government’s mass surveillance program. The book explores key issues about privacy, digital security, and governmental power. Recommended for those wanting a critical and personal view on contemporary cybersecurity and privacy issues.\n“The Idea Factory” - Jon Gertner\n\nGertner details the history of Bell Labs, where some of the 20th century’s most revolutionary technologies, like the transistor and fiber optics, were invented. The book highlights how a collaborative environment was key to these advancements. Recommended for those interested in the history of technological innovation.\n“A Mind at Play” - Jimmy Soni\n\nThis biography of Claude Shannon, the father of information theory, offers a fascinating account of one of the most influential intellectuals of the 20th century. Shannon not only changed how we understand information but also laid the groundwork for the digital revolution. Recommended for those interested in the origins of information theory and its current impact.\n“Everybody Lies” - Seth Stephens-Davidowitz\n\nStephens-Davidowitz uses big data to reveal how Google searches and other online sources can show what people truly think and feel. It’s a provocative read that challenges our notions about privacy, biases, and human behavior. Recommended for those looking for an innovative take on the use of data in today’s society.\n“Fermat’s Last Theorem” - Simon Singh\n\nA classic in mathematical popular science, this book narrates the solving of the problem that stumped mathematicians for centuries. Singh turns this story into a thrilling academic mystery that combines history, mathematics, and intellectual challenge. Recommended for math enthusiasts and those who enjoy stories of intellectual perseverance."
  },
  {
    "objectID": "posts/stem-movie-recommendations/index.html",
    "href": "posts/stem-movie-recommendations/index.html",
    "title": "STEM Movie Recommendations",
    "section": "",
    "text": "Here are reviews and recommendations of STEM movies and series, in no particular order:\n\nThe Imitation Game\nThis biographical film tells the life story of Alan Turing, the British mathematician who deciphered the Enigma code during World War II. It’s a moving portrayal of a brilliant yet misunderstood mind, highlighting Turing’s pivotal contributions to modern computing. Recommended for those interested in the history of cryptography and the early days of artificial intelligence.\nThe Playlist\nThis series follows the story of Spotify and how it revolutionized the music industry. It shows the conflict between technological innovation and the old power structures in the music business. Recommended for those interested in the impact of tech platforms on culture and business.\nThe Billion Dollar Code\nThis miniseries, based on true events, depicts the legal battle between two German programmers and Google over the patent rights to what eventually became Google Earth. It’s a courtroom drama about innovation, intellectual property, and justice in the digital age. Recommended for those who enjoy stories about startups and tech giants.\nBlackberry\nThis film follows the rise and fall of Blackberry, one of the pioneering companies in smartphone development. It’s a fascinating look at the fast-paced world of technology and how innovation—and failure to adapt—can make or break a company. Recommended for those interested in the history of mobile technology and the rise of personal devices.\nThe Theory of Everything\nThis biopic about Stephen Hawking narrates his personal and professional life, focusing on his battle with ALS while developing groundbreaking theories about the universe. It’s a moving and visually stunning film. Highly recommended for those looking for an inspiring story about science and personal perseverance.\nThe Man Who Knew Infinity\nThe film portrays the life of Srinivasa Ramanujan, a self-taught mathematical prodigy who travels from India to Cambridge to collaborate with mathematician G.H. Hardy. It’s a tribute to intellectual perseverance and the genius that breaks cultural and academic barriers. Recommended for those who enjoy biographical stories about mathematical prodigies.\nOppenheimer\nAn epic portrait of the life of J. Robert Oppenheimer, the physicist who led the development of the atomic bomb in the Manhattan Project. The film explores the ethical and emotional impact of creating a weapon of mass destruction. Highly recommended for those interested in the history of science and the ethical dilemmas associated with technology.\nThe Social Network\nThe film tells the story of Facebook’s creation and the rise of Mark Zuckerberg. It shows the personal and legal conflicts that accompanied the success of one of the most influential platforms of the 21st century. Recommended for those who want to understand the origins of social networks and the ethical challenges of digital power.\nThe Social Dilemma\nThis documentary analyzes the negative impact of social media on society, from psychological manipulation to the erosion of democracy. With interviews from former tech company executives, it’s a stark warning about the dangers of unchecked technology. Recommended for those interested in the social and psychological effects of social networks.\nSteve Jobs\nDirected by Danny Boyle, this biopic offers an intimate look at Steve Jobs’s life, centered around three key moments in his career. Through sharp and dramatic dialogue, the film presents the Apple founder as a visionary but also as a complex figure. Recommended for those looking for a personal portrait of one of the most influential figures in modern technology.\nCitizenfour\nThis documentary follows whistleblower Edward Snowden as he reveals the U.S. government’s mass surveillance program. It’s a raw and urgent look at privacy, security, and governmental power. Recommended for those interested in digital rights and privacy.\nThe Internet’s Own Boy: The Story of Aaron Swartz\nThis documentary tells the life of Aaron Swartz, a digital activist and programmer who fought for free access to information. His tragic death highlights the conflicts between information freedom and restrictive laws. Recommended for those looking to explore the intersection of technology, activism, and civil rights in the digital age."
  }
]