[
  {
    "objectID": "posts/you-only-look-once/index.html",
    "href": "posts/you-only-look-once/index.html",
    "title": "You Only Look Once",
    "section": "",
    "text": "You Only Look Once (YOLO) is series of open-source, real-time object detection models that can identify and classify multiple objects within an image or video frame. Unlike traditional object detection methods that rely on region proposal networks, YOLO treats object detection as a single regression problem, directly predicting bounding boxes and class probabilities from the entire image in one evaluation.\nThe Ultralytics YOLOv8 series supports various tasks, including object detection, pose estimation, segmentation, and classification. It is known for its speed and accuracy, making it suitable for real-time applications such as surveillance, autonomous driving, and robotics.\nHere is the code to run a YOLOv8 model using the Ultralytics library in Python for object detection and pose estimation:\n\n\nCode\nfrom ultralytics import YOLO\nimport cv2\nimport math \nimport torch\n\n\nCAM_INDEX = 0  # change if you have multiple cameras\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n# model\nmodel = YOLO(\"yolo-Weights/yolov8n.pt\")\n\n# Optional: move model to GPU (if available)\ntry:\n    model.to(device)\nexcept Exception:\n    pass  # older ultralytics handles device per-predict call\n\n\n# start webcam\ncap = cv2.VideoCapture(CAM_INDEX)\ncap.set(3, 640)\ncap.set(4, 480)\n\n# object classes\nclassNames = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \"boat\",\n              \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n              \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\",\n              \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\", \"baseball bat\",\n              \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\", \"bottle\", \"wine glass\", \"cup\",\n              \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\", \"sandwich\", \"orange\", \"broccoli\",\n              \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \"chair\", \"sofa\", \"pottedplant\", \"bed\",\n              \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n              \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\",\n              \"teddy bear\", \"hair drier\", \"toothbrush\"\n              ]\n\n# Video output settings\noutput_path = \"output_detection.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = 30\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nwhile True:\n    success, img = cap.read()\n    if not success:\n        break\n    results = model(img, stream=True, device=\"cuda\")\n\n    # coordinates\n    for r in results:\n        boxes = r.boxes\n\n        for box in boxes:\n            # bounding box\n            x1, y1, x2, y2 = box.xyxy[0]\n            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2) # convert to int values\n\n            # put box in cam\n            cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 3)\n\n            # confidence\n            confidence = math.ceil((box.conf[0]*100))/100\n            print(\"Confidence ---&gt;\",confidence)\n\n            # class name\n            cls = int(box.cls[0])\n            print(\"Class name --&gt;\", classNames[cls])\n\n            # object details\n            org = [x1, y1]\n            font = cv2.FONT_HERSHEY_SIMPLEX\n            fontScale = 1\n            color = (255, 0, 0)\n            thickness = 2\n\n            cv2.putText(img, classNames[cls], org, font, fontScale, color, thickness)\n\n    # Write frame to video file\n    out.write(img)\n    \n    cv2.imshow('Webcam', img)\n    if cv2.waitKey(1) == ord('q'):\n        break\n\ncap.release()\nout.release()  # Release the video writer\ncv2.destroyAllWindows()\nprint(f\"Video saved to {output_path}\")\n\n\nVideo\n\n\nCode\n# Realtime pose estimation with YOLOv8 (OpenCV window)\nimport cv2, torch, time\nfrom ultralytics import YOLO\n\nCAM_INDEX = 0  # change if you have multiple cameras\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = YOLO('yolov8n-pose.pt')  # or 'yolov8s-pose.pt'\n# Optional: move model to GPU (if available)\ntry:\n    model.to(device)\nexcept Exception:\n    pass  # older ultralytics handles device per-predict call\n\ncap = cv2.VideoCapture(CAM_INDEX)\ncap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\ncap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n\n# Video output settings\noutput_path = \"output_pose.mp4\"\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nfps = 30\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n\nprev_t = time.time()\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    results = model.predict(\n        frame,\n        device=device,\n        imgsz=640,\n        conf=0.5,\n        half=(device == 'cuda'),\n        verbose=False\n    )\n    annotated = results[0].plot()\n\n    # FPS overlay\n    now = time.time()\n    fps_val = 1 / (now - prev_t)\n    prev_t = now\n    cv2.putText(annotated, f'FPS: {fps_val:.1f} ({device})', (10, 30),\n                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n\n    # Write frame to video file\n    out.write(annotated)\n\n    cv2.imshow('YOLOv8 Pose', annotated)\n    if cv2.waitKey(1) & 0xFF == ord('q'):\n        break\n\ncap.release()\nout.release()  # Release the video writer\ncv2.destroyAllWindows()\nprint(f\"Video saved to {output_path}\")\n\n\nVideo"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html",
    "href": "posts/transcribe-messi-using-whisper/index.html",
    "title": "Using Whisper to Transcribe Messi",
    "section": "",
    "text": "Whisper is an open source model for speech recognition developed by OpenAI.\nWe will try to use it to add subtitles to a recent interview.\nHere is the original interview:"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#download-audio-and-video-from-youtube",
    "href": "posts/transcribe-messi-using-whisper/index.html#download-audio-and-video-from-youtube",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Download audio and video from Youtube",
    "text": "Download audio and video from Youtube\n\n\nCode\nimport youtube_dl as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=RYXcR3YejwY'\n\nydl_audio_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'whisper_messi_corto.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\n:::"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#generate-the-transcript",
    "href": "posts/transcribe-messi-using-whisper/index.html#generate-the-transcript",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Generate the transcript",
    "text": "Generate the transcript\n\n\nCode\nimport whisperx\n\ndevice = \"cuda\" \naudio_file = \"whisper_messi_corto.mp3\"\n\n# transcribe with original whisper\nmodel = whisperx.load_model(\"large-v2\", device)\nresult = model.transcribe(audio_file)\n\nprint(result[\"segments\"]) # before alignment\n\n# load alignment model and metadata\nmodel_a, metadata = whisperx.load_align_model(language_code=result[\"language\"], device=device)\n\n# align whisper output\nresult_aligned = whisperx.align(result[\"segments\"], model_a, metadata, audio_file, device)"
  },
  {
    "objectID": "posts/transcribe-messi-using-whisper/index.html#embed-the-transcript-in-the-video-as-subtitles",
    "href": "posts/transcribe-messi-using-whisper/index.html#embed-the-transcript-in-the-video-as-subtitles",
    "title": "Using Whisper to Transcribe Messi",
    "section": "Embed the transcript in the video as subtitles",
    "text": "Embed the transcript in the video as subtitles\n\n\nCode\nimport pandas as pd\nimport cv2\nfrom moviepy.editor import VideoFileClip\nimport moviepy.editor as mp\nfrom moviepy.editor import *\nfrom moviepy.video.tools.subtitles import SubtitlesClip\n\ndict1 = {'start':[], 'end':[], 'text':[]}\nfor i in result_aligned['segments']:\n  dict1['start'].append(int(i['start']))\n  dict1['end'].append(int(i['end']))\n  dict1['text'].append(i['text'])\n\ndf = pd.DataFrame.from_dict(dict1)\ndf.to_csv(f'whisper_messi_corto_subs.csv')\n\nvideocap = cv2.VideoCapture(\"whisper_messi_corto.mp4\")\nsuccess, image = videocap.read()\nheight = image.shape[0]\nwidth =image.shape[1]\n\ngenerator = lambda txt: TextClip(txt, font='P052-Bold', fontsize=width/50, stroke_width=.7, color='white', stroke_color = 'black', size = (width, height*.25), method='caption')\n\nsubs = tuple(zip(tuple(zip(df['start'].values, df['end'].values)), df['text'].values))\nsubtitles = SubtitlesClip(subs, generator)\n\nvideo = VideoFileClip('whisper_messi_corto.mp4')\nfinal = CompositeVideoClip([video, subtitles.set_pos(('center','bottom'))])\nfinal.write_videofile('whisper_messi_corto_con_subs.mp4', fps=video.fps, remove_temp=True, codec=\"libx264\", audio_codec=\"aac\")\n\n\nHere is the final product, the video with the subtitles:"
  },
  {
    "objectID": "posts/stem-book-recommendations/index.html",
    "href": "posts/stem-book-recommendations/index.html",
    "title": "STEM Book Recommendations",
    "section": "",
    "text": "STEM book recommendations that I enjoyed (in no particular order)\n\n“The Innovators” - Walter Isaacson\n\nThis book explores the lives and contributions of the pioneers behind the great technological innovations of the last century. From Ada Lovelace to the creators of the web, Isaacson clearly connects human collaboration with technological advancement. It’s a must-read for those looking to understand how the interplay between science and creativity has shaped today’s digital age. Recommended for anyone seeking a deep dive into the history of technology.\n“A Brief History of Artificial Intelligence” - Michael Wooldridge\n\nWooldridge offers an accessible and well-researched overview of the evolution of AI, from its beginnings in the 1950s to the latest developments. It’s an excellent introduction for those looking for an academic yet approachable take on the history and ethical implications of artificial intelligence. Recommended for anyone interested in how AI has reached its current state.\n“A Brief History of Time” - Stephen W. Hawking\n\nA classic in popular science, this book by Hawking poses some of the most fundamental questions about the universe: from the nature of time to the possibility of parallel universes. Though known for its complexity, Hawking manages to present difficult concepts in a way that’s understandable for the average reader. Highly recommended for those looking to expand their understanding of the cosmos.\n“Weapons of Math Destruction” - Cathy O’Neil\n\nIn this book, O’Neal examines the dark side of algorithms and how, far from being neutral, they can exacerbate social and economic inequalities. Her critique targets systems that negatively impact sectors like education, finance, and criminal justice. Recommended for those interested in the ethics of algorithms and the social impact of technology.\n“Permanent Record” - Edward Snowden\n\nA fascinating account from Snowden, the famous whistleblower who exposed the U.S. government’s mass surveillance program. The book explores key issues about privacy, digital security, and governmental power. Recommended for those wanting a critical and personal view on contemporary cybersecurity and privacy issues.\n“The Idea Factory” - Jon Gertner\n\nGertner details the history of Bell Labs, where some of the 20th century’s most revolutionary technologies, like the transistor and fiber optics, were invented. The book highlights how a collaborative environment was key to these advancements. Recommended for those interested in the history of technological innovation.\n“A Mind at Play” - Jimmy Soni\n\nThis biography of Claude Shannon, the father of information theory, offers a fascinating account of one of the most influential intellectuals of the 20th century. Shannon not only changed how we understand information but also laid the groundwork for the digital revolution. Recommended for those interested in the origins of information theory and its current impact.\n“Everybody Lies” - Seth Stephens-Davidowitz\n\nStephens-Davidowitz uses big data to reveal how Google searches and other online sources can show what people truly think and feel. It’s a provocative read that challenges our notions about privacy, biases, and human behavior. Recommended for those looking for an innovative take on the use of data in today’s society.\n“Fermat’s Last Theorem” - Simon Singh\n\nA classic in mathematical popular science, this book narrates the solving of the problem that stumped mathematicians for centuries. Singh turns this story into a thrilling academic mystery that combines history, mathematics, and intellectual challenge. Recommended for math enthusiasts and those who enjoy stories of intellectual perseverance."
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/etl.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "import pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n\n\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\n\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:25: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_46263/1757400123.py:28: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n  ax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n\n\n\n\n\n\n\n\n\nfrom matplotlib import cm\nimport matplotlib as mpl\n\n# cmap = cm.coolwarm\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\n\n\n\n\nestab_agro_refefo_gpd.head()\n\n\n\n\n\n\n\n\ncuit\nsucursal\nanio\nlat\nlon\nclae6\nin_departamentos\nprovincia_id\nquintil\nempleo\n...\nCUICOM\nNivAcc\nLocalidad\nDepartamen\nProvincia\nOPERAT\nOBSERV\nLongitud\nLatitud\ndistance\n\n\n\n\n2\n41X8684801PW69\n1\n2021\n-31.831\n-68.538\n13019\n70070\n70\n0\na. 1-9\n...\n116000998\n\nTupeli\n25 de Mayo\nSan Juan\nConectado\nReFeFO\n-68.355148\n-31.835497\n20363.518228\n\n\n6\n8ZXA578022006P\n1\n2021\n-35.707\n-61.852\n14113\n6609\n6\n0\na. 1-9\n...\n116000747\n\nPehuajo\nPehuajo\nBuenos Aires\nConectado\nReFeFO\n-61.886181\n-35.808664\n14455.869113\n\n\n7\n55X57A24220Z03\n1\n2021\n-27.467\n-58.801\n14113\n18021\n18\n0\na. 1-9\n...\n116000280\n\nCorrientes\nCapital\nCorrientes\nConectado\nReFeFO\n-58.853519\n-27.473892\n5910.026706\n\n\n8\n62XA5Z5532016P\n1\n2021\n-36.805\n-63.338\n14113\n6007\n6\n0\na. 1-9\n...\n116000851\n\nSalliquelo\nSalliqueló\nBuenos Aires\nConectado\nReFeFO\n-62.960400\n-36.751767\n42680.380667\n\n\n11\n02X7181Z420J70\n1\n2021\n-33.812\n-59.501\n14610\n6070\n6\n0\na. 1-9\n...\n116000103\n\nBaradero\nBaradero\nBuenos Aires\nConectado\nReFeFO\n-59.509570\n-33.810287\n981.225711\n\n\n\n\n5 rows × 25 columns\n\n\n\n\nestab_agro_refefo_gpd['distance'].describe()\n\ncount    139032.000000\nmean      25544.488222\nstd       43024.509877\nmin          10.732621\n25%        2012.328661\n50%        8579.902917\n75%       35895.504459\nmax      607665.364021\nName: distance, dtype: float64"
  },
  {
    "objectID": "posts/on-regulatory-simplification/index.html",
    "href": "posts/on-regulatory-simplification/index.html",
    "title": "On Regulatory Simplification",
    "section": "",
    "text": "At the last Internet Day, organized by the Argentine Chamber of Internet (CABASE) on May 17 and 18, one of the topics discussed was regulatory simplification. How can we approach this issue from a data analysis perspective? One way is through graph analysis.\nAccording to the National Communications Entity (ENACOM), there are 357 fundamental regulations that regulate the ICT sector in Argentina. On the other hand, Infoleg, the normative and documentary information system of the Argentine Republic, publishes in open format data on all the regulations in force in the country in three data sets: a base of regulations, a base of modified regulations, and a base of modifying regulations (here modifying and modified regulations are considered in a broad sense, that is, they include complementary regulations).\nBut what does this have to do with graph theory? A graph is a data structure consisting of a set of nodes and a set of edges that connect them. These edges can be directed (those where the relationship goes in one direction but not the other) or undirected (those where the relationship goes in both directions). In the case of regulations, we can think of a graph where the nodes are the regulations and the edges are the relationships between them.\nFirst, I will read the data and load it into a Neo4j database, which is a graph database.\n\n\nCode\nimport pandas as pd\nfrom neo4j import GraphDatabase\nimport os\n\nnormas_fundamentales_tic = pd.read_csv(\"normas_fundamentales_tic.csv\")\nnormas_modificatorias_tic = pd.read_csv(\"normas_modificatorias_tic.csv\")\n\n# Configurar la conexión a Neo4j\nuri = \"bolt://localhost:7687\"  # Ajusta según la configuración de tu Neo4j\nusername = os.getenv(\"NEO4J_USER\")\npassword = os.getenv(\"NEO4J_PASS\")\n\ndriver = GraphDatabase.driver(uri, auth=(username, password))\n\ndef create_nodes_and_relationships(tx, normas_fundamentales_tic, normas_modificatorias_tic):\n    # Crear nodos para normas fundamentales\n    for index, row in normas_fundamentales_tic.iterrows():\n        tx.run(\"MERGE (n:Norma {id: $id, titulo: $titulo, grupo: $grupo, link: $link, notas: $notas, tipo: 'fundamental', boletin_oficial: $boletin_oficial})\",\n               id=row['id_norma'], titulo=row['norma'], grupo=row['grupo'], link=row['link'], notas=row['notas'], boletin_oficial=row['boletin_oficial'])\n    \n    # Crear relaciones \"modifica a\" o \"es modificada por\"\n    for index, row in normas_modificatorias_tic.iterrows():\n        tx.run(\"\"\"\n        MATCH (a:Norma {id: $id_modificatoria}), (b:Norma {id: $id_modificada})\n        MERGE (a)-[:MODIFICA_A]-&gt;(b)\n        \"\"\", id_modificatoria=row['id_norma_modificatoria'], id_modificada=row['id_norma_modificada'])\n\n# Ejecutar la función en una sesión\nwith driver.session() as session:\n    session.execute_write(create_nodes_and_relationships, normas_fundamentales_tic, normas_modificatorias_tic)\n\ndriver.close()\n\n\nNow let’s see what the graph looks like.\nThe Figure 1 shows the graph of the fundamental and modifying regulations of the ICT sector in Argentina. The Figure 2 is a zoom of a part of the graph to better visualize the relationships between the regulations.\nBut what can we do with this graph? What interesting questions can we answer?\n\n\n\n\n\n\nFigure 1: Grafo de normas fundamentales y modificatorias\n\n\n\n\n\n\n\n\n\nFigure 2: Zoom al grafo de normas fundamentales y modificatorias\n\n\n\nAn interesting question could be: what are the 10 fundamental regulations that have been modified or complemented the most by other regulations?\n\n\n\n\n\n\nNote\n\n\n\nNeo4j uses a query language called Cypher. The previous question can be answered with the Cypher query shown below.\n\n\nMATCH (n:Norma)-[:MODIFICA_A]-&gt;(m)\nRETURN m.titulo, COUNT(n) AS num_modificaciones\nORDER BY num_modificaciones DESC\nLIMIT 10\n\n\n\n\n\n\nFigure 3: Tabla de normas fundamentales que más fueron modificadas o complementadas\n\n\n\nHere the ranking is led by Decree 764/2000, the Digital Argentina Law, Decree 267/2015 which, among other things, created ENACOM, and the Audiovisual Communication Services Law."
  },
  {
    "objectID": "posts/internet-submarine-cables/index.html",
    "href": "posts/internet-submarine-cables/index.html",
    "title": "Internet Submarine Cables",
    "section": "",
    "text": "Some time ago Tyler Morgan-Wall made a visualization of all the submarine internet cables with Telegeography data.\nTyler posted the code in this gist. I decided to reproduce the visualization with a little modification to add a title and change earth´s rotation direction.\nHere is the modification to the last for loop to add the title:\n\nfor(i in seq(1,720,by=1)) {\n  tmp &lt;- group_objects(fullcablescene,scale=c(1,1,1)*1.02) %&gt;% \n    add_object(sphere(radius=0.99,material=diffuse(image_texture = \"2k_earth_daymap.jpg\"),angle=c(0,-90,0))) %&gt;% \n    group_objects(angle=c(0,-i/2,0)) %&gt;% \n    add_object(sphere(y=5,z=5,x=5,material=light(intensity = 80,color=\"lightblue\"))) %&gt;% \n    add_object(sphere(y=5,z=5,x=-5,material=light(intensity = 10,color=\"orange\"))) %&gt;% \n    add_object(sphere(y=-10,material=light(intensity = 3,color=\"white\"))) %&gt;%\n    render_scene(samples=64,width=1200,height=1200,fov=0,aperture=0, ortho_dimensions = c(2.3,2.3),\n                 sample_method = \"sobol_blue\",parallel = TRUE,return_raw_array = TRUE)\n  rayimage::add_title(image = tmp,\n                      title_text = \"https://martinolmos.github.io/datos_tic/\",\n                      title_color = \"orange\",\n                      title_position = \"north\",\n                      filename = sprintf(\"imgs/smallcables%d.png\",i))\n}\n\nAnd here is the code to change the direction of earth´s rotation:\n\nav::av_encode_video(sprintf(\"imgs/smallcables%d.png\", seq(720,1,by=-1)), \n                    framerate = 30, \n                    output = \"cables.mp4\")\n\nAnd finally the new visualization:\n\nVideo"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html",
    "href": "posts/ict-infra-subsidies-analysis/index.html",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "",
    "text": "In Argentina, as in many other countries, there is a fund made up of contributions from companies in the ICT sector with the goal of bringing services to populations that have no access to them for various reasons. In this post, I participated in a panel where I talked about the history of this fund in Argentina, called the Universal Service Trust Fund (FFSU), its regulatory framework and the different programs it has today.\nIn this post, I will develop a small exploratory analysis of some of the data regarding the two most important programs of the FFSU: the Connectivity Program and the Vulnerable Neighborhoods Program. The analysis covers the years between 2020 and 2023, for which data is available. The data was extracted from the minutes of the meetings of the Board of Directors of the National Communications Entity (ENACOM), which are published in PDF on the agency’s website."
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#connectivity-program",
    "href": "posts/ict-infra-subsidies-analysis/index.html#connectivity-program",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Connectivity Program",
    "text": "Connectivity Program\n\n\nCode\n# Me conecto a la base de datos y leo la tabla del Programa Conectividad\n# Connect to the database and read the Conectividad Program table\n\nfrom dotenv import load_dotenv\nfrom sqlalchemy import create_engine\nimport os\nimport pandas as pd\n\nload_dotenv()\n\nhost = os.getenv(\"HOST\")\nport = os.getenv(\"PORT\")\ndatabase = os.getenv(\"DBNAME\")\nuser = os.getenv(\"USER\")\npassword = os.getenv(\"PASSWD\")\n\nengine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n\nanr_prog_con = pd.read_sql_table(table_name=\"conectividad_aprob_georef\", con=engine)\n\n\nThe Figure 1 shows the number of localities that were beneficiaries from ANRs from the Connectivity Program approved by province, between 2020 and 2023.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_con.groupby(\"provincia_indec\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 1: Localidades beneficiarias de ANRs del Prog. Conectividad por provincia\n\n\n\nThe Figure 2 shows the number of localities that were beneficiaries of ANRs from the Connectivity Program by year.\n\n\nCode\nanr_prog_con['anio'] = anr_prog_con['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_con.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 2: Localidades beneficiarias de ANRs del Prog. Conectividad por año\n\n\n\nThe Figure 3 shows the number of localities that were beneficiairies from ANRs from the Connectivity Program by year and province.\n\n\nCode\nimport textwrap\n\nanr_prog_con_prov_anio = anr_prog_con.groupby(['anio', 'provincia_indec']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(4,1)\n\nfor i, anio in enumerate(anr_prog_con_prov_anio.index):\n    anr_prog_con_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigure 3: Localidades beneficiarias de ANRs del Prog. Conectividad por año y provincia"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/index.html#vulnerable-neighborhoods-program",
    "href": "posts/ict-infra-subsidies-analysis/index.html#vulnerable-neighborhoods-program",
    "title": "ICT Infrastructure Subsidies Analysis",
    "section": "Vulnerable Neighborhoods Program",
    "text": "Vulnerable Neighborhoods Program\n\n\nCode\n# Me conecto a la base de datos y leo la tabla del Programa Barrios Populares\n# Connect to the database and read the Barrios Populares Program table\n\nimport geopandas as gpd\n\nanr_prog_renabap = gpd.read_postgis(\"SELECT * FROM renabap_aprob\", con=engine, geom_col=\"geometry\")\n\n\nThe Figure 4 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by province, between 2021, the year in which the program began, and 2023.\n\n\nCode\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\n\nax = anr_prog_renabap.groupby(\"provincia\").size().sort_values(ascending=False).plot(kind='bar', figsize=(20,10), legend=False)\n\nax.set_xlabel(\"Provincia\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 4: Barrios beneficiados con ANRs del Prog. Barrios Populares por provincia\n\n\n\nThe Figure 5 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by year.\n\n\nCode\nanr_prog_renabap['anio'] = anr_prog_renabap['fecha'].apply(lambda x: x.strip().split(' ')[1] if len(x.split(' ')) &gt; 1 else None)\n\nfig, ax = plt.subplots()\n\nanr_prog_renabap.groupby(\"anio\").size().plot(ax=ax, kind='bar', figsize=(12,6), legend=False)\n\nax.set_xlabel(\"Año\", fontsize=15)\n\n\n\n\n\n\n\n\nFigure 5: Barrios beneficiados con ANRs del Prog. Barrios Populares aprobados por año\n\n\n\nThe Figure 6 shows the number of neighborhoods that were beneficiaries of ANRs from the Vulnerable Neighborhoods Program by year and province.\n\n\nCode\nimport textwrap\n\nanr_prog_renabap_prov_anio = anr_prog_renabap.groupby(['anio', 'provincia']).size().unstack().fillna(0)\n\nfig, ax = plt.subplots(3,1)\n\nfor i, anio in enumerate(anr_prog_renabap_prov_anio.index):\n    anr_prog_renabap_prov_anio.loc[anio].sort_values(ascending=False).plot(ax=ax[i], kind='bar', figsize=(12,26), legend=False)\n    ax[i].set_title(f\"{anio}\", fontsize=20)\n    ax[i].set_xlabel(\"\")\n    ax[i].set_xticklabels([textwrap.fill(label.get_text(), 10) for label in ax[i].get_xticklabels()], rotation=45, fontsize=8, ha='right')  # Wrap labels\n\n\n\n\n\n\n\n\nFigure 6: Barrios beneficiados por ANRs del Prog. Barrios Populares aprobados por año y provincia\n\n\n\nBeyond these graphs about the number of localities and vulnerable neighborhoods that were beneficiaries, it would be interesting to analyze the impact of these programs on the connectivity of the beneficiary populations. We will try to approach this issue in a future post."
  },
  {
    "objectID": "posts/ict-companies-social-network-analysis/index.html",
    "href": "posts/ict-companies-social-network-analysis/index.html",
    "title": "ICT Companies Social Network Analysis",
    "section": "",
    "text": "Natural Language Processing or NLP is the field of study on computational analysis of human language. This area of knowledge includes a very wide variety of techniques and applications. One of them, within the field of language analysis and comprehension, is Sentiment Analysis, an application that allows a text to be classified according to its positive, negative or neutral charge or polarity.\nIn this post, with a few lines of python code we’ll do the following tasks:\n\nConnect to the Twitter API\nDownload the latest tweets that mention certain ICT companies\nUse a pre-trained machine learning model to perform sentiment analysis of these tweets\nVisualize the results\n\nThe pre-trained model that we are going to use is RoBERTuito, a model trained with 500 million tweets in Spanish. The authors of the paper/model made it available through the platform HuggingFace and the library pysentimento to facilitate NLP research and applications in Spanish.\nClarification 1: It is natural and expected that mentions of ICT companies in social media have a negative sentiment, since it is one of the channels for submitting complaints and, as it is a paid service, it is unusual to post a positive comment in case there are no problems with the service.\nClarification 2: to access the tweets, it is necessary to first apply for authentication credentials at Twitter for Developers. Once you have the credentials you should save them in a file called search_tweets_creds.yml with the following structure:\nsearch_tweets_api:\n    bearer_token: MY_BEARER_TOKEN\n    endpoint: https://api.twitter.com/2/tweets/search/recent\nTo obtain the tweets I will use the searchtweets-v2 library, a Python Client for the Twitter API Version 2.\nUse the following code for authentication and to obtain the last 100 tweets that mention each of the companies of interest:\n\nfrom searchtweets import load_credentials, ResultStream, gen_request_parameters, collect_results\n\nsearch_args = load_credentials(filename=\"search_tweets_creds.yml\", \n                               yaml_key=\"search_tweets_api\",\n                               env_overwrite=False)\n\nempresas = [\"Telecentro\", \"MovistarArg\", \"ClaroArgentina\", \"PersonalAr\"]\nempresas_tweets = dict()\n\nfor empresa in empresas:\n    query = gen_request_parameters(empresa, results_per_call=100, granularity=None)\n    tweets = collect_results(query,\n                             max_tweets=100,\n                             result_stream_args=search_args)\n    empresas_tweets[empresa] = tweets[0]['data']\n\nPre-process tweets, apply sentiment analysis and extract the category for each of the tweets and companies:\n\nfrom pysentimiento import create_analyzer\n\nanalyzer = create_analyzer(task=\"sentiment\", lang=\"es\", model_name=\"pysentimiento/robertuito-sentiment-analysis\")\n\nempresas_tweets_sent = dict()\nempresas_tweets_sent_out = dict()\n\nfor empresa in empresas:\n    empresas_tweets_sent[empresa] = [analyzer.predict(tuit) for tuit in empresas_tweets_proc[empresa]]\n    empresas_tweets_sent_out[empresa] = [tuit.output for tuit in empresas_tweets_sent[empresa]]\n\nVisualize the results:\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nempresas_tweets_sent_count = dict()\nfig, axes = plt.subplots(2, 2, figsize=(8, 6),dpi=144)\n\nplt.suptitle(\"Análisis de Sentimientos de Empresas TIC\")\n\narray_index = [(0,0), (0,1), (1,0), (1,1)]\naxes_title_font_size = 10\n\nfor empresa, index in zip(empresas, array_index):\n    empresas_tweets_sent_count[empresa] = np.unique(empresas_tweets_sent_out[empresa], return_counts=True)\n    axes[index].pie(empresas_tweets_sent_count[empresa][1], labels=empresas_tweets_sent_count[empresa][0], wedgeprops=dict(width=.5), autopct='%1.f%%')\n    axes[index].set_title(empresa, fontsize=axes_title_font_size)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html",
    "href": "posts/cumbre-ia/index.html",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "",
    "text": "On October 3 and 4 in Montevideo, Uruguay, the 2nd Ministerial and High-Level Authorities Summit on Artificial Intelligence Ethics in Latin America and the Caribbean took place. The summit focused on discussing the challenges and opportunities that AI presents in the region, as well as the ethical principles that should guide its development and application.\nThe complete program of the summit and the live streaming of the sessions can be accessed here. Within this framework, the Montevideo Declaration and the 2024-2025 Roadmap were approved.\nFor those who could not follow the event live and do not have time to watch the entire video, here we will show how to automatically transcribe and summarize the content of a video using AI services, specifically AWS Transcribe and OpenAI APIs."
  },
  {
    "objectID": "posts/cumbre-ia/index.html#downloading-and-segmenting-the-video-and-audio-from-youtube",
    "href": "posts/cumbre-ia/index.html#downloading-and-segmenting-the-video-and-audio-from-youtube",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Downloading and Segmenting the Video and Audio from YouTube",
    "text": "Downloading and Segmenting the Video and Audio from YouTube\nFirst, it is necessary to download the full video and audio of the broadcast.\n\n\nCode\nimport yt_dlp as ydl\n\nvideo_url = 'https://www.youtube.com/watch?v=mSnMpzkR2R0'\n\nydl_audio_opts = {\n    'outtmpl': 'data/cumbre_ia_montevideo.%(ext)s',\n    'format': 'bestaudio/best',\n    'postprocessors': [{\n        'key': 'FFmpegExtractAudio',\n        'preferredcodec': 'mp3',\n        'preferredquality': '192'}]\n}\nydl_video_opts = {\n    'outtmpl': 'data/cumbre_ia_montevideo.%(ext)s',\n}\n\nydl.YoutubeDL(ydl_audio_opts).download([video_url])\nydl.YoutubeDL(ydl_video_opts).download([video_url])\n\n\nThen, it is necessary to segment the audio and video into each of the panels and talks from the summit. As an example, we will extract the opening panel, which runs from the beginning to minute 43:15.\n\n\nCode\nimport pydub\nfrom moviepy.video.io.VideoFileClip import VideoFileClip\n\nduration = 43.15 * 60.00\n\naudio_segmentado = pydub.AudioSegment.from_file('../data/cumbre_ia_montevideo.mp3', duration=duration)\n\nvideo = VideoFileClip('../data/cumbre_ia_montevideo.webm')\nvideo_segmentado = video.subclip(0, duration)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#transcription-with-aws-transcribe",
    "href": "posts/cumbre-ia/index.html#transcription-with-aws-transcribe",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Transcription with AWS Transcribe",
    "text": "Transcription with AWS Transcribe\nThe AWS Transcribe API allows the use of a customized vocabulary to improve the accuracy of transcribing technical terms, domain-specific words, or proper names. Additionally, it provides the transcript in both subtitle format and plain text.\n\n\nCode\nfrom __future__ import print_function\nimport time\nimport boto3\n\ntranscribe = boto3.client('transcribe', 'us-east-1')\n\njob_name = \"cumbre-ia-montevideo-apertura\"\njob_uri = \"s3://cumbre-ia-montevideo/input-audios/cumbre_ia_montevideo_apertura.mp3\"\n\ntranscribe.start_transcription_job(\n    TranscriptionJobName = job_name,\n    Media = {\n        'MediaFileUri': job_uri\n    },\n    OutputBucketName = 'cumbre-ia-montevideo',\n    OutputKey = 'output-transcriptions/', \n    LanguageCode = 'es-US', \n    Subtitles = {\n        'Formats': [\n            'vtt','srt'\n        ],\n        'OutputStartIndex': 1 \n   },\n    Settings = {\n        'ShowSpeakerLabels': True,\n        'MaxSpeakerLabels': 5,\n        'VocabularyName': 'cumbre-ia-montevideo-apertura-vocabulario'\n    }    \n)\n\nwhile True:\n    status = transcribe.get_transcription_job(TranscriptionJobName = job_name)\n    if status['TranscriptionJob']['TranscriptionJobStatus'] in ['COMPLETED', 'FAILED']:\n        break\n    print(\"Not ready yet...\")\n    time.sleep(5)\nprint(status)"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#embedding-the-subtitles-into-the-video",
    "href": "posts/cumbre-ia/index.html#embedding-the-subtitles-into-the-video",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Embedding the Subtitles into the Video",
    "text": "Embedding the Subtitles into the Video\nWe then embed the subtitles into the video.\n\n\nCode\nfrom moviepy.editor import CompositeVideoClip\nfrom moviepy.video.tools.subtitles import SubtitlesClip\nfrom moviepy.video.fx.resize import resize\nimport moviepy.editor as mp\n\n# Load subtitles from an SRT file\n# You can adjust the font size, font type, etc.\ngenerator = lambda txt: mp.TextClip(txt, font='Arial', fontsize=48, color='white')\n\n# Create the SubtitlesClip\nsubtitles = SubtitlesClip(\"../data/cumbre-ia-montevideo-apertura.srt\", generator)\n\n# Overlay the subtitles on the video\nvideo_with_subtitles = CompositeVideoClip([video_segmentado, subtitles.set_position(('center', 'bottom'))])\n\n# Write the final video file with subtitles embedded\nvideo_with_subtitles.write_videofile(\"../data/cumbre_ia_montevideo_apertura_with_subtitles.mp4\", fps=video.fps)\n\n\nHere is the opening video with the embedded subtitles:"
  },
  {
    "objectID": "posts/cumbre-ia/index.html#automatic-summary-with-openai",
    "href": "posts/cumbre-ia/index.html#automatic-summary-with-openai",
    "title": "Ministerial Summit on the Ethics of AI in LAC",
    "section": "Automatic Summary with OpenAI",
    "text": "Automatic Summary with OpenAI\nNow we will use the OpenAI API to automatically summarize the transcriptions of the speeches during the summit’s opening.\nFirst, some preprocessing of the transcriptions is required.\n\n\nCode\nimport boto3\nimport json\n\ns3_client = boto3.client('s3')\n\ntranscripcion = s3_client.get_object(Bucket='cumbre-ia-montevideo', Key='output-transcriptions/cumbre-ia-montevideo-aperura.json')['Body'].read().decode('utf-8')\n\ndata = json.loads(transcripcion)\n\n# Extraer las etiquetas de orador y las palabras\nitems = data['results']['items']\nspeaker_labels = data['results']['speaker_labels']['segments']\n\ntranscripcion_por_orador = []\n\n# Crear una estructura para mantener las intervenciones agrupadas\ncurrent_speaker = None\ncurrent_segment = []\n\nfor segment in speaker_labels:\n    speaker = segment['speaker_label']\n    start_time = float(segment['start_time'])\n    end_time = float(segment['end_time'])\n    \n    if current_speaker is None or current_speaker != speaker:\n        # Guardar la intervención anterior antes de cambiar de orador\n        if current_segment:\n            transcripcion_por_orador.append({\n                \"orador\": current_speaker,\n                \"texto\": \" \".join(current_segment)\n            })\n        # Empezar un nuevo segmento\n        current_speaker = speaker\n        current_segment = []\n\n    # Extraer las palabras dentro del rango de tiempo del segmento actual\n    for item in items:\n        if 'start_time' in item:\n            word_time = float(item['start_time'])\n            if start_time &lt;= word_time &lt; end_time:\n                current_segment.append(item['alternatives'][0]['content'])\n\n# Añadir la última intervención\nif current_segment:\n    transcripcion_por_orador.append({\n        \"orador\": current_speaker,\n        \"texto\": \" \".join(current_segment)\n    })\n\n\ntranscripcion_por_orador_sin_presentador = [intervencion for intervencion in transcripcion_por_orador if intervencion['orador'] != 'spk_0']\n\n\nThen, we send the text of the speeches to OpenAI to obtain a summary of each presentation.\n\n\nCode\nfrom dotenv import load_dotenv\nimport openai\n\nload_dotenv()\n\nsintesis_transcripciones = []\n\nfor i in range(len(transcripcion_por_orador_sin_presentador)):\n    prompt = f\"\"\"\n    Estoy realizando una síntesis de las exposiciones en la 2da Cumbre Ministerial y de Altas Autoridades sobre la Ética en la Inteligencia Artificial. \\\n    La misma se realizó el pasado 3 y 4 de octubre en Montevideo, Uruguay. \\\n    En este caso, toca resumir la transcripción del panel {panel}, integrado por {''.join(oradores)}. \\\n    Procura corregir los errores de transcripción, sobre todo en los nombres propios. \\\n    Devuelve sólo el resumen de la transcripción, sin comentarios adicionales. \\\n    A continuación, la transcripción completa de la exposición de {oradores[i]}: \\\n    {transcripcion_por_orador_sin_presentador[i]['texto']}\n    \"\"\"\n    response = openai.chat.completions.create(\n        model=\"gpt-4o\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        max_tokens=1000\n    )\n    assistant_response = response.choices[0].message.content\n    sintesis_transcripciones.append({'orador': oradores[i], 'sintesis_exposicion': assistant_response})\n\n\nFinally, we display the summaries of the speeches.\n\n\nCode\nfrom IPython.display import display, Markdown\n\nfor sintesis in sintesis_transcripciones:\n    display(Markdown(f\"### {sintesis['orador']}:\\n\\n{sintesis['sintesis_exposicion']}\"))\n\n\n\nBeatriz Argimón, Vicepresidenta de la República Oriental del Uruguay:\nBeatriz Argimón, Vicepresidenta de la República Oriental del Uruguay, expresó su entusiasmo por participar en la apertura de la 2da Cumbre Ministerial sobre la Ética en la Inteligencia Artificial. Destacó la importancia de los debates éticos y el protagonismo que deben asumir aquellos con responsabilidades, sobre todo en un país con alta adhesión democrática como Uruguay. Señaló la relevancia de proteger los derechos humanos y las democracias frente a los cambios vertiginosos de la inteligencia artificial.\nArgimón enfatizó la necesidad de un enfoque regional unido en América Latina y el Caribe para avanzar en el ámbito global y subrayó la importancia de enfrentar los desafíos con responsabilidad ética. Expresó su orgullo por las políticas de Estado de Uruguay, independientes del partido político gobernante, y elogió el papel de AGESIC y Hebert Paguas en la creación de una conciencia estratégica en el ámbito público.\nFinalmente, habló sobre la responsabilidad democrática de informar y educar a la ciudadanía sobre estos nuevos tiempos y agradeció a los organizadores de la cumbre por promover el entendimiento de que estos tiempos, aunque desafiantes, también son esperanzadores.\n\n\nChristian Asinelli, Vicepresidente Corporativo de Programación Estratégica, CAF -banco de desarrollo de América Latina y el Caribe-:\nEn la 2da Cumbre Ministerial y de Altas Autoridades sobre la Ética en la Inteligencia Artificial, celebrada en Montevideo, Uruguay, el discurso de apertura de Christian Asinelli, Vicepresidente Corporativo de Programación Estratégica de CAF -banco de desarrollo de América Latina y el Caribe-, abordó varios puntos clave:\nChristian Asinelli resaltó la importancia de abordar los problemas globales con soluciones regionales, especialmente en el ámbito de la inteligencia artificial (IA) y otras áreas como la energía y la alimentación. Destacó el esfuerzo conjunto con la UNESCO para implementar políticas públicas de IA y mencionó la anterior Cumbre de Ética de la Inteligencia Artificial en Chile, donde se lanzó la Declaración de Santiago. Asinelli expresó la expectativa de que la Declaración de Montevideo continúe avanzando en capacidades regionales.\nAdemás, Asinelli enfatizó la necesidad de una transición justa e inclusiva en América Latina y el Caribe, considerando las capacidades fiscales y la pobreza en la región, y subrayó los riesgos de la IA, incluyendo derechos humanos, transparencia y democracia. Destacó la colaboración con diferentes organizaciones y la intención de crear una hoja de ruta con un enfoque holístico que sitúe al ser humano en el centro de las políticas públicas de IA. También mencionó la importancia de los espacios de diálogo y reflexión durante la cumbre para promover una IA al servicio de la comunidad.\nEn conclusión, Asinelli agradeció los esfuerzos conjuntos del gobierno de Uruguay, la UNESCO y todos los involucrados en la organización de esta cumbre, proyectando que será un evento significativo en el desarrollo de la IA ética en la región.\n\n\nGabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas, UNESCO:\nEn su intervención, Gabriela Ramos, Subdirectora General de Ciencias Sociales y Humanas de la UNESCO, agradeció al Gobierno de Uruguay y a los participantes de la cumbre por la oportunidad de discutir temas relevantes sobre la ética en la inteligencia artificial. Resaltó la importancia de América Latina en definir su propio destino tecnológico y enfatizó que el proceso involucra no solo aspectos tecnológicos, sino sociales, económicos y de visión para el desarrollo sostenible.\nMencionó que el proceso iniciado con el Consenso de Santiago ha sido destacado a nivel internacional y subrayó la necesidad de seguir avanzando con nuevas etapas, como las planificadas para la República Dominicana. Ramos destacó los retos y logros de los países en sus hojas de ruta (RAM), señalando el éxito de Uruguay en diversas áreas como la protección de datos y la energía renovable.\nRamos enfatizó el crecimiento significativo de la inversión global en inteligencia artificial y la necesidad de que las tecnologías sirvan para resolver problemas humanos. Asimismo, instó a los países de América Latina a incrementar sus inversiones en investigación y desarrollo, sugiriendo que un aumento del PIB dedicado a este sector podría impulsar el crecimiento económico y social.\nFinalmente, subrayó la importancia de la ética en el desarrollo tecnológico y el papel de las competencias humanas, proponiendo una educación que fomente el pensamiento crítico y la inclusión de humanidades en programas tecnológicos. Concluyó reiterando el compromiso de la UNESCO de trabajar conjuntamente con las naciones de la región para aprovechar la inteligencia artificial de manera inclusiva y beneficiosa.\n\n\nHebert Paguas, Director Ejecutivo de AGESIC:\nHebert Paguas, Director Ejecutivo de AGESIC, comenzó su intervención en la Cumbre reflexionando sobre el reto de abordar el ritmo acelerado de los cambios tecnológicos, especialmente en comparación con la lentitud de los procesos legislativos tradicionales. Subrayó que aunque la inteligencia artificial (IA) se definió por primera vez en 1956, el debate significativo sobre su influencia apenas tomó auge en 2022 con la aparición de la inteligencia artificial generativa, que simula una conversación humana. Paguas expresó su deseo de que la tecnología no llegue a suplantar la esencia humana, diferenciando a los humanos como “Homo Viator”, seres en constante viaje y búsqueda de madurez.\nAdemás, destacó la importancia de la colaboración regional e internacional para enfrentar los desafíos que surgen en el entorno digital, donde los límites territoriales de la legislación se vuelven obsoletos. Citó la necesidad de coordinación internacional similar a la que ocurre en el mundo físico con convenios como los de extradición, ahora trasladados al ámbito digital.\nPaguas también mencionó el Pacto Global Digital y enfatizó tanto en los beneficios potenciales de la tecnología como en los riesgos aún desconocidos que conlleva. Agradeció a organizaciones como la UNESCO y la CAF por su apoyo logístico y esfuerzo colaborativo en el evento, y concluyó destacando la importancia de que Uruguay se posicione como un polo de innovación, resaltando el rol necesario del sector privado y la preparación del sector público para enfrentar los retos presentes y futuros."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "",
    "text": "Note: for those interested in the code used to generate each visualization, you can see it by clicking the “Show/Hide All Code” button at the top right of the page or the “Code” button above and to the right of each visualization."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#day-3---polygons",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#day-3---polygons",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Day 3 - Polygons",
    "text": "Day 3 - Polygons\nMobile network cells can be modeled using Voronoi Diagrams. Typically, this is done for mobility analysis with cellular signaling data, as shown in this paper.\n\nlibrary(tidyverse)\nlibrary(sf)\nlibrary(httr)\nlibrary(ggvoronoi)\nlibrary(ggmap)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:departamento\",\n                            cql_filter=\"in1='02007'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\n\ncomuna1_sf &lt;- read_sf(ign_geoserver_url)\n\ncomuna1_centroid &lt;- st_centroid(comuna1_sf)\ncomuna1_bbox &lt;- st_bbox(comuna1_sf)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(comuna1_bbox[c(2,1,4,3)], collapse = \",\"), \")\", \" AND Banda='7'\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_comuna1 &lt;- read_sf(idecom_geoserver_url)\n\nradiobases_4g_comuna1 &lt;- radiobases_4g_comuna1 %&gt;% \n  as_Spatial() %&gt;% \n  sp::remove.duplicates() %&gt;% \n  st_as_sf() %&gt;% \n  na.omit()\n\nregister_google(Sys.getenv(\"GOOGLE_MAPS_API_KEY\"))\ncomuna1_map &lt;- get_googlemap(center = c(lon=-58.37869433449463, \n                                        lat=-34.606838945727), \n                             zoom = 15)\n\nggmap(comuna1_map, \n      base_layer = ggplot(data = na.omit(st_drop_geometry(radiobases_4g_comuna1)), \n                          aes(Longitud, Latitud))) +\n  geom_path(stat = \"voronoi\", alpha = 0.6, size = 0.4) +\n  geom_point(color = \"blue\", size = 0.7) +\n  theme_minimal() +\n  theme(axis.text = element_blank(),\n        axis.title = element_blank())"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-3-and-4/index.html#day-4---hexagons",
    "href": "posts/30-day-map-challenge-day-3-and-4/index.html#day-4---hexagons",
    "title": "30 Day Map Challenge Day 3 and 4",
    "section": "Day 4 - Hexagons",
    "text": "Day 4 - Hexagons\nHexagons can also be used to plot 4G radio bases, using color intensity to show their density.\n\nlibrary(hexbin)\n\nign_geoserver_base_url &lt;- \"https://wms.ign.gob.ar/geoserver/ows\"\n\nign_geoserver_query &lt;- list(service=\"wfs\",\n                            version=\"1.1.0\",\n                            request=\"GetFeature\",\n                            typeNames=\"ign:provincia\",\n                            CQL_FILTER=\"in1='02'\")\n\nign_geoserver_url &lt;- modify_url(url = ign_geoserver_base_url,\n                                query = ign_geoserver_query)\ncaba &lt;- read_sf(ign_geoserver_url)\n\ncaba_bb &lt;- st_bbox(caba)\n\nidecom_geoserver_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\n\nidecom_geoserver_query &lt;- list(service=\"wfs\",\n                               version=\"1.3.0\",\n                               request=\"GetFeature\",\n                               typeNames=\"publico:Antenas103-NO4G-5-3\",\n                               cql_filter=paste0(\"BBOX(the_geom,\", paste(caba_bb[c(2,1,4,3)], collapse = \",\"), \")\"))\n\nidecom_geoserver_url &lt;- modify_url(url=idecom_geoserver_base_url, \n                                   query = idecom_geoserver_query)\n\nradiobases_4g_caba &lt;- read_sf(idecom_geoserver_url)\n\nif(st_crs(caba)!=st_crs(radiobases_4g_caba)) {\n  radiobases_4g_caba &lt;- st_transform(radiobases_4g_caba, crs = st_crs(caba))\n}\nradiobases_4g_caba &lt;- st_join(radiobases_4g_caba, caba, left=FALSE)\n\ncaba %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_hex(data = radiobases_4g_caba, aes(Longitud, Latitud)) +\n  theme_bw() +\n  coord_sf(datum = NA) +\n  scale_fill_viridis_c(direction = -1, name = \"Radiobases 4G\") +\n  theme(axis.title.x = element_blank(),\n        axis.title.y = element_blank())"
  },
  {
    "objectID": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/soupsieve-2.5.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2023 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "href": "lib/python3.11/site-packages/pyzmq-25.1.2.dist-info/AUTHORS.html#authors",
    "title": "Data & ICTs",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "href": "lib/python3.11/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "href": "lib/python3.11/site-packages/idna-3.6.dist-info/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2023, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpcore-1.0.2.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "You Only Look Once\n\n\nYou Only Look Once\n\n\n\ncomputer-vision\n\n\ndeep-learning\n\n\npython\n\n\nyolo\n\n\nultralytics\n\n\n\n\n\n\n\n\n\nJan 11, 2026\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nLanguage Models in Spanish\n\n\nModelos de Lenguaje en Español\n\n\n\nAI\n\n\nLLM\n\n\nHugging Face\n\n\n\n\n\n\n\n\n\nDec 18, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nMinisterial Summit on the Ethics of AI in LAC\n\n\nCumbre Ministerial sobre la Ética de la IA en LAC\n\n\n\nAI\n\n\nAWS\n\n\nOpenAI\n\n\n\n\n\n\n\n\n\nNov 17, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nSTEM Movie Recommendations\n\n\nRecomendaciones de películas STEM\n\n\n\nPelículas\n\n\nMovies\n\n\nSeries\n\n\nSTEM\n\n\n\n\n\n\n\n\n\nSep 30, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nSTEM Book Recommendations\n\n\nRecomendaciones de libros STEM\n\n\n\nLibros\n\n\nBooks\n\n\nSTEM\n\n\n\n\n\n\n\n\n\nSep 22, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nOn Regulatory Simplification\n\n\nSobre Simplificación Regulatoria\n\n\n\nAnálisis de Grafos\n\n\nGraph Analysis\n\n\n\n\n\n\n\n\n\nJul 24, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Infrastructure Subsidies Analysis\n\n\nAnálisis de Subsidios para Infraestructura TIC\n\n\n\nANR\n\n\n\n\n\n\n\n\n\nApr 26, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nREFEFO Potential to Enhance Productive Connectivity\n\n\nEl Potencial de la REFEFO para Mejorar la Conectividad Productiva\n\n\n\nREFEFO\n\n\nProductive Connectivity\n\n\n\n\n\n\n\n\n\nApr 26, 2024\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Whisper to Transcribe Messi\n\n\nTranscribir a Messi con Whisper\n\n\n\nNLP\n\n\nIA\n\n\nML\n\n\nPython\n\n\nMessi\n\n\n\n\n\n\n\n\n\nFeb 3, 2023\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nBeckham vs. Papu Gomez\n\n\nBeckham vs. Papu Gomez\n\n\n\n\n\n\n\n\n\n\n\nJan 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nForum on Equality and the Digital Divide\n\n\nForo Brechas y Equidad Digital\n\n\n\n\n\n\n\n\n\n\n\nJun 17, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Companies Social Network Analysis\n\n\nAnálisis de Empresas TIC en Redes Sociales\n\n\n\nNLP\n\n\nsocial networks\n\n\n\n\n\n\n\n\n\nApr 20, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Fix Access Dashboard for Argentina\n\n\nTablero de Accesos Fijos a Internet en Argentina\n\n\n\n\n\n\n\n\n\n\n\nApr 12, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nUsing Satellite Images\n\n\nUsando Imágenes Satelitales\n\n\n\n\n\n\n\n\n\n\n\nMar 19, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\nICT Prices Evolution\n\n\nEvolución de los precios\n\n\n\n\n\n\n\n\n\n\n\nFeb 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nInternet Submarine Cables\n\n\nCables Submarinos de Internet\n\n\n\n\n\n\n\n\n\n\n\nFeb 6, 2022\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Day Map Challenge Day 3 and 4\n\n\nDía 3 y 4 del Desafío de Mapas de 30 Días\n\n\n\n\n\n\n\n\n\n\n\nNov 9, 2021\n\n\nMartin Olmos\n\n\n\n\n\n\n\n\n\n\n\n\n30 Days Map Challenge Day 1 and 2\n\n\n30 Days Map Challenge Día 1 y 2\n\n\n\n\n\n\n\n\nNov 6, 2021\n\n\nMartin Olmos\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Code\nimport matplotlib.pyplot as plt\nimport matplotlib.dates as mdates\nfrom datetime import datetime\nimport matplotlib.patches as mpatches\n\ntoday = date.today().strftime(\"%d/%m/%Y\")\n\n# Activity data\nfechas = [\n    (\"01/09/2024\", today, \"CAF: Main Executive at the Digital Transformation Department\", \"Professional Experience\"),\n    (\"01/09/2023\", \"01/05/2024\", \"IDB: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/03/2023\", \"31/12/2023\", \"BNMC: Associate Consultant\", \"Professional Experience\"),\n    (\"01/02/2023\", \"01/03/2024\", \"CAF: Data Science and ICT Consultant\", \"Professional Experience\"),\n    (\"01/07/2022\", \"01/12/2023\", \"UNSAM: Instructor in Open Government and New Technologies\", \"Teaching Activity\"),\n    (\"01/06/2021\", \"31/12/2023\", \"PELI: Instructor in New Technologies\", \"Teaching Activity\"),\n    (\"01/04/2023\", \"31/01/2024\", \"ITBA: Master's in Data Science\", \"Academic Training\"),\n    (\"20/12/2019\", \"11/03/2022\", \"Deputy Secretary of ICTs\", \"Professional Experience\"),\n    (\"01/08/2018\", \"31/07/2019\", \"ITBA: Specialization in Data Science\", \"Academic Training\"),\n    (\"01/07/2018\", \"01/11/2019\", \"SUBE: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/08/2018\", \"01/06/2019\", \"Muni San Miguel: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/02/2018\", \"01/08/2018\", \"OPDS: Data Science Consultant\", \"Professional Experience\"),\n    (\"01/04/2017\", \"01/11/2019\", \"iCiudad: Executive Director\", \"Professional Experience\"),\n    (\"01/05/2015\", \"01/12/2016\", \"CAF: Data Science Consultant\", \"Professional Experience\"),\n    (\"14/01/2015\", \"10/10/2016\", \"GWU: Master in Public Policy\", \"Academic Training\"),\n    (\"01/11/2009\", \"01/12/2014\", \"ANSES: Regional Head of Buenos Aires City\", \"Professional Experience\")\n]\n\n# Create a color map that maps each category to a specific color\ncolor_map = {\n    \"Professional Experience\": \"lightskyblue\",\n    \"Teaching Activity\": \"palegreen\",\n    \"Academic Training\": \"peachpuff\"\n}\n\n# Transform string dates to datetime format\nfechas_convertidas = [(datetime.strptime(start, \"%d/%m/%Y\"), datetime.strptime(end, \"%d/%m/%Y\")) for start, end, _, _ in fechas]\n\n# Create figure and axis\nfig, ax = plt.subplots()\n\n# Create a list of patches to add to the legend\npatches = [mpatches.Patch(color=color, label=label) for label, color in color_map.items()]\n\n# Add the legend to the plot\nplt.legend(handles=patches)\n\n# Add each activity as a horizontal bar\nfor i, (start, end, label, category) in enumerate(fechas):\n    start_date = datetime.strptime(start, \"%d/%m/%Y\")\n    end_date = datetime.strptime(end, \"%d/%m/%Y\")\n    ax.barh(i, (end_date - start_date).days, left=start_date, color=color_map[category], label=label)\n\n# Format dates in the x axis\nax.xaxis.set_major_locator(mdates.YearLocator())\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n\n# Add legends and labels\nax.set_yticks(range(len(fechas)))\nax.set_yticklabels([label for _, _, label, _ in fechas])\nplt.xlabel('Year')\nplt.title('Martin Olmos CV Timeline')\nplt.xticks(rotation=45)\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\nI have a degree in Political Science (Universidad Católica Argentina - UCA), a Masters degree in Public Policy (George Washington University - GWU) and a Specialization in Data Science (Instituto Tecnológico de Buenos Aires - ITBA).\n\nEDUCATION\n2023 MASTER IN DATA SCIENCE\n(Thesis in progress) Instituto Tecnológico de Buenos Aires (ITBA)\n2018 SPECIALIZATION IN DATA SCIENCE\nInstituto Tecnológico de Buenos Aires (ITBA)\n2016 MASTER IN PUBLIC POLICY\nTrachtenberg School of Public Policy and Public Administration\nGeorge Washington University\n2003 DEGREE IN POLITICAL SCIENCE\nFacultad de Ciencias Políticas y Relaciones Internacionales. Pontificia Universidad Católica Argentina. Buenos Aires, Argentina.\n\n\nPROFESIONAL AND TEACHING BACKGROUND\n9/2024- present day CAF LATIN AMERICAN DEVELOPMENT BANK Responsibility: Main Executive at the Digital Transformation Department\n9/2023- 4/2024 INTER-AMERICAN DEVELOPMENT BANK\nResponsibility: Consultant on Data Science and ICTs\n3/2023- 12/2023 BLUENOTE MANAGEMENT CONSULTING\nResponsibility: Associate Consultant\n2/2023- 2/2024 CAF LATIN AMERICAN DEVELOPMENT BANK\nResponsibility: Consultant on Data Science and ICTs\n7/2022- 12/2023 DIPLOMA ON CITY MANAGEMENT - ESCUELA DE ECONOMÍA Y NEGOCIOS – UNIVERSIDAD NACIONAL DE SAN MARTÍN\nResponsibility: Professor on Open Government and New Technologies\n12/2019-03/2022 UNDERSECRETARY OF INFORMATION AND COMMUNICATIONS TECHNOLOGIES OF THE CHIEF OF CABINET OF ARGENTINA\n6/2021-9/2021 EXECUTIVE PROGRAM ON INNOVATIVE LEADERSHIP – OEI, ILES, SECRETARÍA DE ASUNTOS ESTRATÉGICOS DE LA REPÚBLICA ARGENTINA\nResponsibility: Professor on New Technologies\n*4/2017-11/2019 INSTITUTO CIUDAD – POLÍTICAS PÚBLICAS PARA BUENOS AIRES\nResponsibility: Executive Director\n8/2019-present day INTRODUCTORY SEMINAR ON DATA SCIENCE FOR SOCIAL SCIENCES – FACULTAD DE CIENCIAS SOCIALES (UBA)\nResponsibility: Professor\n2/2019-present day THE CARPENTRIES – DATA CARPENTRY\nResponsibility: Instructor\n7/2018-11/2019 DIRECCIÓN DE IMPLEMENTACIÓN Y SEGUIMIENTO SUBE – MINISTERIO DE TRANSPORTE DE LA NACIÓN\nResponsibility: Consultant on data science\n8/2018-6/2019 SECRETARÍA DE ASUNTOS PÚBLICOS – MUNICIPALIDAD DE SAN MIGUEL\nResponsibility: Consultant on data science\n2/2018-8/2018 ORGANISMO PROVINCIAL PARA EL DESARROLLO SOSTENIBLE\nResponsibility: Consultant on data science\n1/2017-6/2018 CONVENIO MINISTERIO DE TRANSPORTE-UNSAM\nResponsibility: Consultant on data science\n5/2015-12/2016 BANCO DE DESARROLLO DE AMÉRICA LATINA (CAF)\nResponsibility: Consultant on data science\n11/2009-12/2014 ADMINISTRACIÓN NACIONAL DE LA SEGURIDAD SOCIAL\nResponsibility: Regional Chief for Buenos Aires City.\n\n\nFELLOWSHIPS\n2016 ORGANIZATION OF AMERICAN STATES (OAS) FELLOWSHIP FOR GRADUATE STUDIES.\n2015 GLOBAL LEADERS FELLOWSHIP 2015-2016 , GEORGE WASHINGTON UNIVERSITY.\n2015 FULBRIGHT FELLOWSHIP FOR MASTER STUDIES 2015-2016 , COMISIÓN FULBRIGHT ARGENTINA.\n2013 IV FORO “EL FUTURO DE AMÉRICA LATINA: LA VISIÓN DE LOS JÓVENES LÍDERES” , CAF – BANCO DE DESARROLLO DE AMÉRICA LATINA A PARTICIPAR, CIUDAD DE MÉXICO, 22 Y 23 DE AGOSTO DE 2013.\n2013 PROGRAMA DE GOBIERNO PARA EL DESARROLLO DE LÍDERES DE COMUNIDADES LOCALES. CENTRO DE ESTUDIOS EN GOBIERNO, EMPRESA, SOCIEDAD Y ECONOMÍA, IAE BUSINESS SCHOOL, UNIVERSIDAD AUSTRAL, PILAR, PROVINCIA DE BUENOS AIRES, MAYO Y JUNIO DE 2013. BECA OTORGADA POR LA FUNDACIÓN RAP (RED DE ACCIÓN POLÍTICA).\n2005 FURP-USA PROGRAM, DEPARTMENT OF STATE OF THE UNITED STATES OF AMERICA. FEBRUARY 2005.\n\n\nINTERNATIONAL CONFERENCES AND ACTIVITIES\n\nJune 2022\n\nOrganized by | Cámara Chilena de Infraestructura Digital y Asociación Chilena de Municipalidades\nEvent | Forum on Equality and Digital Divide\nPanel | The role of universal access funds\n\nMarch 2022\n\nOrganized by | GSMA\nEvent | Ministerial Programme - Mobile World Congress (MWC)\n\nFebruary 2022\n\nOrganized by | Unión Internacional Telecomunicaciones (ITU)\nEvent | 4th Global Standards Symposium\nPanel | International Standards for Digital Transformation\n\nNovember 2021\n\nOrganized by | Forum Europe (Forum Global)\nEvent | Latin America Spectrum Management Conference\nTema | The Emerging Shape of the 6GHz Band\n\nJune 2021\n\nOrganized by | GSMA\nEvent | Spectrum Roundtable at the Ministerial Programme - Mobile World Congress (MWC)\nRoundtable | The Future of Spectrum Access\n\nNovember 2020\n\nOrganized by | Forum Europe (Forum Global)\nEvent | Latam Spectrum Conference\nTema | Bridging the Digital Divide – How Has Covid Shone a Light on Digital Inequalities and How Can the Region Move Forward in Tackling This Issue?\n\nOctober 2020\n\nOrganized by | International Institute of Communications\nTema | Digital Transformation Post COVID-19: LatAm Responses to the Digital Divide.\n\nJuly 2020\n\nOrganized by | ITU, GeSI & the United Nations Office for South South Cooperation.\nPanel | Accelerating Action and Transformative Pathways for Delivering on the Sustainable Development Goals and Recovery from COVID-19 Pandemic.\n\n\nNATIONAL CONFERENCES AND ACTIVITIES\n\nMay 2021\n\nOrganized by | CABASE\nEvent | Internet Day\nPanel | Infrastructure development initiatives for universal connectivity\nOrganized by | ISOC Argentinean Chapter and Facultad de Ingeniería de Universidad de Palermo\nEvent | 5tas Jornadas sobre Perspectivas de las Telecomunicaciones y TICs 2021\nPanel | Desafíos Actuales de las Telecomunicaciones\n\nApril 2021\n\nOrganized by | Grupo Convergencia\nEvent | NPlay Cono Sur\nTema | Programms to Reduce the Digital Divide and Infrastructure Sharing\n\nDecember 2020\n\nOrganized by | Grupo Convergencia\nTema | Infrastructure and Network Deployment for Growth in the New Normal\nOrganized by | Internet Governance Forum (IGF)\nTema | Algorithms and AI Governance\n\nAugust 2020 – March 2022\n\nOrganized by | BID - INTAL\nProgram | Regional Program for Latin America and the Caribbean Integration to the Digital Economy\nPosition | Member of the Board"
  },
  {
    "objectID": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "href": "lib/python3.11/site-packages/httpx-0.26.0.dist-info/licenses/LICENSE.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "UAT for NbAgg backend.",
    "section": "",
    "text": "from imp import reload\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)"
  },
  {
    "objectID": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "lib/python3.11/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "UAT for NbAgg backend.",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#original-authors",
    "title": "Authors",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#current-maintainers",
    "title": "Authors",
    "section": "",
    "text": "Daniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)"
  },
  {
    "objectID": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "href": "lib/python3.11/site-packages/QtPy-2.4.1.dist-info/AUTHORS.html#contributors",
    "title": "Authors",
    "section": "",
    "text": "The QtPy Contributors"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "",
    "text": "Note: for those interested in the code used to generate each visualization, you can see it by pressing the “Show/Hide All Code” button at the top right of the page or the “Code” button at the top right of each visualization.\nThe #30daymapchallenge is a mapping/cartography/data visualization challenge powered by the data science community. The idea is to publish maps based on a daily challenge for 30 days using the hashtag #30daymapchallenge.\nHere are the daily themes for this year’s challenges:\nIn particular, I am going to focus (whenever I can) on data related to ICTs.\nLet’s start with the challenges of days 1 (points) and 2 (lines)."
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#day-1---points",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#day-1---points",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Day 1 - Points",
    "text": "Day 1 - Points\nConnection nodes to the Federal Fiber Optic Network (REFEFO) of ARSAT.\nThe REFEFO is a fiber optic trunk network. Internet providers or ISPs connect to the connection points or nodes to bring internet services to final users.\n\n\nCode\nlibrary(tidyverse)\nlibrary(sf)\nsf_use_s2(FALSE)\nlibrary(httr)\n\nprovincias_ign &lt;- read_sf(\"https://wms.ign.gob.ar/geoserver/ows?service=wfs&version=1.1.0&request=GetFeature&typeNames=ign:provincia&outputFormat=application/json\")\n\nif(sum(!st_is_valid(provincias_ign)) &gt; 0) {\n  provincias_ign &lt;- st_make_valid(provincias_ign)\n}\n\nprovincias_ign &lt;- st_crop(x = provincias_ign,\n                          y = st_bbox(obj = c(xmin=-76.36532,\n                                              ymin=-56.75009,\n                                              xmax=-51.20850,\n                                              ymax=-20.91625)))\n\nnodos_refefo &lt;- read.csv2(\"https://datos.arsat.com.ar/dataset/8f0b4da0-a40d-4b2b-8fe0-dac06d64152a/resource/15713af0-f384-44c5-8397-c8050162312d/download/puntos-conexion-red-federal-de-fibra-optica-2021-12-01_v1.csv\", fileEncoding = \"LATIN1\")\n\nnodos_refefo &lt;- nodos_refefo %&gt;%\n  na.omit() %&gt;%\n  st_as_sf(crs = 4326, coords=c(\"Longitud\", \"Latitud\"), remove=FALSE)\n\nnodos_refefo &lt;- st_crop(x = nodos_refefo,\n                        y = st_bbox(obj = c(xmin=-76.36532,\n                                            ymin=-56.75009,\n                                            xmax=-51.20850,\n                                            ymax=-20.91625)))\n\nprovincias_ign %&gt;% \n  ggplot() + \n  geom_sf() +\n  geom_sf(data = nodos_refefo, color = \"#2ca25f\", size = 0.5) +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.datos.gob.ar / Source: www.datos.gob.ar\")"
  },
  {
    "objectID": "posts/30-day-map-challenge-day-1-and-2/index.html#day-2---lines",
    "href": "posts/30-day-map-challenge-day-1-and-2/index.html#day-2---lines",
    "title": "30 Days Map Challenge Day 1 and 2",
    "section": "Day 2 - Lines",
    "text": "Day 2 - Lines\nLay out of the REFEFO. The optical fiber of the REFEFO is generally buried next to national and provincial routes, connecting different small and medium-sized towns, where there are no other providers or there is only one and therefore there is no competition.\n\n\nCode\nidecom_base_url &lt;- \"https://www.idecom.gob.ar/geoserver/ows\"\nrefefo_query &lt;- list(service=\"wfs\",\n                     version=\"1.3.0\",\n                     request=\"GetFeature\",\n                     typeNames=\"publico:FO118-TZFO-REDFIBRAOPTICA-5-2\",\n                     CQL_FILTER=\"OBSERV='ARSAT - ReFeFO'\",\n                     outputFormat=\"application/json\")\n\nidecom_url &lt;- modify_url(url = idecom_base_url, \n                         query = refefo_query)\n\ntraza_refefo_idecom &lt;- read_sf(idecom_url)\n\nprovincias_ign %&gt;% \n  ggplot() +\n  geom_sf() +\n  geom_sf(data = traza_refefo_idecom, colour=\"#2b8cbe\") +\n  coord_sf(datum = NA) +\n  theme_bw() +\n  labs(caption = \"Fuente: www.idecom.gob.ar / Source: www.idecom.gob.ar\")"
  },
  {
    "objectID": "posts/beckham-vs-papu-gomez/index.html",
    "href": "posts/beckham-vs-papu-gomez/index.html",
    "title": "Beckham vs. Papu Gomez",
    "section": "",
    "text": "This post is not about ICTs. It’s about using AI to classify images. In this case we take a controversy that came up during the World Cup in a stream of Kun Aguero, where Lio Messi and Papu Gomez asked Kun to guess who Papu looks like, after his new haircut.\n\n\n\n\nAfter that, a controversy was opened. Does Papu Gomez look like David Beckham? That’s why I decided to train an AI model to classify images of both players. I have to say that after this I came to the conclusion that they have some similarity, since I had to go from simpler to more complex models so that it could learn to distinguish between the two.\nYou can try the application below or in the following link"
  },
  {
    "objectID": "posts/forum-equality-digital-divide/index.html",
    "href": "posts/forum-equality-digital-divide/index.html",
    "title": "Forum on Equality and the Digital Divide",
    "section": "",
    "text": "The Forum on Equality and the Digital Divide was held on June 9 and 10. In this context, I was invited to speak at the panel “Universal Access Funds in the Region: the case of Argentina.”\nHere I leave the full video of my participation (in Spanish):\n\n\n\nvideo\n\n\nAnd my presentation (in Spanish):"
  },
  {
    "objectID": "posts/ict-infra-subsidies-analysis/etl.html",
    "href": "posts/ict-infra-subsidies-analysis/etl.html",
    "title": "Data & ICTs",
    "section": "",
    "text": "from dotenv import load_dotenv\n\nload_dotenv('../../.env', override=True)\n\nTrue\n\n\n\nfrom sqlalchemy import create_engine\nimport os\n\nhost = os.getenv(\"HOST\")\nport = os.getenv(\"PORT\")\n# database = os.getenv(\"DBNAME\")\ndatabase = \"anr\"\nuser = os.getenv(\"USER\")\npassword = os.getenv(\"PASSWD\")\n\n\n\nengine = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database}\")\n\n\nimport pandas as pd\n\nanr_prog_con = pd.read_sql_table(table_name=\"conectividad_aprob_georef\", con=engine)\n\n\nanr_prog_con.drop_duplicates(inplace=True, ignore_index=True)\n\n\nanr_prog_con.columns\n\nIndex(['acta', 'tipo', 'exp', 'razon_social', 'cuit', 'programa', 'monto',\n       'lugar', 'file', 'acta_nro', 'prog_original', 'acta_file', 'fecha',\n       'provincia', 'localidad', 'departamento', 'id', 'localidad_indec',\n       'departamento_indec', 'provincia_indec', 'lat', 'lon'],\n      dtype='object')\n\n\n\nanr_prog_con.head()\n\n\n\n\n\n\n\n\nacta\ntipo\nexp\nrazon_social\ncuit\nprograma\nmonto\nlugar\nfile\nacta_nro\n...\nfecha\nprovincia\nlocalidad\ndepartamento\nid\nlocalidad_indec\ndepartamento_indec\nprovincia_indec\nlat\nlon\n\n\n\n\n0\nEX-2019-45180205-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-45180205-APN-DNFYD#ENACOM\nSEBE CABLE SOCIEDAD DE RESPONSABILIDAD LIMITADA\n3.064501e+10\nPROGRAMA CONECTIVIDAD\n2261577.0\nLocalidad de Juan A. Pradere, departamento de ...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nBuenos Aires\nJuan A Pradere\nPatagones\n06602050000\nJUAN A. PRADERE\nPatagones\nBuenos Aires\n-39.599380\n-62.651047\n\n\n1\nEX-2019-57002814-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-57002814-APN-DNFYD#ENACOM\nVIDEO CABLE TOTAL S.A.\n3.070783e+10\nPROGRAMA CONECTIVIDAD\n9874019.0\nLocalidad de Teodelina, departamento de Genera...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nSanta Fe\nTeodelina\nGeneral Lopez\n82042280000\nTEODELINA\nGeneral López\nSanta Fe\n-34.191613\n-61.527226\n\n\n2\nEX-2019-88343739-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-88343739-APN-DNFYD#ENACOM\nCOOPERATIVA DE SERVICIOS PÚBLICOS DEL CAMPILLO...\n3.054579e+10\nPROGRAMA CONECTIVIDAD\n8848620.0\nLocalidad de Del Campillo, del departamento de...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nCórdoba\nDel Campillo\nGral Roca\n14035010000\nDEL CAMPILLO\nGeneral Roca\nCórdoba\n-34.376085\n-64.494540\n\n\n3\nEX-2019-81016814-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-81016814-APN-DNFYD#ENACOM\nCOOPERATIVA DE OBRAS Y SERVICIOS PÚBLICOS MONJ...\n3.056536e+10\nPROGRAMA CONECTIVIDAD\n2661583.0\nLocalidad de Monje, departamento de San Jeróni...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nSanta Fe\nMonje\nSan Jerónimo\n82105200000\nMONJE\nSan Jerónimo\nSanta Fe\n-32.358736\n-60.942904\n\n\n4\nEX-2019-77479546-APN-DNFYD#ENACOM: Aprobar el ...\nAprobar el proyecto\nEX-2019-77479546-APN-DNFYD#ENACOM\nTELE IMAGEN PRIVADA S.A.\n3.070886e+10\nPROGRAMA CONECTIVIDAD\n5218974.0\nLocalidad de Villa Ascasubi, departamento de T...\naprobados_acta_56.csv\nActa 56\n...\nenero 2020\nCórdoba\nVilla Ascasubi\nTercero Arriba\n14161170000\nVILLA ASCASUBI\nTercero Arriba\nCórdoba\n-32.164358\n-63.892559\n\n\n\n\n5 rows × 22 columns\n\n\n\n\nanr_prog_con_simple = anr_prog_con[['fecha', 'id']]\n\n\nanr_prog_con_simple.loc[anr_prog_con_simple['fecha']=='junio', 'fecha'] = 'junio 2022' \n\n\nmeses = {'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04', 'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08', 'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'}\n\nanr_prog_con_simple['mes'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[0])\nanr_prog_con_simple['mes'] = anr_prog_con_simple['mes'].map(meses)\nanr_prog_con_simple['anio'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[1])\nanr_prog_con_simple['fecha_alt'] = anr_prog_con_simple['anio'] + '-' + anr_prog_con_simple['mes'] + '-01'\nanr_prog_con_simple['fecha_alt'] = pd.to_datetime(anr_prog_con_simple['fecha_alt'])\n\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:3: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['mes'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[0])\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['mes'] = anr_prog_con_simple['mes'].map(meses)\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:5: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['anio'] = anr_prog_con_simple['fecha'].apply(lambda x: x.split(' ')[1])\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:6: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['fecha_alt'] = anr_prog_con_simple['anio'] + '-' + anr_prog_con_simple['mes'] + '-01'\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2779528713.py:7: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['fecha_alt'] = pd.to_datetime(anr_prog_con_simple['fecha_alt'])\n\n\n\nanr_prog_con_simple['fecha'].unique()\n\narray(['enero 2020', 'julio 2020', 'febrero 2020', 'abril 2020',\n       'mayo 2020', 'agosto 2020', 'octubre 2020', 'noviembre 2020',\n       'febrero 2021', 'abril 2021', 'junio 2021', 'agosto 2021',\n       'octubre 2021', 'noviembre 2021', 'diciembre 2021', 'febrero 2022',\n       'mayo 2022', 'junio', 'agosto 2022', 'septiembre 2022',\n       'noviembre 2022', 'diciembre 2022', 'marzo 2023', 'abril 2022',\n       'mayo 2023', 'junio 2023', 'agosto 2023', 'octubre 2023',\n       'noviembre 2023'], dtype=object)\n\n\n\nanr_prog_con.loc[anr_prog_con['fecha']=='junio', 'acta_file']\n\n100    Acta 79 - junio.pdf\n101    Acta 79 - junio.pdf\n102    Acta 79 - junio.pdf\n103    Acta 79 - junio.pdf\n104    Acta 79 - junio.pdf\nName: acta_file, dtype: object\n\n\n\nanr_prog_con_simple['link'] = anr_prog_con_simple['id'].apply(lambda x: x[:-3] if x is not None else None)\n\n/var/folders/_7/80b7r22d48j6n3m0r4vsgvdm0000gn/T/ipykernel_58503/2617043581.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  anr_prog_con_simple['link'] = anr_prog_con_simple['id'].apply(lambda x: x[:-3] if x is not None else None)\n\n\n\nanr_prog_con_simple.head()\n\n\n\n\n\n\n\n\nfecha\nid\nmes\nanio\nfecha_alt\nlink\n\n\n\n\n0\nenero 2020\n06602050000\n01\n2020\n2020-01-01\n06602050\n\n\n1\nenero 2020\n82042280000\n01\n2020\n2020-01-01\n82042280\n\n\n2\nenero 2020\n14035010000\n01\n2020\n2020-01-01\n14035010\n\n\n3\nenero 2020\n82105200000\n01\n2020\n2020-01-01\n82105200\n\n\n4\nenero 2020\n14161170000\n01\n2020\n2020-01-01\n14161170\n\n\n\n\n\n\n\n\nanr_prog_con_simple_lag = anr_prog_con_simple.loc[anr_prog_con_simple['fecha_alt'] &lt; '2023-01-01']\n\n\nanr_prog_con_simple.shape, anr_prog_con_simple_lag.shape\n\n((594, 6), (515, 6))\n\n\n\ndatabase2 = \"conectividad_localidad\"\nengine2 = create_engine(f\"postgresql://{user}:{password}@{host}:{port}/{database2}\")\n\ncon_loc = pd.read_sql_table(table_name=\"con_loc\", con=engine2)\n\n/Users/martinolmos/Documents/py_projects/data_tic/lib/python3.11/site-packages/pandas/io/sql.py:1725: SAWarning: Did not recognize type 'geometry' of column 'geometry'\n  self.meta.reflect(bind=self.con, only=[table_name], views=True)\n\n\n\ncon_loc.columns\n\nIndex(['link', 'codpcia', 'coddpto', 'codloc', 'codpciadpto', 'provincia',\n       'departamento', 'localidad', 'personas', 'hogares', 'geometry',\n       'cambio', 'personas2022', 'hogares_act', 'accesos', 'otros', 'vmd',\n       'ADSL', 'CABLEMODEM', 'DIAL UP', 'FIBRA OPTICA', 'OTROS', 'SATELITAL',\n       'WIMAX', 'WIRELESS', '3G', '4G', 'pen_pob', 'pen_hog'],\n      dtype='object')\n\n\n\ncon_loc_simple = con_loc[['link', 'personas', 'pen_pob', 'vmd']]\n\n\ncon_loc_simple_anr = con_loc_simple.loc[con_loc_simple['link'].isin(anr_prog_con_simple_lag['link'])]\n\n\ncon_loc_simple_elegible = con_loc_simple.loc[con_loc_simple['personas'] &lt; 30000]\n\n\ncon_loc_simple_elegible_sin_anr = con_loc_simple_elegible.loc[~con_loc_simple_elegible['link'].isin(anr_prog_con_simple['link'])]\n\n\ncon_loc_simple.shape, con_loc_simple_elegible.shape, con_loc_simple_elegible_sin_anr.shape, con_loc_simple_anr.shape\n\n((3527, 4), (3355, 4), (2854, 4), (465, 4))\n\n\n\ncon_loc_simple_elegible_sin_anr['pen_pob'].mean(), con_loc_simple_anr['pen_pob'].mean()\n\n(27.391489894477758, 18.36155918758159)\n\n\n\ncon_loc_simple_elegible_sin_anr['pen_pob'].median(), con_loc_simple_anr['pen_pob'].median()\n\n(5.510015155247972, 8.818575156059055)\n\n\n\ncon_loc_simple_elegible_sin_anr['personas'].mean(), con_loc_simple_anr['personas'].mean()\n\n(2497.656271899089, 3126.0717131474103)\n\n\n\ncon_loc_simple_elegible_sin_anr['personas'].median(), con_loc_simple_anr['personas'].median()\n\n(553.5, 1251.0)\n\n\n\n# Calculate the 5th and 95th percentiles\nq_low = con_loc_simple_elegible_sin_anr['pen_pob'].quantile(0.05)\nq_high = con_loc_simple_elegible_sin_anr['pen_pob'].quantile(0.95)\n\n# Filter out the outliers\n# filtered_data = con_loc_simple_elegible_sin_anr[(con_loc_simple_elegible_sin_anr['pen_pob'] &gt; q_low) & (con_loc_simple_elegible_sin_anr['pen_pob'] &lt; q_high)]\nfiltered_data = con_loc_simple_elegible_sin_anr[con_loc_simple_elegible_sin_anr['pen_pob'] &lt; q_high]\n\n# Plot the histogram of the filtered data\nfiltered_data['pen_pob'].hist()\n\n\n\n\n\n\n\n\n\nq_high = con_loc_simple_anr['pen_pob'].quantile(0.95)\n\nfiltered_data_anr = con_loc_simple_anr[con_loc_simple_anr['pen_pob'] &lt; q_high]\n\nfiltered_data_anr['pen_pob'].hist()"
  },
  {
    "objectID": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "href": "posts/internet-fix-access-dashboard-in-argentina/index.html",
    "title": "Internet Fix Access Dashboard for Argentina",
    "section": "",
    "text": "It is possible to make a dashboard with basic data on fix access in Argentina very quickly (about 30 minutes), with open data from ENACOM, open source tools (in this case R, Plotly and Flexdashboards but there are many others) and deploy it online for free with Github Pages.\nHere you can see the dashboard online (in Spanish): https://martinolmos.github.io/tablero_accesos_fijos/\nAnd the code to acquire the data and generate the visualizations:\n\nFixed Accesses per 100 Households by Province\n\n# Penetracion por provincia: accesos cada 100 hogares\npen_prov_hog &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275028/data.csv\", \n                         n_max = 24, \n                         locale = locale(decimal_mark = \",\"))\n\npen_prov_hog_plot &lt;- pen_prov_hog %&gt;% \n  ggplot(aes(x = reorder(Provincia, `Accesos por cada 100 hogares`),\n             y = `Accesos por cada 100 hogares`,\n             text = Provincia)) +\n  geom_col(data=pen_prov_hog, aes(x=reorder(Provincia, `Accesos por cada 100 hogares`)), fill = \"red\") +\n  coord_flip() +\n  theme_bw() +\n  theme(axis.text.y = element_text(size = 6), axis.title = element_blank())\n\nggplotly(pen_prov_hog_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of Accesses per 100 people\n\n# Penetración: accesos cada 100 habitantes. Serie histórica\npen_nac_hab_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/281491/data.csv\",\n                              locale = locale(decimal_mark = \",\"))\n\npen_nac_hab_serie_plot &lt;- pen_nac_hab_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Accesos por cada 100 hab`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title = element_blank())\n\nggplotly(pen_nac_hab_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of the Average Download Speed\n\n# Velocidad Media de Descarga (Mbps) - Nacional\nvmd_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275016/data.csv\", col_names = c(\"Año\", \"Trimestre\", \"Velocidad Media de Descarga\", \"Periodo\"), skip = 1,\n                          locale = locale(decimal_mark = \",\"))\n\nvmd_nac_serie_plot &lt;- vmd_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = `Velocidad Media de Descarga`,\n             text = Periodo)) +\n  geom_point() +\n  geom_line(aes(group = 1)) +\n  labs(y = \"VMD en Mbps\") +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8),\n        axis.title.x = element_blank())\n\nggplotly(vmd_nac_serie_plot, tooltip = c(\"text\", \"y\"))\n\n\n\nEvolution of Fix Accesses by Technology\n\ntec_nac_serie &lt;- read_csv(\"https://datosabiertos.enacom.gob.ar/rest/datastreams/275029/data.csv\",\n                          locale = locale(decimal_mark = \",\"))\n\ntec_nac_serie &lt;- tec_nac_serie %&gt;% \n  select(-Total) %&gt;% \n  gather(Tecnología, Accesos, ADSL:Otros)\n\ntec_nac_serie_plot &lt;- tec_nac_serie %&gt;% \n  ggplot(aes(x = fct_reorder(Periodo, paste0(Año, Trimestre), .desc = FALSE), \n             y = Accesos,\n             group = Tecnología,\n             color = Tecnología,\n             text = Periodo)) +\n  geom_line() +\n  scale_y_continuous(labels = c(\"0\", \"2M\", \"4M\", \"6M\")) +\n  theme_bw() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 8), \n        axis.title = element_blank(), \n        legend.title = element_blank())\n\nggplotly(tec_nac_serie_plot, tooltip = c(\"text\", \"color\", \"y\")) %&gt;% \n  layout(legend = list(title = \"\", \n                       orientation = \"h\",\n                       y = 1.3))"
  },
  {
    "objectID": "posts/language-models-in-spanish/index.html",
    "href": "posts/language-models-in-spanish/index.html",
    "title": "Language Models in Spanish",
    "section": "",
    "text": "One of the topics discussed during the 2nd Ministerial Meeting on AI Ethics in LAC was the need for the region to advance in the development of language models in Ibero-American languages, particularly in Spanish.\nOne of the main Hubs for generative AI models is Hugging Face, which offers an API to access and host pre-trained models, datasets, and “Spaces” (web applications based on existing models in the Hub).\nWe can use the Hugging Face API to analyze the quantity, quality, and usage of models, datasets, and Spaces in Spanish and compare them with other languages such as English.\n\n\nCode\nfrom huggingface_hub import HfApi\n\napi = HfApi()\nmodels = api.list_models()\nmodels_es = api.list_models(filter=\"es\")\n\n\nLet’s first see how many models are in the Huggingface Hub and how many of them are in Spanish.\n\n\nCode\nmodels_list = list(models)\nlen(models_list)\n\n\n1191400\n\n\nCode\nmodels_es_list = list(models_es)\nlen(models_es_list)\n\n\n6444\nWe see that there are currently 1,191,400 models in the Hub, of which 6,444 are in Spanish.\nLet’s now take one of the models to see the available metadata.\n\n\nCode\nm = models_list[500]\nm.__dict__\n\n\n{'id': 'mistralai/Mistral-Large-Instruct-2411',\n 'author': None,\n 'sha': None,\n 'last_modified': None,\n 'created_at': datetime.datetime(2024, 11, 14, 20, 3, 52, tzinfo=datetime.timezone.utc),\n 'private': False,\n 'gated': None,\n 'disabled': None,\n 'downloads': 488732,\n 'downloads_all_time': None,\n 'likes': 165,\n 'library_name': 'vllm',\n 'gguf': None,\n 'inference': None,\n 'tags': ['vllm',\n  'safetensors',\n  'mistral',\n  'en',\n  'fr',\n  'de',\n  'es',\n  'it',\n  'pt',\n  'zh',\n  'ja',\n  'ru',\n  'ko',\n  'license:other',\n  'region:us'],\n 'pipeline_tag': None,\n 'mask_token': None,\n 'trending_score': 5,\n 'card_data': None,\n 'widget_data': None,\n 'model_index': None,\n 'config': None,\n 'transformers_info': None,\n 'siblings': None,\n 'spaces': None,\n 'safetensors': None,\n 'security_repo_status': None,\n 'lastModified': None,\n 'cardData': None,\n 'transformersInfo': None,\n '_id': '673657a8517b82b436cb7e4c',\n 'modelId': 'mistralai/Mistral-Large-Instruct-2411'}\nWe see that within the tags field there are tags that indicate the language in ISO 639-1 code. We can use these tags to analyze the data by language.\nFirst, I will download a dataset of ISO 639-1 codes.\n\n\nCode\nimport pandas as pd\n\niso_639_url = \"https://raw.githubusercontent.com/datasets/language-codes/refs/heads/main/data/language-codes.csv\"\niso_639 = pd.read_csv(iso_639_url)\nprint(iso_639.head())\n\n\n  alpha2    English\n0     aa       Afar\n1     ab  Abkhazian\n2     ae    Avestan\n3     af  Afrikaans\n4     ak       Akan\nNow for each model in my list of models and models in Spanish, I will create a languages attribute and assign the ISO 639-1 codes that I find in the tags field.\n\n\nCode\nfor m in models_list:\n    m.languages = [l for l in m.tags if l in iso_639[\"alpha2\"].values]\n\nfor m in models_es_list:\n    m.languages = [l for l in m.tags if l in iso_639[\"alpha2\"].values]\n\n\nLet’s see how many models have at least one language tag.\n\n\nCode\nlanguages = [m.languages for m in models_list if len(m.languages) &gt; 0]\nlanguages_es = [m.languages for m in models_es_list]\n\nlen(languages), len(languages_es)\n\n\n(143924, 6444)\nOnly 143,924 models have at least one language tag. Of these, 6,444 are in Spanish.\n\n\nCode\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import ScalarFormatter\n\n# Make a bar plot of len(models_list), len(languages) and len(languages_es)\nplt.bar([\"Total de modelos\", \"Modelos con etiqueta de lenguaje\", \"Modelos en español\"], [len(models_list), len(languages), len(languages_es)])\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\n# Add a title\nplt.title(\"Cantidad de modelos en Hugging Face Hub por lenguaje\")\n\n# Disable scientific notation\nplt.gca().yaxis.set_major_formatter(ScalarFormatter(useOffset=False))\nplt.gca().ticklabel_format(style='plain', axis='y')\n\n# Show the plot\nplt.show()\n\n\n\nAnother interesting question is how many models are “pure” in Spanish models, that is, they do not have tags for other languages.\n\n\nCode\nmodels_es_only_list = [m for m in models_es_list if len(m.languages) == 1]\nlen(models_es_only_list)\n\n\n1568\nThe models only in Spanish are 1568.\nLet’s now look at quality metrics, such as the number of likes and downloads of the Spanish models, compared to those in other languages.\n\n\nCode\nlikes = [m.likes for m in models_list]\nlikes_es = [m.likes for m in models_es_only_list]\ndownloads = [m.downloads for m in models_list]\ndownloads_es = [m.downloads for m in models_es_only_list]\n\n\n\n\nCode\nlen(likes), likes.count(0), likes.count(1)\n\n\n(1191400, 1092628, 49002)\nFrom the total of 1,191,400 models, 1,092,628 have 0 likes and 49,002 have 1 like.\n\n\nCode\nlikes_dist = {\"Min\": np.min(likes), \"25%\": np.quantile(likes, 0.25), \"Median\": np.median(likes), \"Mean\": np.mean(likes), \"75%\": np.quantile(likes, 0.75), \"90%\": np.quantile(likes, 0.9), \"95%\": np.quantile(likes, .95), \"99%\": np.quantile(likes, .99)}\n\n\n\n\nCode\nplt.bar(likes_dist.keys(), likes_dist.values())\n\nplt.title(\"Distribución de likes en modelos de Hugging Face Hub\")\n\nplt.show()\n\n\n\nAs seen in the graph, 90% of the models have 0 likes, 95% have 0 or 1 like, and 99% have 11 likes or less.\nLet’s focus on those with the most likes.\n\n\nCode\nplt.bar([\"Modelos con más de 100 likes\", \"Modelos con más de 500 likes\", \"Modelos con más de 1000 likes\", \"Modelos con más de 3000\", \"Modelos con más de 5000 likes\"], [len([l for l in likes if l &gt; 100]), len([l for l in likes if l &gt; 500]), len([l for l in likes if l &gt; 1000]), len([l for l in likes if l &gt; 3000]), len([l for l in likes if l &gt; 5000])])\n\nplt.title(\"Cantidad de modelos con más de X likes en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\nLet’s now see what happens with the models that are only in Spanish.\n\n\nCode\nlen(likes_es), likes_es.count(0), likes_es.count(1)\n\n\n(1568, 1138, 166)\nFrom the total of 1,568 models that are only in Spanish, 1,138 have 0 likes and 430 have 1 like.\n\n\nCode\nlikes_es_dist = {\"Min\": np.min(likes_es), \"25%\": np.quantile(likes_es, 0.25), \"Median\": np.median(likes_es), \"Mean\": np.mean(likes_es), \"75%\": np.quantile(likes_es, 0.75), \"90%\": np.quantile(likes_es, 0.9), \"95%\": np.quantile(likes_es, .95), \"99%\": np.quantile(likes_es, .99)}\n\n\n\n\nCode\nplt.bar(likes_es_dist.keys(), likes_es_dist.values())\n\nplt.title(\"Distribución de likes en modelos sólo en español de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(likes_es_dist)\n\n\n{'Min': np.int64(0), '25%': np.float64(0.0), 'Median': np.float64(0.0), 'Mean': np.float64(1.5012755102040816), '75%': np.float64(1.0), '90%': np.float64(3.0), '95%': np.float64(7.0), '99%': np.float64(27.0)}\nThe average number of likes for models only in Spanish is 1.5, 75% of the models have 1 like or less, 90% have 3 likes or less, 95% have 7 likes or less, and 99% have 27 likes or less.\nLet’s now look at the models only in Spanish with the most likes.\n\n\nCode\nplt.bar([\"Modelos con más de 150 likes\", \"Modelos con más de 100 likes\", \"Modelos con más de 50 likes\", \"Modelos con más de 20\"], [len([l for l in likes_es if l &gt; 150]), len([l for l in likes_es if l &gt; 100]), len([l for l in likes_es if l &gt; 50]), len([l for l in likes_es if l &gt; 20])])\n\nplt.title(\"Cantidad de modelos sólo en español con más de X likes en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(len([l for l in likes_es if l &gt; 150]), len([l for l in likes_es if l &gt; 100]), len([l for l in likes_es if l &gt; 50]), len([l for l in likes_es if l &gt; 20]))\n\n\n0 1 4 23\nThere is only one model only in Spanish with 100 likes or more, while 4 models have 50 likes or more and 23 models have 20 likes or more.\nLet’s now look at the downloads.\n\n\nCode\nlen(downloads), downloads.count(0), downloads.count(1)\n\n\n(1191400, 588526, 26337)\nFrom the total of 1,191,400 models, 588,526 (approximately half) have 0 downloads.\n\n\nCode\ndl_dist = {\"Min\": np.min(downloads), \"25%\": np.quantile(downloads, 0.25), \"Median\": np.median(downloads), \"Mean\": np.mean(downloads), \"75%\": np.quantile(downloads, 0.75), \"90%\": np.quantile(downloads, 0.9), \"95%\": np.quantile(downloads, .95), \"99%\": np.quantile(downloads, .99)}\n\n\n\n\nCode\nplt.bar(dl_dist.keys(), dl_dist.values())\n\nplt.title(\"Distribución de descargas en modelos de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(dl_dist, np.max(downloads))\n\n\n{'Min': np.int64(0), '25%': np.float64(0.0), 'Median': np.float64(1.0), 'Mean': np.float64(1823.2946558670471), '75%': np.float64(11.0), '90%': np.float64(23.0), '95%': np.float64(76.0), '99%': np.float64(1398.0)} 181462888\nThe average number of downloads for the models is 1823, while the median is just 1. This large difference indicates that there are a few models with a large number of downloads that make the average so high.\nThe model with the most downloads has 181,462,888 downloads. Let’s see which model this is.\n\n\nCode\nplt.bar([\"Modelos con más de 100 mil descargas\", \"Modelos con más de 500 mil descargas\", \"Modelos con más de 1 millón de  descargas\", \"Modelos con más de 10 millones de descargas\", \"Modelos con más de 100 millones de descargas\"], [len([l for l in downloads if l &gt; 100000]), len([l for l in downloads if l &gt; 500000]), len([l for l in downloads if l &gt; 1000000]), len([l for l in downloads if l &gt; 10000000]), len([l for l in downloads if l &gt; 100000000])])\n\nplt.title(\"Cantidad de modelos con más de X descargas en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(len([l for l in downloads if l &gt; 100000]), len([l for l in downloads if l &gt; 500000]), len([l for l in downloads if l &gt; 1000000]), len([l for l in downloads if l &gt; 10000000]), len([l for l in downloads if l &gt; 100000000]))\n\n\n1134 443 273 34 3\nThere are 1,134 models with more than 100,000 downloads, 443 with more than 500,000 downloads, 273 with more than 1 million downloads, 34 with more than 10 million downloads, and 3 with more than 100 million downloads.\nLet’s see which models have more than 10 million downloads.\n\n\nCode\n[print(f\"Modelo: {m.id}, descargas: {m.downloads}\") for m in models_millon_downloads if m.downloads &gt; 10000000]\n\n\nModelo: nesaorg/benchmark_v0, descargas: 172569176\nModelo: sentence-transformers/all-MiniLM-L6-v2, descargas: 102361718\nModelo: Qwen/Qwen2.5-1.5B-Instruct, descargas: 29787495\nModelo: openai-community/gpt2, descargas: 13635588\nModelo: google-bert/bert-base-uncased, descargas: 69032646\nModelo: openai/clip-vit-large-patch14, descargas: 30593669\nModelo: openai/clip-vit-base-patch32, descargas: 21394717\nModelo: sentence-transformers/all-mpnet-base-v2, descargas: 181462888\nModelo: pyannote/speaker-diarization-3.1, descargas: 11145540\nModelo: sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2, descargas: 10717417\nModelo: pyannote/segmentation-3.0, descargas: 14657651\nModelo: bartowski/Meta-Llama-3.1-8B-Instruct-GGUF, descargas: 10642781\nModelo: FacebookAI/roberta-base, descargas: 16983687\nModelo: sentence-transformers/all-MiniLM-L12-v2, descargas: 10686154\nModelo: openai/clip-vit-large-patch14-336, descargas: 20836111\nModelo: distilbert/distilbert-base-uncased, descargas: 15451802\nModelo: microsoft/resnet-50, descargas: 34636864\nModelo: FacebookAI/xlm-roberta-large, descargas: 71149467\nModelo: google-bert/bert-base-multilingual-uncased, descargas: 12923212\nModelo: FacebookAI/roberta-large, descargas: 14851944\nModelo: FacebookAI/xlm-roberta-base, descargas: 12074140\nModelo: google/electra-base-discriminator, descargas: 10615222\nModelo: google/vit-base-patch16-224-in21k, descargas: 10802933\nModelo: jonatasgrosman/wav2vec2-large-xlsr-53-english, descargas: 20671837\nModelo: openai/clip-vit-base-patch16, descargas: 13014792\nModelo: bigscience/bloomz-560m, descargas: 12417679\nModelo: timm/resnet50.a1_in1k, descargas: 24015981\nModelo: pyannote/wespeaker-voxceleb-resnet34-LM, descargas: 12499697\nModelo: nesaorg/fc_12, descargas: 26749830\nModelo: nesaorg/fc_4, descargas: 19983316\nModelo: nesaorg/fc_6, descargas: 39967060\nModelo: nesaorg/fc_8, descargas: 54180206\nModelo: nesaorg/fc_16, descargas: 12477680\nModelo: distributed/optimized-gpt2-1b, descargas: 25559944\nLet’s now look at the downloads of the models only in Spanish.\n\n\nCode\nprint(len(downloads_es), downloads_es.count(0))\n\n\n1568 248\nOf the 1,568 models only in Spanish, 248 have 0 downloads.\n\n\nCode\ndl_es_dist = {\"Min\": np.min(downloads_es), \"25%\": np.quantile(downloads_es, 0.25), \"Median\": np.median(downloads_es), \"Mean\": np.mean(downloads_es), \"75%\": np.quantile(downloads_es, 0.75), \"90%\": np.quantile(downloads_es, 0.9), \"95%\": np.quantile(downloads_es, .95), \"99%\": np.quantile(downloads_es, .99)}\n\n\n\n\nCode\nplt.bar(dl_es_dist.keys(), dl_es_dist.values())\n\nplt.title(\"Distribución de descargas en modelos sólo en español de Hugging Face Hub\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(dl_es_dist)\n\n\n{'Min': np.int64(0), '25%': np.float64(9.0), 'Median': np.float64(15.0), 'Mean': np.float64(2504.596301020408), '75%': np.float64(27.0), '90%': np.float64(99.59999999999991), '95%': np.float64(376.8999999999992), '99%': np.float64(11140.349999999986)}\nThe average number of downloads for models only in Spanish is 2504, while 95% of the models have 377 downloads or less.\n\n\nCode\nplt.bar([\"Modelos con más de 1000 descargas\", \"Modelos con más de 5000 descargas\", \"Modelos con más de 10000 descargas\", \"Modelos con más de 100 mil descargas\", \"Modelos con más de 200 mil descargas\", \"Modelos con más de 500 mil descargas\"], [len([l for l in downloads_es if l &gt; 1000]), len([l for l in downloads_es if l &gt; 5000]), len([l for l in downloads_es if l &gt; 10000]), len([l for l in downloads_es if l &gt; 100000]), len([l for l in downloads_es if l &gt; 200000]), len([l for l in downloads_es if l &gt; 500000])])\n\nplt.title(\"Cantidad de modelos sólo en español con más de X descargas en Hugging Face Hub\")\n\n# Rotate the x-axis labels 45 degrees\nplt.xticks(rotation=45, ha=\"right\")\n\nplt.show()\n\n\n\n\n\nCode\nprint(len([l for l in downloads_es if l &gt; 1000]), len([l for l in downloads_es if l &gt; 5000]), len([l for l in downloads_es if l &gt; 10000]), len([l for l in downloads_es if l &gt; 100000]), len([l for l in downloads_es if l &gt; 200000]), len([l for l in downloads_es if l &gt; 500000]))\n\n\n53 23 17 7 5 2\nLet’s see which models only in Spanish have more than 100,000 downloads.\n\n\nCode\n[print(f\"Modelo: {m.id}, descargas: {m.downloads}\") for m in models_es_only_list if m.downloads &gt; 100000]\n\n\nModelo: MMG/xlm-roberta-large-ner-spanish, descargas: 657221\nModelo: dccuchile/bert-base-spanish-wwm-uncased, descargas: 458065\nModelo: hiiamsid/sentence_similarity_spanish_es, descargas: 131325\nModelo: pysentimiento/robertuito-emotion-analysis, descargas: 117978\nModelo: pysentimiento/robertuito-sentiment-analysis, descargas: 1111575\nModelo: datificate/gpt2-small-spanish, descargas: 480166\nModelo: finiteautomata/beto-sentiment-analysis, descargas: 461003\n\n\n\n\n\n[None, None, None, None, None, None, None]"
  },
  {
    "objectID": "posts/price-evolution/index.html",
    "href": "posts/price-evolution/index.html",
    "title": "ICT Prices Evolution",
    "section": "",
    "text": "Let’s see what was the evolution of prices of ICT services in Argentina in recent years.\nIf we take the time-series of the communications chapter of the INDEC Consumer Price Index (IPC-COM) we see that since the beginning of the series (Dec-2016=100) prices of communication services were above the general index until 2020, where the IPC-COM flattens and then goes below the general index.\n\n\n\nLet’s analyze in particular the years 2020 and 2021. First, 2020: if we look at the cumulative annual variation, the IPC-COM rises above the general IPC with the increase in March, which was partially reversed in April (the increase in prepaid mobile and fixed telephony, but not postpaid and mixed mobile) and then the IPC plateaus first due to the price agreement until July 31 and then due to the freeze imposed by DNU 690/2020 until December 31.\n\n\n\nNow let’s look at the year 2021:\n\n\n\n\nAs we can see, both 2020 and 2021 were years where price increases in ICTs were well below the increases in the general index.\nNote: according to COICOP Argentina, the Communications Chapter of the IPC does not include only ICT services but also the price of equipment and does not include prices of pay television services, which are reflected in the Chapter of Recreation and Culture.\nNow let’s see how we rank against other countries in the region in terms of affordability. The International Telecommunication Union (ITU) compiles standardized price statistics of price baskets for fixed and mobile services. Some examples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn these time-series, Argentina only seems to be doing well in mobile broadband (only data).\nNote: these time-series only includes 2018, 2019 and 2020 because in 2017 there was a change in methodology. For more information see here."
  },
  {
    "objectID": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "href": "posts/refefo-potential-to-enhance-productive-connectivity/index.html",
    "title": "REFEFO Potential to Enhance Productive Connectivity",
    "section": "",
    "text": "Most countries in the region have some sort of strategy to improve digital connectivity for vulnerable populations, for those who live in low density areas where the private sector alone does not have the incentives to invest in infrastructure, or to bring connectivity to education and health services. However, we cannot say the same about productive connectivity, meaning, connectivity infrastructure oriented towards improving the productivity of companies and workers.\nAn important prerequisite for bringing connectivity to a place is the existance of backbone networks that allow the development of the so-called “last mile” to connect homes and businesses. Argentina, for example, has the Federal Fiber Optic Network (REFEFO) managed by ARSAT, which is a backbone network that goes through the 23 provinces of the country, reaching about 1,300 localities, many of which have populations of less than 10,000 people. Of course, there are also other backbone fiber optic networks of private operators, but the layout of these networks and the location of the connection nodes is not publicly available.\nBut going back to the previous point, let’s analyze the potential of REFEFO to improve productive connectivity. Let’s take for example the agricultural sector, which is one of the most important in the Argentine economy and the most important regarding exports.\nWe can use data from the former Ministry of Productive Development to georeference agricultural companies and calculate the distance of each of them to the nearest REFEFO node and then analyze the distribution of these distances.\nFirst, we will obtain, filter and merge the necessary data for the analysis:\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd\nfrom requests import Request\nfrom shapely.geometry import box\n\n# Obtengo los datos de establecimientos productivos\nestab = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/establecimientos-productivos/distribucion_establecimientos_productivos_sexo.csv')\n\n# Obtengo datos del nomenclador de AFIP\nclae = pd.read_csv('https://cdn.produccion.gob.ar/cdn-cep/clae_agg.csv')\n\n# Uno los datos de establecimientos con el nomenclador\nestab = estab.merge(clae[['clae6', 'letra_desc']], left_on='clae6', right_on='clae6')\n\n# Filtro los del sector agropecuario\nestab_agro = estab[estab['letra_desc'] == ' AGRICULTURA, GANADERÍA, CAZA, SILVICULTURA Y PESCA']\n\n# Transformo los datos de establecimientos a un GeoDataFrame\nestab_agro_gpd = gpd.GeoDataFrame(estab_agro, geometry=gpd.points_from_xy(estab_agro.lon, estab_agro.lat), crs='EPSG:4326')\n\n# Obtengo los datos de los nodos de REFEFO\nidecom_url = 'https://www.idecom.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.3.0',\n    'request': 'GetFeature',\n    'typeName': 'idera:a010504-NODOS-FO',\n    'outputFormat': 'json'\n}\n\nrefefo_nodos_url = Request('GET', idecom_url, params=params).prepare().url\n\nrefefo_nodos = gpd.read_file(refefo_nodos_url)\n\n# Obtengo los datos de la geometría de las provincias\nign_url = 'https://wms.ign.gob.ar/geoserver/ows'\nparams = {\n    'service': 'wfs',\n    'version': '1.1.0',\n    'request': 'GetFeature',\n    'typeName': 'ign:provincia',\n    'outputFormat': 'json'\n}\n\nprov_url = Request('GET', ign_url, params=params).prepare().url\nprov = gpd.read_file(prov_url)\n\n# Recorto las provincias a la parte continental de Argentina\nbbox = (-76.36532,\n        -56.75009,\n        -51.20850,\n        -20.91625)\nbbox = gpd.GeoSeries([box(*bbox)], crs=prov.crs)\n\nprov_clipped = gpd.clip(prov, bbox)\n\n# Cruzo los establecimientos agropecuarios con el nodo de REFEFO más cercano y obtengo la distancia\nestab_agro_refefo_gpd = estab_agro_gpd.to_crs(crs=3857).sjoin_nearest(refefo_nodos.to_crs(3857), how='left', distance_col='distance')\n\n\nThen we will plot on a map each of the agricultural establishments and assign a color based on the distance to the nearest REFEFO node.\n\n\nCode\nfrom matplotlib import cm\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n# Size\nfig_size_bar = (7, 4)\nsize_labels = 10\nsize_tick_labels = 8\n\nfuente_bar_pos_x = 0.0\nfuente_bar_pos_y = -0.4\n\nfuente_map_pos_x = -74.0\nfuente_map_pos_y = -59.0\n\nfontname = 'Avenir'\nfont_weight = 'ultralight'\n\nnorm = mpl.colors.Normalize(vmin=0, vmax=150000)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\nprov_clipped.boundary.plot(ax=ax, color='black', linewidth=0.5)\n\nestab_agro_refefo_gpd.to_crs('EPSG:4326').plot(ax=ax, c=estab_agro_refefo_gpd['distance'], markersize=5, alpha=0.5, legend=True)\n\nax.set_axis_off()\n\ncbar = fig.colorbar(cm.ScalarMappable(norm), ax=ax, orientation='horizontal')\ncbar.set_label('Distancia a nodo de red (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\ncbar.ax.tick_params(labelsize=size_tick_labels)\nplt.show()\n\n\n\n\n\nMapa de Establecimientos Agropecuarios y Distancia a Nodo de REFEFO\n\n\nAlso, we will plot the histogram of the distances to analyze their distribution.\n\n\nCode\nimport matplotlib.ticker as mticker\nimport numpy as np\n\ncolor1 = [160.0/255.0, 160.0/255.0, 160.0/255.0, 1.0]\ncolor2 = [0.0, 200.0/255.0, 200.0/255.0, 1.0]\ncolor3 = [0.0, 255.0/255.0, 255.0/255.0, 1.0]\ncolor4 = [94.0/255.0, 144.0/255.0, 227.0/255.0, 1.0]\ncolor5 = [111.0/255.0, 109.0/255.0, 163.0/255.0, 1.0]\n\ncolors = [color1, color2, color3, color4, color5]\n\n# Style\ndef crossval_style(ax):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.spines['left'].set_visible(False)\n    ax.spines['bottom'].set_visible(False)\n    ax.grid(axis='y', linestyle='-', alpha=0.4)\n\ncounts, bins = np.histogram(estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'], bins=15)\n\ndensity = counts / np.sum(counts)\n\nfig, ax = plt.subplots(figsize=(7, 4))\n\n# ax = estab_agro_refefo_gpd[estab_agro_refefo_gpd['distance'] &lt; 150000]['distance'].hist(density=True, bins=15)\nax.hist(bins[:-1], bins, weights=density, color=colors[1])\n\n# Format the yticklabels to show actual proportions\n# ax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=0.0001))\nax.yaxis.set_major_formatter(mticker.PercentFormatter(xmax=1))\n\n# Set the font family and size of the x-axis label\nax.set_xlabel('Distancia (m)', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis label\nax.set_ylabel('Proporción', fontname=fontname, fontsize=size_labels, weight=font_weight)\n\n# Set the font family and size of the x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\n# Set the font family and size of the y-axis tick labels\nax.set_yticklabels(ax.get_yticklabels(), fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\ncrossval_style(ax)\n\nax.text(x = fuente_bar_pos_x, y = -0.3, s = f\"Fuente: Elaboración propia en base a datos del CEP XXI e IDECOM\", transform=ax.transAxes, fontname=fontname, fontsize=size_tick_labels, weight=font_weight)\n\nplt.show()\n\n\n\n\n\nHistograma de Distancias a Nodo de REFEFO\n\n\nAs you can see in the map and in the histogram, most of the agricultural establishments are located less than 10 km from a REFEFO node. To get the precise numbers let’s take a look at the mean and the quartiles of the distances.\n\n\nCode\nestab_agro_refefo_gpd['distance'].describe()\n\n\nThe mean distance of agricultural establishments to the nearest REFEFO node is 25,544 meters or 25.5 KMs. However, as observed in the histogram, the distances do not have a normal distribution but rather a right-skewed distribution, with most distances having low values and a few distances having very high values. In these cases, the median is more representative than the mean. Here the median is 8,580 meters or 8.6 KMs. This means that 50% of the agricultural establishments are located less than 8.6 KMs from a REFEFO node. Finally, the third quartile is 35,895 meters or almost 36 KMs, which means that 75% of the agricultural establishments are located less than 36 KMs from a REFEFO node.\nThere are many ways in which we can improve this preliminary analysis but this first approach seems to indicate that the distance to backbone networks should not be an obstacle for the development of productive rural connectivity in Argentina."
  },
  {
    "objectID": "posts/stem-movie-recommendations/index.html",
    "href": "posts/stem-movie-recommendations/index.html",
    "title": "STEM Movie Recommendations",
    "section": "",
    "text": "Here are reviews and recommendations of STEM movies and series, in no particular order:\n\nThe Imitation Game\nThis biographical film tells the life story of Alan Turing, the British mathematician who deciphered the Enigma code during World War II. It’s a moving portrayal of a brilliant yet misunderstood mind, highlighting Turing’s pivotal contributions to modern computing. Recommended for those interested in the history of cryptography and the early days of artificial intelligence.\nThe Playlist\nThis series follows the story of Spotify and how it revolutionized the music industry. It shows the conflict between technological innovation and the old power structures in the music business. Recommended for those interested in the impact of tech platforms on culture and business.\nThe Billion Dollar Code\nThis miniseries, based on true events, depicts the legal battle between two German programmers and Google over the patent rights to what eventually became Google Earth. It’s a courtroom drama about innovation, intellectual property, and justice in the digital age. Recommended for those who enjoy stories about startups and tech giants.\nBlackberry\nThis film follows the rise and fall of Blackberry, one of the pioneering companies in smartphone development. It’s a fascinating look at the fast-paced world of technology and how innovation—and failure to adapt—can make or break a company. Recommended for those interested in the history of mobile technology and the rise of personal devices.\nThe Theory of Everything\nThis biopic about Stephen Hawking narrates his personal and professional life, focusing on his battle with ALS while developing groundbreaking theories about the universe. It’s a moving and visually stunning film. Highly recommended for those looking for an inspiring story about science and personal perseverance.\nThe Man Who Knew Infinity\nThe film portrays the life of Srinivasa Ramanujan, a self-taught mathematical prodigy who travels from India to Cambridge to collaborate with mathematician G.H. Hardy. It’s a tribute to intellectual perseverance and the genius that breaks cultural and academic barriers. Recommended for those who enjoy biographical stories about mathematical prodigies.\nOppenheimer\nAn epic portrait of the life of J. Robert Oppenheimer, the physicist who led the development of the atomic bomb in the Manhattan Project. The film explores the ethical and emotional impact of creating a weapon of mass destruction. Highly recommended for those interested in the history of science and the ethical dilemmas associated with technology.\nThe Social Network\nThe film tells the story of Facebook’s creation and the rise of Mark Zuckerberg. It shows the personal and legal conflicts that accompanied the success of one of the most influential platforms of the 21st century. Recommended for those who want to understand the origins of social networks and the ethical challenges of digital power.\nThe Social Dilemma\nThis documentary analyzes the negative impact of social media on society, from psychological manipulation to the erosion of democracy. With interviews from former tech company executives, it’s a stark warning about the dangers of unchecked technology. Recommended for those interested in the social and psychological effects of social networks.\nSteve Jobs\nDirected by Danny Boyle, this biopic offers an intimate look at Steve Jobs’s life, centered around three key moments in his career. Through sharp and dramatic dialogue, the film presents the Apple founder as a visionary but also as a complex figure. Recommended for those looking for a personal portrait of one of the most influential figures in modern technology.\nCitizenfour\nThis documentary follows whistleblower Edward Snowden as he reveals the U.S. government’s mass surveillance program. It’s a raw and urgent look at privacy, security, and governmental power. Recommended for those interested in digital rights and privacy.\nThe Internet’s Own Boy: The Story of Aaron Swartz\nThis documentary tells the life of Aaron Swartz, a digital activist and programmer who fought for free access to information. His tragic death highlights the conflicts between information freedom and restrictive laws. Recommended for those looking to explore the intersection of technology, activism, and civil rights in the digital age."
  },
  {
    "objectID": "posts/using-satellite-images/index.html",
    "href": "posts/using-satellite-images/index.html",
    "title": "Using Satellite Images",
    "section": "",
    "text": "Satellite remote sensing or satellite remote sensing is the activity of collecting data through the use of sensors, in this case satellites, from a place to which there is no physical access, that is, remotely.\nThese data consist of the measurement of electromagnetic energy. Electromagnetic radiation is a form of energy emitted by all matter with a temperature above absolute zero (0 Kelvin or -272° Celcius). X-rays, ultraviolet, visible light, infrared, heat, microwaves, and radio and television waves are all forms of electromagnetic energy with different wavelengths or frequencies and are part of the electromagnetic spectrum.\nHotter objects emit more electromagnetic energy and shorter wavelengths than cooler ones. The most common source of electromagnetic radiation is the Sun. Objects that make up the Earth’s surface reflect and emit electromagnetic radiation in different ways.\nThe portion of the electromagnetic spectrum where the peak of solar radiation is located is called the visible band, since human vision is sensitive to these waves. Remote sensing allows us to extend the human ability to perceive electromagnetic radiation beyond the visual band, so the parts of the electromagnetic spectrum that we cannot see are very important.\nThe objects that make up the Earth’s surface reflect electromagnetic radiation in different ways. The appeal of multispectral remote sensing is that objects indistinguishable at one wavelength may be easy to distinguish at another. The bands commonly used to perceive occupation and land use are: visible, infrared and microwave.\nUnderstanding the different ways in which specific wavelengths interact with different objects allows finding “stamps” or “signatures” that will allow those objects to be detected automatically.\nThe applications are diverse: monitoring of deforestation, soil degradation, detection and classification of objects as dissimilar as wetlands, informal settlements and gated communities, monitoring of water quality and salinity, air quality, detection of clandestine dumps, monitoring of landfills health, monitoring the environmental impact of certain industries, among others.\nIn this post I am not going to advance in detection or classification of objects but, following this tutorial I am going to use satellite images together with SRTM elevation data to make a 3D map of my favorite place in the world: the Cuesta del Viento Dam in Rodeo, San Juan.\nHere is the code:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nAnd the resulting visualization:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#brief-concept-intro1",
    "href": "posts/using-satellite-images/index.html#brief-concept-intro1",
    "title": "Using Satellite Images",
    "section": "",
    "text": "Satellite remote sensing or satellite remote sensing is the activity of collecting data through the use of sensors, in this case satellites, from a place to which there is no physical access, that is, remotely.\nThese data consist of the measurement of electromagnetic energy. Electromagnetic radiation is a form of energy emitted by all matter with a temperature above absolute zero (0 Kelvin or -272° Celcius). X-rays, ultraviolet, visible light, infrared, heat, microwaves, and radio and television waves are all forms of electromagnetic energy with different wavelengths or frequencies and are part of the electromagnetic spectrum.\nHotter objects emit more electromagnetic energy and shorter wavelengths than cooler ones. The most common source of electromagnetic radiation is the Sun. Objects that make up the Earth’s surface reflect and emit electromagnetic radiation in different ways.\nThe portion of the electromagnetic spectrum where the peak of solar radiation is located is called the visible band, since human vision is sensitive to these waves. Remote sensing allows us to extend the human ability to perceive electromagnetic radiation beyond the visual band, so the parts of the electromagnetic spectrum that we cannot see are very important.\nThe objects that make up the Earth’s surface reflect electromagnetic radiation in different ways. The appeal of multispectral remote sensing is that objects indistinguishable at one wavelength may be easy to distinguish at another. The bands commonly used to perceive occupation and land use are: visible, infrared and microwave.\nUnderstanding the different ways in which specific wavelengths interact with different objects allows finding “stamps” or “signatures” that will allow those objects to be detected automatically.\nThe applications are diverse: monitoring of deforestation, soil degradation, detection and classification of objects as dissimilar as wetlands, informal settlements and gated communities, monitoring of water quality and salinity, air quality, detection of clandestine dumps, monitoring of landfills health, monitoring the environmental impact of certain industries, among others.\nIn this post I am not going to advance in detection or classification of objects but, following this tutorial I am going to use satellite images together with SRTM elevation data to make a 3D map of my favorite place in the world: the Cuesta del Viento Dam in Rodeo, San Juan.\nHere is the code:\n\nlibrary(rayshader)\nlibrary(sp)\nlibrary(raster)\nlibrary(scales)\n\nrodeo_elevation &lt;- raster::raster(\"S31W070.hgt\")\n\nheight_shade(raster_to_matrix(rodeo_elevation)) %&gt;% \n  plot_map()\n\nrodeo_r &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B4.TIF\")\nrodeo_g &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B3.TIF\")\nrodeo_b &lt;- raster::raster(\"LC08_L1TP_232081_20210817_20210826_01_T1_B2.TIF\")\n\nrodeo_rgb &lt;- raster::stack(rodeo_r, rodeo_g, rodeo_b)\n\nraster::plotRGB(rodeo_rgb, scale=255^2)\n\nrodeo_rgb_corrected &lt;- sqrt(raster::stack(rodeo_r, rodeo_g, rodeo_b))\nraster::plotRGB(rodeo_rgb_corrected)\n\nraster::crs(rodeo_r)\nraster::crs(rodeo_elevation)\n\nrodeo_elevation_utm &lt;- raster::projectRaster(rodeo_elevation, \n                                             crs = crs(rodeo_r), \n                                             method = \"bilinear\")\n\ncrs(rodeo_elevation_utm)\n\nbottom_left &lt;- c(y=-69.1478, x=-30.2374)\ntop_right &lt;- c(y=-69.0077, x=-30.1295)\n\nextent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), \n                                   proj4string=sp::CRS(\"+proj=longlat +ellps=WGS84 +datum=WGS84\"))\nextent_utm &lt;- sp::spTransform(extent_latlong, raster::crs(rodeo_elevation_utm))\n\ne &lt;- raster::extent(extent_utm)\n\nrodeo_rgb_cropped &lt;- raster::crop(rodeo_rgb_corrected, e)\nrodeo_elevation_cropped &lt;- raster::crop(rodeo_elevation_utm, e)\n\nnames(rodeo_rgb_cropped) &lt;- c(\"r\", \"g\", \"b\")\n\nrodeo_r_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$r)\nrodeo_g_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$g)\nrodeo_b_cropped = rayshader::raster_to_matrix(rodeo_rgb_cropped$b)\n\nrodeo_elevation_matrix &lt;- rayshader::raster_to_matrix(rodeo_elevation_cropped)\n\nrodeo_rgb_array &lt;- array(0, dim = c(nrow(rodeo_r_cropped), ncol(rodeo_r_cropped), 3))\n\nrodeo_rgb_array[,,1] &lt;- rodeo_r_cropped/255\nrodeo_rgb_array[,,2] &lt;- rodeo_g_cropped/255\nrodeo_rgb_array[,,3] &lt;- rodeo_b_cropped/255\n\nrodeo_rgb_array &lt;- aperm(rodeo_rgb_array, c(2,1,3))\n\nplot_map(rodeo_rgb_array)\n\nrodeo_rgb_contrast &lt;- scales::rescale(rodeo_rgb_array, to=c(0,1))\n\nplot_map(rodeo_rgb_contrast)\n\nplot_3d(hillshade = rodeo_rgb_contrast, \n        heightmap = rodeo_elevation_matrix,\n        windowsize = c(1100, 900),\n        zscale = 15, \n        shadowdepth = -50, \n        zoom = 0.5,\n        phi = 45, \n        theta = -45, \n        fov = 70, \n        background = \"#F2E1D0\", \n        shadowcolor = \"#523E2B\")\n\nrender_snapshot(title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\", \n                title_bar_color = \"#523E2B\", title_color = \"white\", title_bar_alpha = 1)\n\n# Video\n\nangles &lt;- seq(0, 360, length.out = 1441)[-1]\n\nfor(i in 1:1440) {\n  render_camera(theta = -45+angles[i])\n  render_snapshot(filename = sprintf(\"cuesta_%i.png\", i),\n                  title_text = \"Dique Cuesta del Viento, San Juan | Imagery: Landsat 8 | DEM: 30m SRTM\",\n                  title_bar_color = \"#1f5214\", title_color = \"white\", title_bar_alpha = 1)\n}\n\nrgl::rgl.close()\n\nAnd the resulting visualization:\nVideo"
  },
  {
    "objectID": "posts/using-satellite-images/index.html#footnotes",
    "href": "posts/using-satellite-images/index.html#footnotes",
    "title": "Using Satellite Images",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn base al MOOC “Imagery, Automation, and Applications” de la Universidad de California, Davis y al libro de David DiBiase, The Nature of Geographic Information. Penn State University, College of Earth and Mineral Sciences. Retrieved from https://www.e-education.psu.edu/natureofgeoinfo/↩︎"
  }
]